{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758f5a36-a6fc-42a4-980f-e2e51ba91184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading all pore size data...\n",
      "found 8 PORE SIZE RESULTS folders in c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\AFM Accuracy INTERNAL\\AFM 1% INTERNAL\n",
      "  AFM 1% replicate=1: 11 csv files\n",
      "  AFM 1% replicate=1: 0 csv files\n",
      "  AFM 1% replicate=1: 0 csv files\n",
      "  AFM 1% replicate=1: 0 csv files\n",
      "  AFM 1% replicate=2: 11 csv files\n",
      "  AFM 1% replicate=3: 11 csv files\n",
      "  AFM 1% replicate=4: 11 csv files\n",
      "  AFM 1% replicate=5: 11 csv files\n",
      "found 1 PORE SIZE RESULTS folders in c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\AFM Accuracy INTERNAL\\AFM 1.5% INTERNAL\n",
      "  AFM 1.5% replicate=1: 11 csv files\n",
      "found 3 PORE SIZE RESULTS folders in c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\AFM Accuracy INTERNAL\\AFM 2% INTERNAL\n",
      "  AFM 2% replicate=1: 11 csv files\n",
      "  AFM 2% replicate=2: 10 csv files\n",
      "  AFM 2% replicate=3: 11 csv files\n",
      "found 1 PORE SIZE RESULTS folders in c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\Confocal Accuracy INTERNAL\\Confocal 0.375%\n",
      "  CONFOCAL 0.375% replicate=1: 11 csv files\n",
      "found 1 PORE SIZE RESULTS folders in c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\Confocal Accuracy INTERNAL\\Confocal 1%\n",
      "  CONFOCAL 1% replicate=1: 11 csv files\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\STED Accuracy INTERNAL\\Internal 0.375%\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\STED Accuracy INTERNAL\\Internal 1%\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X3000\\CRYO-SEM X3000\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X10000\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\n",
      "warning: path does not exist: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X60000\n",
      "\n",
      "combined pore size results:\n",
      "shape: (21933, 10)\n",
      "   technique concentration  replicate method_group    method  \\\n",
      "0        AFM            1%          1    SEMI_AUTO       60%   \n",
      "1        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "2        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "3        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "4        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "5        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "6        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "7        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "8        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "9        AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "10       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "11       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
      "\n",
      "                  file_source    Method    AECD_um        SourceFile Subfolder  \n",
      "0        60% AECD Results.csv       60%  11.269509       60% Results         .  \n",
      "1   FREEHAND AECD Results.csv  FREEHAND   1.134007  FREEHAND Results         .  \n",
      "2   FREEHAND AECD Results.csv  FREEHAND   1.433530  FREEHAND Results         .  \n",
      "3   FREEHAND AECD Results.csv  FREEHAND   0.816809  FREEHAND Results         .  \n",
      "4   FREEHAND AECD Results.csv  FREEHAND   0.469330  FREEHAND Results         .  \n",
      "5   FREEHAND AECD Results.csv  FREEHAND   1.015541  FREEHAND Results         .  \n",
      "6   FREEHAND AECD Results.csv  FREEHAND   0.873310  FREEHAND Results         .  \n",
      "7   FREEHAND AECD Results.csv  FREEHAND   0.638308  FREEHAND Results         .  \n",
      "8   FREEHAND AECD Results.csv  FREEHAND   0.249777  FREEHAND Results         .  \n",
      "9   FREEHAND AECD Results.csv  FREEHAND   0.620095  FREEHAND Results         .  \n",
      "10  FREEHAND AECD Results.csv  FREEHAND   0.609743  FREEHAND Results         .  \n",
      "11  FREEHAND AECD Results.csv  FREEHAND   0.340389  FREEHAND Results         .  \n",
      "\n",
      "file counts by technique/concentration/method:\n",
      "   technique concentration    method  file_count\n",
      "0        AFM            1%       60%           1\n",
      "1        AFM            1%  FREEHAND           1\n",
      "2        AFM            1%      GOLD           2\n",
      "3        AFM            1%   ILASTIK           2\n",
      "4        AFM            1%      OTSU           1\n",
      "5        AFM            1%      OVAL           2\n",
      "6        AFM            1%      PLAN           2\n",
      "7        AFM            1%    PORED2           2\n",
      "8        AFM            1%      SAMJ           2\n",
      "9        AFM            1%      SEMI           2\n",
      "10       AFM            1%      UNET           2\n",
      "11       AFM          1.5%       60%           1\n",
      "12       AFM          1.5%  FREEHAND           1\n",
      "13       AFM          1.5%      GOLD           1\n",
      "14       AFM          1.5%   ILASTIK           1\n",
      "15       AFM          1.5%      OTSU           1\n",
      "16       AFM          1.5%      OVAL           1\n",
      "17       AFM          1.5%      PLAN           1\n",
      "18       AFM          1.5%    PORED2           1\n",
      "19       AFM          1.5%      SAMJ           1\n",
      "20       AFM          1.5%      SEMI           1\n",
      "21       AFM          1.5%      UNET           1\n",
      "22       AFM            2%       60%           1\n",
      "23       AFM            2%  FREEHAND           1\n",
      "24       AFM            2%      GOLD           1\n",
      "\n",
      "saved to: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\AFM Accuracy INTERNAL\\AFM 1% INTERNAL\\pore_size_results_all.csv\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd()\n",
    "proj_root = notebook_dir.parent\n",
    "org_dir = str(proj_root)\n",
    "\n",
    "\"\"\"\n",
    "This script loads all my pore size analysis results from different folders\n",
    "I have data from AFM, CRYO-SEM, STED, and CONFOCAL experiments\n",
    "Each has different concentrations and I need to combine everything\n",
    "\"\"\"\n",
    "\n",
    "# method groups i need to categorize the segmentation approaches\n",
    "traditional_methods = [\"FREEHAND\", \"OVAL\"]\n",
    "semi_auto_methods = [\"SEMI\", \"SAMJ\", \"ILASTIK\", \"60%\"]\n",
    "full_auto_methods = [\"PORED2\", \"UNET\", \"OTSU\", \"PHANSALKAR\"]\n",
    "\n",
    "def clean_method_name(name):\n",
    "    \"\"\"\n",
    "    Clean up method names from filenames to standardize them\n",
    "    Sometimes the filenames have extra stuff so need to extract the actual method\n",
    "    \"\"\"\n",
    "    if name is None or not isinstance(name, str):\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "    clean_name = name.strip()\n",
    "    upper_name = clean_name.upper()\n",
    "    \n",
    "    # special case for 60% because it has a percentage sign\n",
    "    if \"60\" in upper_name and \"%\" in upper_name:\n",
    "        return \"60%\"\n",
    "    \n",
    "    # check against my list of known methods\n",
    "    known_methods = [\"FREEHAND\", \"OVAL\", \"SEMI\", \"SAMJ\", \"ILASTIK\", \"OTSU\", \"PHANSALKAR\", \"PORED2\", \"UNET\", \"PLAN\"]\n",
    "    for method in known_methods:\n",
    "        if upper_name.startswith(method):\n",
    "            return method\n",
    "    \n",
    "    # if nothing matches try to get something meaningful\n",
    "    match = re.search(r\"[A-Z0-9%]+\", upper_name)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    else:\n",
    "        return clean_name\n",
    "\n",
    "def get_method_group(method):\n",
    "    \"\"\"\n",
    "    Put each method into one of my three categories\n",
    "    This helps with the statistical analysis later\n",
    "    \"\"\"\n",
    "    clean_method = clean_method_name(method)\n",
    "    \n",
    "    if clean_method in traditional_methods:\n",
    "        return \"TRADITIONAL\"\n",
    "    elif clean_method in semi_auto_methods:\n",
    "        return \"SEMI_AUTO\"\n",
    "    elif clean_method in full_auto_methods:\n",
    "        return \"FULL_AUTO\"\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "\n",
    "# these are all the folders where i stored my experimental data\n",
    "# each one has a specific technique and concentration\n",
    "data_roots = [\n",
    "    os.path.join(org_dir ,\"AFM Accuracy INTERNAL/AFM 1% INTERNAL\"),\n",
    "    os.path.join(org_dir ,\"AFM Accuracy INTERNAL/AFM 1.5% INTERNAL\"),\n",
    "    os.path.join(org_dir ,\"AFM Accuracy INTERNAL/AFM 2% INTERNAL\"),\n",
    "    os.path.join(org_dir ,\"Confocal Accuracy INTERNAL/Confocal 0.375%\"),\n",
    "    os.path.join(org_dir ,\"Confocal Accuracy INTERNAL/Confocal 1%\"),\n",
    "    os.path.join(org_dir ,\"STED Accuracy INTERNAL/Internal 0.375%\"),\n",
    "    os.path.join(org_dir ,\"STED Accuracy INTERNAL/Internal 1%\"),\n",
    "    os.path.join(org_dir ,\"CRYO-SEM Accuracy INTERNAL/CRYO-SEM X3000/CRYO-SEM X3000\"),\n",
    "    os.path.join(org_dir ,\"CRYO-SEM Accuracy INTERNAL/CRYO-SEM X10000\"),\n",
    "    os.path.join(org_dir ,\"CRYO-SEM Accuracy INTERNAL/CRYO-SEM X30000\"),\n",
    "    os.path.join(org_dir ,\"CRYO-SEM Accuracy INTERNAL/CRYO-SEM X60000\"),\n",
    "]\n",
    "\n",
    "def get_technique(path_string):\n",
    "    \"\"\"\n",
    "    Extract which imaging technique was used from the folder path\n",
    "    Just looking for keywords in the path name\n",
    "    \"\"\"\n",
    "    path_upper = path_string.upper()\n",
    "    \n",
    "    if \"AFM\" in path_upper:\n",
    "        return \"AFM\"\n",
    "    elif \"CONFOCAL\" in path_upper:\n",
    "        return \"CONFOCAL\"\n",
    "    elif \"STED\" in path_upper:\n",
    "        return \"STED\"\n",
    "    elif \"CRYO-SEM\" in path_upper or (\"CRYO\" in path_upper and \"SEM\" in path_upper):\n",
    "        return \"CRYO-SEM\"\n",
    "    else:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "def get_concentration(path_string, technique):\n",
    "    \"\"\"\n",
    "    Get the concentration or magnification from the path\n",
    "    Different techniques use different units so need to handle separately\n",
    "    \"\"\"\n",
    "    path_upper = path_string.upper()\n",
    "    \n",
    "    # for AFM, STED, CONFOCAL we have percentage concentrations\n",
    "    if technique in [\"AFM\", \"STED\", \"CONFOCAL\"]:\n",
    "        concentrations = [\"0.375%\", \"1.5%\", \"1%\", \"2%\"]\n",
    "        for conc in concentrations:\n",
    "            if conc in path_upper:\n",
    "                return conc\n",
    "        return \"unknown\"\n",
    "    # for CRYO-SEM we have magnifications\n",
    "    elif technique == \"CRYO-SEM\":\n",
    "        magnifications = [\"X60000\", \"X30000\", \"X10000\", \"X3000\"]\n",
    "        for mag in magnifications:\n",
    "            if mag in path_upper:\n",
    "                return mag\n",
    "        return \"unknown\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "def get_replicate_number(path):\n",
    "    \"\"\"\n",
    "    Find replicate numbers in folder names\n",
    "    They are usually in brackets like [1], [2], [3]\n",
    "    \"\"\"\n",
    "    path_str = str(path)\n",
    "    # look for pattern like [1], [2], etc\n",
    "    replicate_match = re.search(r\"\\[(\\d+)\\]\", path_str)\n",
    "    if replicate_match:\n",
    "        try:\n",
    "            return int(replicate_match.group(1))\n",
    "        except:\n",
    "            return 1  # default to 1 if something goes wrong\n",
    "    return 1\n",
    "\n",
    "def find_pore_size_folders(root_path):\n",
    "    \"\"\"\n",
    "    Search for all folders named exactly PORE SIZE RESULTS\n",
    "    This is where i put all my analysis outputs\n",
    "    \"\"\"\n",
    "    result_folders = []\n",
    "    for folder in root_path.rglob(\"PORE SIZE RESULTS\"):\n",
    "        result_folders.append(folder)\n",
    "    return result_folders\n",
    "\n",
    "def load_all_pore_data():\n",
    "    \"\"\"\n",
    "    Main function that goes through all my data folders\n",
    "    Finds the CSV files and loads them with proper metadata\n",
    "    This takes a while because there are lots of files\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # go through each root folder\n",
    "    for root_str in data_roots:\n",
    "        root_path = Path(root_str)\n",
    "        \n",
    "        # check if folder actually exists\n",
    "        if not root_path.exists():\n",
    "            print(\"warning: path does not exist: \" + str(root_path))\n",
    "            continue\n",
    "        \n",
    "        # find all the PORE SIZE RESULTS folders\n",
    "        pore_folders = find_pore_size_folders(root_path)\n",
    "        print(\"found \" + str(len(pore_folders)) + \" PORE SIZE RESULTS folders in \" + str(root_path))\n",
    "        \n",
    "        # process each folder\n",
    "        for folder in pore_folders:\n",
    "            path_str = str(folder)\n",
    "            technique = get_technique(path_str)\n",
    "            concentration = get_concentration(path_str, technique)\n",
    "            replicate = get_replicate_number(folder)\n",
    "            \n",
    "            # find all csv files in this folder\n",
    "            csv_files = []\n",
    "            for csv_file in folder.glob(\"*.csv\"):\n",
    "                csv_files.append(csv_file)\n",
    "            csv_files.sort()  # keep them in order\n",
    "            \n",
    "            print(\"  \" + technique + \" \" + concentration + \" replicate=\" + str(replicate) + \": \" + str(len(csv_files)) + \" csv files\")\n",
    "            \n",
    "            # load each csv file\n",
    "            for csv_path in csv_files:\n",
    "                try:\n",
    "                    # read the csv data\n",
    "                    data = pd.read_csv(csv_path)\n",
    "                except Exception as error:\n",
    "                    print(\"error reading \" + str(csv_path) + \": \" + str(error))\n",
    "                    continue\n",
    "                \n",
    "                # make a copy so we don't mess up the original\n",
    "                data_copy = data.copy()\n",
    "                \n",
    "                # add all the metadata columns\n",
    "                data_copy[\"technique\"] = technique\n",
    "                data_copy[\"concentration\"] = concentration\n",
    "                data_copy[\"replicate\"] = replicate\n",
    "                data_copy[\"file_source\"] = csv_path.name\n",
    "                \n",
    "                # extract method name from the filename\n",
    "                # usually the first part before any spaces\n",
    "                filename_parts = csv_path.stem.split(\" \")\n",
    "                method_name = filename_parts[0]\n",
    "                data_copy[\"method\"] = clean_method_name(method_name)\n",
    "                \n",
    "                # assign method group for each row\n",
    "                method_groups = []\n",
    "                for method in data_copy[\"method\"]:\n",
    "                    method_groups.append(get_method_group(method))\n",
    "                data_copy[\"method_group\"] = method_groups\n",
    "                \n",
    "                # add this dataframe to our collection\n",
    "                all_data.append(data_copy)\n",
    "    \n",
    "    # check if we actually loaded anything\n",
    "    if len(all_data) == 0:\n",
    "        print(\"warning: no csv files found\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # combine all dataframes into one big one\n",
    "    combined_data = pd.concat(all_data, ignore_index=True, sort=False)\n",
    "    \n",
    "    # reorganize columns so metadata comes first\n",
    "    metadata_cols = [\"technique\", \"concentration\", \"replicate\", \"method_group\", \"method\", \"file_source\"]\n",
    "    other_cols = []\n",
    "    for col in combined_data.columns:\n",
    "        if col not in metadata_cols:\n",
    "            other_cols.append(col)\n",
    "    \n",
    "    final_cols = metadata_cols + other_cols\n",
    "    return combined_data[final_cols]\n",
    "\n",
    "# actually run the data loading process\n",
    "print(\"loading all pore size data...\")\n",
    "results = load_all_pore_data()\n",
    "\n",
    "print(\"\")\n",
    "print(\"combined pore size results:\")\n",
    "print(\"shape: \" + str(results.shape))\n",
    "print(results.head(12))\n",
    "\n",
    "# do some basic checks on what we loaded\n",
    "if len(results) > 0:\n",
    "    print(\"\")\n",
    "    print(\"file counts by technique/concentration/method:\")\n",
    "    # group by the key variables and count unique files\n",
    "    file_counts = results.groupby([\"technique\", \"concentration\", \"method\"])[\"file_source\"].nunique().reset_index()\n",
    "    file_counts.columns = [\"technique\", \"concentration\", \"method\", \"file_count\"]\n",
    "    print(file_counts.head(25))\n",
    "\n",
    "# save everything to a single csv file\n",
    "try:\n",
    "    # try to save near the first root path if it exists\n",
    "    output_dir = Path(data_roots[0]) if Path(data_roots[0]).exists() else Path(org_dir)\n",
    "    output_file = output_dir / \"pore_size_results_all.csv\"\n",
    "    results.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    print(\"\")\n",
    "    print(\"saved to: \" + str(output_file))\n",
    "except Exception as error:\n",
    "    print(\"error saving file: \" + str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b10129b-4003-48e0-ad44-7fa297d358e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>technique</th>\n",
       "      <th>concentration</th>\n",
       "      <th>replicate</th>\n",
       "      <th>method_group</th>\n",
       "      <th>method</th>\n",
       "      <th>file_source</th>\n",
       "      <th>Method</th>\n",
       "      <th>AECD_um</th>\n",
       "      <th>SourceFile</th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFM</td>\n",
       "      <td>1%</td>\n",
       "      <td>1</td>\n",
       "      <td>SEMI_AUTO</td>\n",
       "      <td>60%</td>\n",
       "      <td>60% AECD Results.csv</td>\n",
       "      <td>60%</td>\n",
       "      <td>11.269509</td>\n",
       "      <td>60% Results</td>\n",
       "      <td>.</td>\n",
       "      <td>Semi-automated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFM</td>\n",
       "      <td>1%</td>\n",
       "      <td>1</td>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>FREEHAND AECD Results.csv</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>1.134007</td>\n",
       "      <td>FREEHAND Results</td>\n",
       "      <td>.</td>\n",
       "      <td>Traditional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFM</td>\n",
       "      <td>1%</td>\n",
       "      <td>1</td>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>FREEHAND AECD Results.csv</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>1.433530</td>\n",
       "      <td>FREEHAND Results</td>\n",
       "      <td>.</td>\n",
       "      <td>Traditional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFM</td>\n",
       "      <td>1%</td>\n",
       "      <td>1</td>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>FREEHAND AECD Results.csv</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>0.816809</td>\n",
       "      <td>FREEHAND Results</td>\n",
       "      <td>.</td>\n",
       "      <td>Traditional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFM</td>\n",
       "      <td>1%</td>\n",
       "      <td>1</td>\n",
       "      <td>TRADITIONAL</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>FREEHAND AECD Results.csv</td>\n",
       "      <td>FREEHAND</td>\n",
       "      <td>0.469330</td>\n",
       "      <td>FREEHAND Results</td>\n",
       "      <td>.</td>\n",
       "      <td>Traditional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  technique concentration  replicate method_group    method  \\\n",
       "0       AFM            1%          1    SEMI_AUTO       60%   \n",
       "1       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
       "2       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
       "3       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
       "4       AFM            1%          1  TRADITIONAL  FREEHAND   \n",
       "\n",
       "                 file_source    Method    AECD_um        SourceFile Subfolder  \\\n",
       "0       60% AECD Results.csv       60%  11.269509       60% Results         .   \n",
       "1  FREEHAND AECD Results.csv  FREEHAND   1.134007  FREEHAND Results         .   \n",
       "2  FREEHAND AECD Results.csv  FREEHAND   1.433530  FREEHAND Results         .   \n",
       "3  FREEHAND AECD Results.csv  FREEHAND   0.816809  FREEHAND Results         .   \n",
       "4  FREEHAND AECD Results.csv  FREEHAND   0.469330  FREEHAND Results         .   \n",
       "\n",
       "           family  \n",
       "0  Semi-automated  \n",
       "1     Traditional  \n",
       "2     Traditional  \n",
       "3     Traditional  \n",
       "4     Traditional  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the combined dataframe we made in the previous cell\n",
    "# making a copy so i dont accidentally change the original data\n",
    "combined_pore_size_df = results.copy()\n",
    "\n",
    "def assign_family(method_name):\n",
    "    \"\"\"\n",
    "    This function takes a method name and puts it into one of the family categories\n",
    "    I need this because i want to group methods by how much human input they need\n",
    "    Traditional methods need lots of manual work\n",
    "    Semi-automated methods need some human guidance\n",
    "    Fully automated methods work on their own\n",
    "    \"\"\"\n",
    "    # convert to string and make uppercase to be safe\n",
    "    token = str(method_name).upper()\n",
    "    \n",
    "    # check which family this method belongs to\n",
    "    if token in traditional_methods:\n",
    "        return \"Traditional\"\n",
    "    elif token in semi_auto_methods:\n",
    "        return \"Semi-automated\"\n",
    "    elif token in full_auto_methods:\n",
    "        return \"Fully automated\"\n",
    "    else:\n",
    "        # if its not in any of my lists just call it unknown\n",
    "        return \"Unknown\"\n",
    "\n",
    "# add the family column to my dataframe\n",
    "# this will help me compare different types of methods later\n",
    "combined_pore_size_df['family'] = combined_pore_size_df['method'].apply(assign_family)\n",
    "\n",
    "# take a look at what we got\n",
    "combined_pore_size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a00cdf24-430e-4b59-b785-2cb17a04b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "analyzing: CRYO-SEM X3000\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: CRYO-SEM X10000\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: CRYO-SEM X30000\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: CRYO-SEM X60000\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: AFM 1%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 55\n",
      "number of replicates: 5\n",
      "number of methods: 11\n",
      "\n",
      "observations per method:\n",
      "method\n",
      "60%         5\n",
      "FREEHAND    5\n",
      "GOLD        5\n",
      "ILASTIK     5\n",
      "OTSU        5\n",
      "OVAL        5\n",
      "PLAN        5\n",
      "PORED2      5\n",
      "SAMJ        5\n",
      "SEMI        5\n",
      "UNET        5\n",
      "dtype: int64\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "          n       mean     median        std       min         max\n",
      "method                                                            \n",
      "60%       5  2523.8313   231.2489  4899.4319   50.4627  11269.5086\n",
      "FREEHAND  5   448.0592   592.4122   319.6859   61.8039    809.3367\n",
      "GOLD      5   386.7769   550.4230   257.5455   66.5844    591.7270\n",
      "ILASTIK   5   212.0509   280.8819   132.0044   71.3650    355.6784\n",
      "OTSU      5   121.8666   100.7272   104.5889   28.0238    270.5528\n",
      "OVAL      5   433.9955   549.8807   287.9905   71.3650    715.7552\n",
      "PLAN      5    54.6787    71.3650    30.7312   21.1853     79.7885\n",
      "PORED2    5   165.9466   155.5363    72.1549   87.4039    248.4964\n",
      "SAMJ      5   493.4351   573.1455   262.4269  163.5177    780.9493\n",
      "SEMI      5   750.4908  1039.3904   486.8306  180.1790   1171.5597\n",
      "UNET      5   133.3211   163.5177    56.9792   71.3650    181.9457\n",
      "\n",
      "kruskal wallis test:\n",
      "  h statistic: 21.064\n",
      "  p value: 0.020652487355082978\n",
      "  number of methods compared: 11\n",
      "  result: significant difference found\n",
      "\n",
      "post hoc pairwise comparisons (mann whitney u with holm correction):\n",
      "technique concentration  metric   group1   group2  n1  n2     median1     median2  U_statistic  p_value  p_value_holm significant_raw significant_holm         family1         family2\n",
      "      AFM            1% AECD_nm      60% FREEHAND   5   5  231.248915  592.412178         14.0 0.841270      1.000000              No               No  Semi-automated     Traditional\n",
      "      AFM            1% AECD_nm      60%     GOLD   5   5  231.248915  550.422986         14.0 0.841270      1.000000              No               No  Semi-automated         Unknown\n",
      "      AFM            1% AECD_nm      60%  ILASTIK   5   5  231.248915  280.881858         14.0 0.834035      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm      60%     OTSU   5   5  231.248915  100.727211         20.0 0.150794      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm      60%     OVAL   5   5  231.248915  549.880681         14.0 0.841270      1.000000              No               No  Semi-automated     Traditional\n",
      "      AFM            1% AECD_nm      60%     PLAN   5   5  231.248915   71.364965         22.0 0.059327      1.000000              No               No  Semi-automated         Unknown\n",
      "      AFM            1% AECD_nm      60%   PORED2   5   5  231.248915  155.536335         16.5 0.463344      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm      60%     SAMJ   5   5  231.248915  573.145533         12.0 1.000000      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm      60%     SEMI   5   5  231.248915 1039.390401          9.0 0.547619      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm      60%     UNET   5   5  231.248915  163.517676         20.0 0.142457      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm FREEHAND     GOLD   5   5  592.412178  550.422986         17.0 0.420635      1.000000              No               No     Traditional         Unknown\n",
      "      AFM            1% AECD_nm FREEHAND  ILASTIK   5   5  592.412178  280.881858         17.0 0.401965      1.000000              No               No     Traditional  Semi-automated\n",
      "      AFM            1% AECD_nm FREEHAND     OTSU   5   5  592.412178  100.727211         20.0 0.150794      1.000000              No               No     Traditional Fully automated\n",
      "      AFM            1% AECD_nm FREEHAND     OVAL   5   5  592.412178  549.880681         12.0 1.000000      1.000000              No               No     Traditional     Traditional\n",
      "      AFM            1% AECD_nm FREEHAND     PLAN   5   5  592.412178   71.364965         22.0 0.059327      1.000000              No               No     Traditional         Unknown\n",
      "      AFM            1% AECD_nm FREEHAND   PORED2   5   5  592.412178  155.536335         18.0 0.309524      1.000000              No               No     Traditional Fully automated\n",
      "      AFM            1% AECD_nm FREEHAND     SAMJ   5   5  592.412178  573.145533         11.5 0.916563      1.000000              No               No     Traditional  Semi-automated\n",
      "      AFM            1% AECD_nm FREEHAND     SEMI   5   5  592.412178 1039.390401          6.0 0.222222      1.000000              No               No     Traditional  Semi-automated\n",
      "      AFM            1% AECD_nm FREEHAND     UNET   5   5  592.412178  163.517676         17.5 0.344267      1.000000              No               No     Traditional Fully automated\n",
      "      AFM            1% AECD_nm     GOLD  ILASTIK   5   5  550.422986  280.881858         17.0 0.401965      1.000000              No               No         Unknown  Semi-automated\n",
      "      AFM            1% AECD_nm     GOLD     OTSU   5   5  550.422986  100.727211         20.0 0.150794      1.000000              No               No         Unknown Fully automated\n",
      "      AFM            1% AECD_nm     GOLD     OVAL   5   5  550.422986  549.880681         10.0 0.690476      1.000000              No               No         Unknown     Traditional\n",
      "      AFM            1% AECD_nm     GOLD     PLAN   5   5  550.422986   71.364965         22.0 0.059327      1.000000              No               No         Unknown         Unknown\n",
      "      AFM            1% AECD_nm     GOLD   PORED2   5   5  550.422986  155.536335         17.0 0.420635      1.000000              No               No         Unknown Fully automated\n",
      "      AFM            1% AECD_nm     GOLD     SAMJ   5   5  550.422986  573.145533          8.0 0.420635      1.000000              No               No         Unknown  Semi-automated\n",
      "      AFM            1% AECD_nm     GOLD     SEMI   5   5  550.422986 1039.390401          6.0 0.222222      1.000000              No               No         Unknown  Semi-automated\n",
      "      AFM            1% AECD_nm     GOLD     UNET   5   5  550.422986  163.517676         17.0 0.401965      1.000000              No               No         Unknown Fully automated\n",
      "      AFM            1% AECD_nm  ILASTIK     OTSU   5   5  280.881858  100.727211         19.0 0.208690      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm  ILASTIK     OVAL   5   5  280.881858  549.880681          7.0 0.290347      1.000000              No               No  Semi-automated     Traditional\n",
      "      AFM            1% AECD_nm  ILASTIK     PLAN   5   5  280.881858   71.364965         20.0 0.137564      1.000000              No               No  Semi-automated         Unknown\n",
      "      AFM            1% AECD_nm  ILASTIK   PORED2   5   5  280.881858  155.536335         15.0 0.675174      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm  ILASTIK     SAMJ   5   5  280.881858  573.145533          6.0 0.208690      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm  ILASTIK     SEMI   5   5  280.881858 1039.390401          6.0 0.208690      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm  ILASTIK     UNET   5   5  280.881858  163.517676         17.0 0.388629      1.000000              No               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm     OTSU     OVAL   5   5  100.727211  549.880681          4.0 0.095238      1.000000              No               No Fully automated     Traditional\n",
      "      AFM            1% AECD_nm     OTSU     PLAN   5   5  100.727211   71.364965         19.0 0.208690      1.000000              No               No Fully automated         Unknown\n",
      "      AFM            1% AECD_nm     OTSU   PORED2   5   5  100.727211  155.536335          9.0 0.547619      1.000000              No               No Fully automated Fully automated\n",
      "      AFM            1% AECD_nm     OTSU     SAMJ   5   5  100.727211  573.145533          2.0 0.031746      1.000000             Yes               No Fully automated  Semi-automated\n",
      "      AFM            1% AECD_nm     OTSU     SEMI   5   5  100.727211 1039.390401          3.0 0.055556      1.000000              No               No Fully automated  Semi-automated\n",
      "      AFM            1% AECD_nm     OTSU     UNET   5   5  100.727211  163.517676         11.0 0.834035      1.000000              No               No Fully automated Fully automated\n",
      "      AFM            1% AECD_nm     OVAL     PLAN   5   5  549.880681   71.364965         22.5 0.045866      1.000000             Yes               No     Traditional         Unknown\n",
      "      AFM            1% AECD_nm     OVAL   PORED2   5   5  549.880681  155.536335         18.0 0.309524      1.000000              No               No     Traditional Fully automated\n",
      "      AFM            1% AECD_nm     OVAL     SAMJ   5   5  549.880681  573.145533         10.0 0.690476      1.000000              No               No     Traditional  Semi-automated\n",
      "      AFM            1% AECD_nm     OVAL     SEMI   5   5  549.880681 1039.390401          7.0 0.309524      1.000000              No               No     Traditional  Semi-automated\n",
      "      AFM            1% AECD_nm     OVAL     UNET   5   5  549.880681  163.517676         21.0 0.090688      1.000000              No               No     Traditional Fully automated\n",
      "      AFM            1% AECD_nm     PLAN   PORED2   5   5   71.364965  155.536335          0.0 0.011925      0.655888             Yes               No         Unknown Fully automated\n",
      "      AFM            1% AECD_nm     PLAN     SAMJ   5   5   71.364965  573.145533          0.0 0.011925      0.655888             Yes               No         Unknown  Semi-automated\n",
      "      AFM            1% AECD_nm     PLAN     SEMI   5   5   71.364965 1039.390401          0.0 0.011925      0.655888             Yes               No         Unknown  Semi-automated\n",
      "      AFM            1% AECD_nm     PLAN     UNET   5   5   71.364965  163.517676          5.0 0.137564      1.000000              No               No         Unknown Fully automated\n",
      "      AFM            1% AECD_nm   PORED2     SAMJ   5   5  155.536335  573.145533          2.0 0.031746      1.000000             Yes               No Fully automated  Semi-automated\n",
      "      AFM            1% AECD_nm   PORED2     SEMI   5   5  155.536335 1039.390401          2.0 0.031746      1.000000             Yes               No Fully automated  Semi-automated\n",
      "      AFM            1% AECD_nm   PORED2     UNET   5   5  155.536335  163.517676         16.0 0.529619      1.000000              No               No Fully automated Fully automated\n",
      "      AFM            1% AECD_nm     SAMJ     SEMI   5   5  573.145533 1039.390401          8.0 0.420635      1.000000              No               No  Semi-automated  Semi-automated\n",
      "      AFM            1% AECD_nm     SAMJ     UNET   5   5  573.145533  163.517676         22.5 0.045866      1.000000             Yes               No  Semi-automated Fully automated\n",
      "      AFM            1% AECD_nm     SEMI     UNET   5   5 1039.390401  163.517676         24.0 0.021177      1.000000             Yes               No  Semi-automated Fully automated\n",
      "\n",
      "\n",
      "analyzing: AFM 2%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 32\n",
      "number of replicates: 3\n",
      "number of methods: 11\n",
      "\n",
      "observations per method:\n",
      "method\n",
      "60%         3\n",
      "FREEHAND    3\n",
      "GOLD        3\n",
      "ILASTIK     3\n",
      "OTSU        3\n",
      "OVAL        3\n",
      "PLAN        3\n",
      "PORED2      3\n",
      "SAMJ        2\n",
      "SEMI        3\n",
      "UNET        3\n",
      "dtype: int64\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "          n      mean    median       std       min       max\n",
      "method                                                       \n",
      "60%       3   79.9709   87.4039   52.7944   23.8539  128.6550\n",
      "FREEHAND  3  217.4342  142.7299  146.2648  123.6077  385.9651\n",
      "GOLD      3  198.4138  140.4638  148.7092   87.4039  367.3736\n",
      "ILASTIK   3   78.6248   61.8039   39.3670   50.4627  123.6077\n",
      "OTSU      3   26.2717   26.2673    9.4085   16.8654   35.6825\n",
      "OVAL      3  245.3741  138.1977  218.7094  100.9253  496.9995\n",
      "PLAN      3   19.2406   18.5720    7.6711   11.9256   27.2241\n",
      "PORED2    3  126.4299   61.8039  121.8894   50.4627  267.0232\n",
      "SAMJ      2  273.7070  273.7070  120.0569  188.8139  358.6001\n",
      "SEMI      3  312.3855  304.8713  156.7008  159.5769  472.7082\n",
      "UNET      3   75.6338   35.6825   69.1977   35.6825  155.5363\n",
      "\n",
      "kruskal wallis test:\n",
      "  h statistic: 21.659\n",
      "  p value: 0.016941198392378905\n",
      "  number of methods compared: 11\n",
      "  result: significant difference found\n",
      "\n",
      "post hoc pairwise comparisons (mann whitney u with holm correction):\n",
      "technique concentration  metric   group1   group2  n1  n2    median1    median2  U_statistic  p_value  p_value_holm significant_raw significant_holm         family1         family2\n",
      "      AFM            2% AECD_nm      60% FREEHAND   3   3  87.403874 142.729929          1.0 0.200000           1.0              No               No  Semi-automated     Traditional\n",
      "      AFM            2% AECD_nm      60%     GOLD   3   3  87.403874 140.463795          1.5 0.268286           1.0              No               No  Semi-automated         Unknown\n",
      "      AFM            2% AECD_nm      60%  ILASTIK   3   3  87.403874  61.803872          5.0 1.000000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm      60%     OTSU   3   3  87.403874  26.267252          7.0 0.400000           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm      60%     OVAL   3   3  87.403874 138.197660          1.0 0.200000           1.0              No               No  Semi-automated     Traditional\n",
      "      AFM            2% AECD_nm      60%     PLAN   3   3  87.403874  18.572038          8.0 0.200000           1.0              No               No  Semi-automated         Unknown\n",
      "      AFM            2% AECD_nm      60%   PORED2   3   3  87.403874  61.803872          4.0 1.000000           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm      60%     SAMJ   3   2  87.403874 273.707032          0.0 0.200000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm      60%     SEMI   3   3  87.403874 304.871263          0.0 0.100000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm      60%     UNET   3   3  87.403874  35.682482          4.0 1.000000           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm FREEHAND     GOLD   3   3 142.729929 140.463795          6.0 0.700000           1.0              No               No     Traditional         Unknown\n",
      "      AFM            2% AECD_nm FREEHAND  ILASTIK   3   3 142.729929  61.803872          8.5 0.121183           1.0              No               No     Traditional  Semi-automated\n",
      "      AFM            2% AECD_nm FREEHAND     OTSU   3   3 142.729929  26.267252          9.0 0.100000           1.0              No               No     Traditional Fully automated\n",
      "      AFM            2% AECD_nm FREEHAND     OVAL   3   3 142.729929 138.197660          5.0 1.000000           1.0              No               No     Traditional     Traditional\n",
      "      AFM            2% AECD_nm FREEHAND     PLAN   3   3 142.729929  18.572038          9.0 0.100000           1.0              No               No     Traditional         Unknown\n",
      "      AFM            2% AECD_nm FREEHAND   PORED2   3   3 142.729929  61.803872          7.0 0.400000           1.0              No               No     Traditional Fully automated\n",
      "      AFM            2% AECD_nm FREEHAND     SAMJ   3   2 142.729929 273.707032          2.0 0.800000           1.0              No               No     Traditional  Semi-automated\n",
      "      AFM            2% AECD_nm FREEHAND     SEMI   3   3 142.729929 304.871263          2.0 0.400000           1.0              No               No     Traditional  Semi-automated\n",
      "      AFM            2% AECD_nm FREEHAND     UNET   3   3 142.729929  35.682482          7.0 0.375825           1.0              No               No     Traditional Fully automated\n",
      "      AFM            2% AECD_nm     GOLD  ILASTIK   3   3 140.463795  61.803872          8.0 0.200000           1.0              No               No         Unknown  Semi-automated\n",
      "      AFM            2% AECD_nm     GOLD     OTSU   3   3 140.463795  26.267252          9.0 0.100000           1.0              No               No         Unknown Fully automated\n",
      "      AFM            2% AECD_nm     GOLD     OVAL   3   3 140.463795 138.197660          4.0 1.000000           1.0              No               No         Unknown     Traditional\n",
      "      AFM            2% AECD_nm     GOLD     PLAN   3   3 140.463795  18.572038          9.0 0.100000           1.0              No               No         Unknown         Unknown\n",
      "      AFM            2% AECD_nm     GOLD   PORED2   3   3 140.463795  61.803872          7.0 0.400000           1.0              No               No         Unknown Fully automated\n",
      "      AFM            2% AECD_nm     GOLD     SAMJ   3   2 140.463795 273.707032          2.0 0.800000           1.0              No               No         Unknown  Semi-automated\n",
      "      AFM            2% AECD_nm     GOLD     SEMI   3   3 140.463795 304.871263          2.0 0.400000           1.0              No               No         Unknown  Semi-automated\n",
      "      AFM            2% AECD_nm     GOLD     UNET   3   3 140.463795  35.682482          7.0 0.375825           1.0              No               No         Unknown Fully automated\n",
      "      AFM            2% AECD_nm  ILASTIK     OTSU   3   3  61.803872  26.267252          9.0 0.100000           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm  ILASTIK     OVAL   3   3  61.803872 138.197660          1.0 0.200000           1.0              No               No  Semi-automated     Traditional\n",
      "      AFM            2% AECD_nm  ILASTIK     PLAN   3   3  61.803872  18.572038          9.0 0.100000           1.0              No               No  Semi-automated         Unknown\n",
      "      AFM            2% AECD_nm  ILASTIK   PORED2   3   3  61.803872  61.803872          4.0 1.000000           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm  ILASTIK     SAMJ   3   2  61.803872 273.707032          0.0 0.200000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm  ILASTIK     SEMI   3   3  61.803872 304.871263          0.0 0.100000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm  ILASTIK     UNET   3   3  61.803872  35.682482          6.0 0.657905           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm     OTSU     OVAL   3   3  26.267252 138.197660          0.0 0.100000           1.0              No               No Fully automated     Traditional\n",
      "      AFM            2% AECD_nm     OTSU     PLAN   3   3  26.267252  18.572038          6.0 0.700000           1.0              No               No Fully automated         Unknown\n",
      "      AFM            2% AECD_nm     OTSU   PORED2   3   3  26.267252  61.803872          0.0 0.100000           1.0              No               No Fully automated Fully automated\n",
      "      AFM            2% AECD_nm     OTSU     SAMJ   3   2  26.267252 273.707032          0.0 0.200000           1.0              No               No Fully automated  Semi-automated\n",
      "      AFM            2% AECD_nm     OTSU     SEMI   3   3  26.267252 304.871263          0.0 0.100000           1.0              No               No Fully automated  Semi-automated\n",
      "      AFM            2% AECD_nm     OTSU     UNET   3   3  26.267252  35.682482          1.0 0.164160           1.0              No               No Fully automated Fully automated\n",
      "      AFM            2% AECD_nm     OVAL     PLAN   3   3 138.197660  18.572038          9.0 0.100000           1.0              No               No     Traditional         Unknown\n",
      "      AFM            2% AECD_nm     OVAL   PORED2   3   3 138.197660  61.803872          7.0 0.400000           1.0              No               No     Traditional Fully automated\n",
      "      AFM            2% AECD_nm     OVAL     SAMJ   3   2 138.197660 273.707032          2.0 0.800000           1.0              No               No     Traditional  Semi-automated\n",
      "      AFM            2% AECD_nm     OVAL     SEMI   3   3 138.197660 304.871263          3.0 0.700000           1.0              No               No     Traditional  Semi-automated\n",
      "      AFM            2% AECD_nm     OVAL     UNET   3   3 138.197660  35.682482          7.0 0.375825           1.0              No               No     Traditional Fully automated\n",
      "      AFM            2% AECD_nm     PLAN   PORED2   3   3  18.572038  61.803872          0.0 0.100000           1.0              No               No         Unknown Fully automated\n",
      "      AFM            2% AECD_nm     PLAN     SAMJ   3   2  18.572038 273.707032          0.0 0.200000           1.0              No               No         Unknown  Semi-automated\n",
      "      AFM            2% AECD_nm     PLAN     SEMI   3   3  18.572038 304.871263          0.0 0.100000           1.0              No               No         Unknown  Semi-automated\n",
      "      AFM            2% AECD_nm     PLAN     UNET   3   3  18.572038  35.682482          0.0 0.076523           1.0              No               No         Unknown Fully automated\n",
      "      AFM            2% AECD_nm   PORED2     SAMJ   3   2  61.803872 273.707032          1.0 0.400000           1.0              No               No Fully automated  Semi-automated\n",
      "      AFM            2% AECD_nm   PORED2     SEMI   3   3  61.803872 304.871263          1.0 0.200000           1.0              No               No Fully automated  Semi-automated\n",
      "      AFM            2% AECD_nm   PORED2     UNET   3   3  61.803872  35.682482          7.0 0.375825           1.0              No               No Fully automated Fully automated\n",
      "      AFM            2% AECD_nm     SAMJ     SEMI   2   3 273.707032 304.871263          3.0 1.000000           1.0              No               No  Semi-automated  Semi-automated\n",
      "      AFM            2% AECD_nm     SAMJ     UNET   2   3 273.707032  35.682482          6.0 0.138641           1.0              No               No  Semi-automated Fully automated\n",
      "      AFM            2% AECD_nm     SEMI     UNET   3   3 304.871263  35.682482          9.0 0.076523           1.0              No               No  Semi-automated Fully automated\n",
      "\n",
      "\n",
      "analyzing: AFM 1.5%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 11\n",
      "number of replicates: 1\n",
      "number of methods: 11\n",
      "\n",
      "observations per method:\n",
      "method\n",
      "60%         1\n",
      "FREEHAND    1\n",
      "GOLD        1\n",
      "ILASTIK     1\n",
      "OTSU        1\n",
      "OVAL        1\n",
      "PLAN        1\n",
      "PORED2      1\n",
      "SAMJ        1\n",
      "SEMI        1\n",
      "UNET        1\n",
      "dtype: int64\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "          n      mean    median  std       min       max\n",
      "method                                                  \n",
      "60%       1  359.2977  359.2977  NaN  359.2977  359.2977\n",
      "FREEHAND  1   50.4627   50.4627  NaN   50.4627   50.4627\n",
      "GOLD      1   50.4627   50.4627  NaN   50.4627   50.4627\n",
      "ILASTIK   1  107.0474  107.0474  NaN  107.0474  107.0474\n",
      "OTSU      1   29.0171   29.0171  NaN   29.0171   29.0171\n",
      "OVAL      1   35.6825   35.6825  NaN   35.6825   35.6825\n",
      "PLAN      1   21.1913   21.1913  NaN   21.1913   21.1913\n",
      "PORED2    1   94.4070   94.4070  NaN   94.4070   94.4070\n",
      "SAMJ      1  439.5091  439.5091  NaN  439.5091  439.5091\n",
      "SEMI      1  165.3520  165.3520  NaN  165.3520  165.3520\n",
      "UNET      1   61.8039   61.8039  NaN   61.8039   61.8039\n",
      "  warning: all groups have zero variance\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: STED 0.375%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: STED 1%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 0\n",
      "number of replicates: 0\n",
      "number of methods: 0\n",
      "\n",
      "observations per method:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "Empty DataFrame\n",
      "Columns: [n, mean, median, std, min, max]\n",
      "Index: []\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: CONFOCAL 0.375%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 11\n",
      "number of replicates: 1\n",
      "number of methods: 11\n",
      "\n",
      "observations per method:\n",
      "method\n",
      "60%         1\n",
      "FREEHAND    1\n",
      "GOLD        1\n",
      "ILASTIK     1\n",
      "OTSU        1\n",
      "OVAL        1\n",
      "PLAN        1\n",
      "PORED2      1\n",
      "SAMJ        1\n",
      "SEMI        1\n",
      "UNET        1\n",
      "dtype: int64\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "          n       mean     median  std        min        max\n",
      "method                                                      \n",
      "60%       1   392.5073   392.5073  NaN   392.5073   392.5073\n",
      "FREEHAND  1   729.5301   729.5301  NaN   729.5301   729.5301\n",
      "GOLD      1   605.0257   605.0257  NaN   605.0257   605.0257\n",
      "ILASTIK   1   500.8275   500.8275  NaN   500.8275   500.8275\n",
      "OTSU      1   328.9762   328.9762  NaN   328.9762   328.9762\n",
      "OVAL      1   654.0707   654.0707  NaN   654.0707   654.0707\n",
      "PLAN      1   133.5116   133.5116  NaN   133.5116   133.5116\n",
      "PORED2    1   123.6077   123.6077  NaN   123.6077   123.6077\n",
      "SAMJ      1  1220.0070  1220.0070  NaN  1220.0070  1220.0070\n",
      "SEMI      1   505.8865   505.8865  NaN   505.8865   505.8865\n",
      "UNET      1   610.2641   610.2641  NaN   610.2641   610.2641\n",
      "  warning: all groups have zero variance\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "\n",
      "analyzing: CONFOCAL 1%\n",
      "\n",
      "data information:\n",
      "total replicate medians: 11\n",
      "number of replicates: 1\n",
      "number of methods: 11\n",
      "\n",
      "observations per method:\n",
      "method\n",
      "60%         1\n",
      "FREEHAND    1\n",
      "GOLD        1\n",
      "ILASTIK     1\n",
      "OTSU        1\n",
      "OVAL        1\n",
      "PLAN        1\n",
      "PORED2      1\n",
      "SAMJ        1\n",
      "SEMI        1\n",
      "UNET        1\n",
      "dtype: int64\n",
      "\n",
      "metric: AECD NM - comparing methods across replicate medians\n",
      "\n",
      "summary statistics by method:\n",
      "          n      mean    median  std       min       max\n",
      "method                                                  \n",
      "60%       1  451.3517  451.3517  NaN  451.3517  451.3517\n",
      "FREEHAND  1  847.7688  847.7688  NaN  847.7688  847.7688\n",
      "GOLD      1  498.9168  498.9168  NaN  498.9168  498.9168\n",
      "ILASTIK   1  369.9629  369.9629  NaN  369.9629  369.9629\n",
      "OTSU      1  332.8240  332.8240  NaN  332.8240  332.8240\n",
      "OVAL      1  714.4322  714.4322  NaN  714.4322  714.4322\n",
      "PLAN      1  142.7299  142.7299  NaN  142.7299  142.7299\n",
      "PORED2    1  136.9409  136.9409  NaN  136.9409  136.9409\n",
      "SAMJ      1  994.6392  994.6392  NaN  994.6392  994.6392\n",
      "SEMI      1  512.1385  512.1385  NaN  512.1385  512.1385\n",
      "UNET      1  620.0954  620.0954  NaN  620.0954  620.0954\n",
      "  warning: all groups have zero variance\n",
      "  cannot perform statistical test (insufficient variation or data)\n",
      "\n",
      "analysis complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell does the statistical analysis on my pore size data\n",
    "I need to prepare the data first then run tests to compare methods\n",
    "The main goal is to see if different segmentation methods give significantly different results\n",
    "\"\"\"\n",
    "\n",
    "# start with the combined dataframe from before\n",
    "metric_df = combined_pore_size_df.copy()\n",
    "\n",
    "# fix the units because some are in micrometers and i need nanometers\n",
    "metric_df['AECD_nm'] = metric_df['AECD_um'] * 1000\n",
    "\n",
    "# clean up method names because some have typos or extra spaces\n",
    "# i noticed some inconsistencies when looking at the data\n",
    "metric_df['method'] = metric_df['method'].str.upper()\n",
    "# fix the common typos i found\n",
    "metric_df['method'] = metric_df['method'].replace({'OAVL': 'OVAL', 'OAVL ': 'OVAL', 'OVL': 'OVAL'})\n",
    "metric_df['method'] = metric_df['method'].str.strip()\n",
    "\n",
    "# calculate median values for each replicate\n",
    "# this is important because each replicate has multiple measurements\n",
    "# and i want to compare replicates not individual measurements\n",
    "replicate_medians = metric_df.groupby(['technique', 'concentration', 'method', 'replicate']).agg({\n",
    "    'AECD_nm': 'median',\n",
    "    'family': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# the metric i want to analyze\n",
    "metrics = ['AECD_nm']\n",
    "\n",
    "def print_data_info(df_subset):\n",
    "    \"\"\"\n",
    "    Print basic information about the data subset\n",
    "    This helps me understand what im working with for each condition\n",
    "    \"\"\"\n",
    "    print(\"\")\n",
    "    print(\"data information:\")\n",
    "    print(\"total replicate medians: \" + str(len(df_subset)))\n",
    "    print(\"number of replicates: \" + str(df_subset['replicate'].nunique()))\n",
    "    print(\"number of methods: \" + str(df_subset['method'].nunique()))\n",
    "    print(\"\")\n",
    "    print(\"observations per method:\")\n",
    "    method_counts = df_subset.groupby('method').size()\n",
    "    print(method_counts)\n",
    "\n",
    "def perform_kruskal_wallis(df, metric, group_by='method'):\n",
    "    \"\"\"\n",
    "    Do kruskal wallis test to compare multiple groups\n",
    "    This is the nonparametric version of ANOVA which is good for my data\n",
    "    Returns the test statistic and p value\n",
    "    \"\"\"\n",
    "    # get data for each group\n",
    "    groups = []\n",
    "    for group_name, group_data in df.groupby(group_by):\n",
    "        group_values = group_data[metric].dropna().values\n",
    "        if len(group_values) > 0:\n",
    "            groups.append(group_values)\n",
    "    \n",
    "    # need at least 2 groups to compare\n",
    "    if len(groups) < 2:\n",
    "        return None, None, None\n",
    "    \n",
    "    # check if all groups have no variation\n",
    "    group_stds = []\n",
    "    for group in groups:\n",
    "        group_stds.append(group.std())\n",
    "    \n",
    "    if all(std == 0 for std in group_stds):\n",
    "        print(\"  warning: all groups have zero variance\")\n",
    "        return None, None, len(groups)\n",
    "    \n",
    "    # do the actual test\n",
    "    h_stat, p_value = kruskal(*groups)\n",
    "    return h_stat, p_value, len(groups)\n",
    "\n",
    "def calculate_summary_stats(df, metric, group_by='method'):\n",
    "    \"\"\"\n",
    "    Calculate basic statistics for each group\n",
    "    I need this to understand the data before doing tests\n",
    "    \"\"\"\n",
    "    summary = df.groupby(group_by)[metric].agg([\n",
    "        ('n', 'count'),\n",
    "        ('mean', 'mean'),\n",
    "        ('median', 'median'),\n",
    "        ('std', 'std'),\n",
    "        ('min', 'min'),\n",
    "        ('max', 'max')\n",
    "    ]).round(4)\n",
    "    return summary\n",
    "\n",
    "def holm_correction(p_values):\n",
    "    \"\"\"\n",
    "    Apply holm correction for multiple testing\n",
    "    This is more conservative than bonferroni but still controls family wise error\n",
    "    I need this because im doing multiple pairwise comparisons\n",
    "    \"\"\"\n",
    "    p_array = np.asarray(p_values, dtype=float)\n",
    "    m = len(p_array)\n",
    "    corrected = np.full(m, np.nan, dtype=float)\n",
    "    \n",
    "    # find finite p values\n",
    "    finite_mask = np.isfinite(p_array)\n",
    "    finite_vals = p_array[finite_mask]\n",
    "    \n",
    "    if len(finite_vals) == 0:\n",
    "        return corrected\n",
    "    \n",
    "    # sort and apply correction\n",
    "    sorted_idx = np.argsort(finite_vals)\n",
    "    adj_vals = np.empty_like(finite_vals)\n",
    "    running_max = 0.0\n",
    "    \n",
    "    for k, idx in enumerate(sorted_idx):\n",
    "        adj_p = (len(finite_vals) - k) * finite_vals[idx]\n",
    "        adj_p = min(adj_p, 1.0)\n",
    "        running_max = max(running_max, adj_p)\n",
    "        adj_vals[idx] = running_max\n",
    "    \n",
    "    corrected[finite_mask] = adj_vals\n",
    "    return corrected\n",
    "\n",
    "def perform_pairwise_mannwhitney(df, metric, group_by='method'):\n",
    "    \"\"\"\n",
    "    Do all pairwise comparisons using mann whitney u test\n",
    "    This is for post hoc analysis after significant kruskal wallis\n",
    "    \"\"\"\n",
    "    group_names = df[group_by].dropna().unique()\n",
    "    results = []\n",
    "    \n",
    "    # compare every pair of groups\n",
    "    for g1, g2 in combinations(group_names, 2):\n",
    "        data1 = df[df[group_by] == g1][metric].dropna().values\n",
    "        data2 = df[df[group_by] == g2][metric].dropna().values\n",
    "        \n",
    "        if len(data1) > 0 and len(data2) > 0:\n",
    "            try:\n",
    "                stat, p_value = mannwhitneyu(data1, data2, alternative='two-sided')\n",
    "                results.append({\n",
    "                    'group1': g1,\n",
    "                    'group2': g2,\n",
    "                    'n1': len(data1),\n",
    "                    'n2': len(data2),\n",
    "                    'median1': np.median(data1),\n",
    "                    'median2': np.median(data2),\n",
    "                    'U_statistic': stat,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "            except ValueError:\n",
    "                # skip if test fails\n",
    "                continue\n",
    "    \n",
    "    # make dataframe and add corrections\n",
    "    df_results = pd.DataFrame(results)\n",
    "    if len(df_results) > 0:\n",
    "        df_results['p_value_holm'] = holm_correction(df_results['p_value'])\n",
    "        \n",
    "        # check significance\n",
    "        sig_raw = []\n",
    "        sig_holm = []\n",
    "        for p in df_results['p_value']:\n",
    "            if p < 0.05:\n",
    "                sig_raw.append(\"Yes\")\n",
    "            else:\n",
    "                sig_raw.append(\"No\")\n",
    "        \n",
    "        for p in df_results['p_value_holm']:\n",
    "            if p < 0.05:\n",
    "                sig_holm.append(\"Yes\")\n",
    "            else:\n",
    "                sig_holm.append(\"No\")\n",
    "        \n",
    "        df_results['significant_raw'] = sig_raw\n",
    "        df_results['significant_holm'] = sig_holm\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# conditions i want to test\n",
    "conditions = [\n",
    "    ('CRYO-SEM', 'X3000'),\n",
    "    ('CRYO-SEM', 'X10000'),\n",
    "    ('CRYO-SEM', 'X30000'),\n",
    "    ('CRYO-SEM', 'X60000'),\n",
    "    ('AFM', '1%'),\n",
    "    ('AFM', '2%'),\n",
    "    ('AFM', '1.5%'),\n",
    "    ('STED', '0.375%'),\n",
    "    ('STED', '1%'),\n",
    "    ('CONFOCAL', '0.375%'),\n",
    "    ('CONFOCAL', '1%'),\n",
    "]\n",
    "\n",
    "# store all results for later\n",
    "all_kw_results = []\n",
    "all_pairwise_results = []\n",
    "\n",
    "# go through each condition\n",
    "for technique, concentration in conditions:\n",
    "    # filter data for this condition\n",
    "    df_subset = replicate_medians[\n",
    "        (replicate_medians['technique'] == technique) &\n",
    "        (replicate_medians['concentration'] == concentration)\n",
    "    ]\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"analyzing: \" + technique + \" \" + concentration)\n",
    "    print_data_info(df_subset)\n",
    "    \n",
    "    # analyze each metric\n",
    "    for metric in metrics:\n",
    "        print(\"\")\n",
    "        print(\"metric: \" + metric.upper().replace('_', ' ') + \" - comparing methods across replicate medians\")\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"summary statistics by method:\")\n",
    "        summary = calculate_summary_stats(df_subset, metric)\n",
    "        print(summary)\n",
    "        \n",
    "        # check if we have enough data\n",
    "        if summary['n'].min() < 1:\n",
    "            print(\"  warning: some methods have fewer than 1 observation\")\n",
    "            continue\n",
    "        \n",
    "        # do kruskal wallis test\n",
    "        h_stat, p_value, n_groups = perform_kruskal_wallis(df_subset, metric)\n",
    "        if h_stat is not None:\n",
    "            print(\"\")\n",
    "            print(\"kruskal wallis test:\")\n",
    "            print(\"  h statistic: \" + str(round(h_stat, 3)))\n",
    "            print(\"  p value: \" + str(p_value))\n",
    "            print(\"  number of methods compared: \" + str(n_groups))\n",
    "            \n",
    "            if p_value < 0.05:\n",
    "                print(\"  result: significant difference found\")\n",
    "            else:\n",
    "                print(\"  result: no significant difference\")\n",
    "            \n",
    "            # store results\n",
    "            all_kw_results.append({\n",
    "                'technique': technique,\n",
    "                'concentration': concentration,\n",
    "                'metric': metric,\n",
    "                'H_statistic': h_stat,\n",
    "                'p_value': p_value,\n",
    "                'n_methods': n_groups\n",
    "            })\n",
    "            \n",
    "            # do post hoc tests if significant and more than 2 groups\n",
    "            if p_value < 0.05 and n_groups > 2:\n",
    "                print(\"\")\n",
    "                print(\"post hoc pairwise comparisons (mann whitney u with holm correction):\")\n",
    "                pairwise_results = perform_pairwise_mannwhitney(df_subset, metric)\n",
    "                if len(pairwise_results) > 0:\n",
    "                    # add family information\n",
    "                    family_map = df_subset.set_index('method')['family'].to_dict()\n",
    "                    pairwise_results['family1'] = pairwise_results['group1'].map(family_map)\n",
    "                    pairwise_results['family2'] = pairwise_results['group2'].map(family_map)\n",
    "                    pairwise_results.insert(0, 'technique', technique)\n",
    "                    pairwise_results.insert(1, 'concentration', concentration)\n",
    "                    pairwise_results.insert(2, 'metric', metric)\n",
    "                    all_pairwise_results.append(pairwise_results)\n",
    "                    print(pairwise_results.to_string(index=False))\n",
    "        else:\n",
    "            print(\"  cannot perform statistical test (insufficient variation or data)\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b5854-de5a-461c-af81-2bd1931aa6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pore-acc (NumPy 1.26)",
   "language": "python",
   "name": "pore-acc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
