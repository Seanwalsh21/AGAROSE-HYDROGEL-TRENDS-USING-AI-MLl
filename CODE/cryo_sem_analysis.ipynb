{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c79d0eb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CODE\n",
            "60%: Dice=0.717 IoU=0.559 Bias=20.33% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\60%_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\60%_metrics.csv\n",
            "FREEHAND: Dice=0.610 IoU=0.439 Bias=-11.81% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\FREEHAND_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\FREEHAND_metrics.csv\n",
            "ILASTIK: Dice=0.723 IoU=0.567 Bias=-5.10% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\ILASTIK_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\ILASTIK_metrics.csv\n",
            "OTSU: Dice=0.624 IoU=0.453 Bias=-8.47% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OTSU_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OTSU_metrics.csv\n",
            "OVAL: Dice=0.653 IoU=0.484 Bias=-2.66% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVAL_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVAL_metrics.csv\n",
            "PLANKSTER: Dice=0.579 IoU=0.407 Bias=-16.90% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\PLANKSTER_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\PLANKSTER_metrics.csv\n",
            "PORED2: Dice=0.655 IoU=0.487 Bias=23.37% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\PORED2_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\PORED2_metrics.csv\n",
            "SAMJ: Dice=0.207 IoU=0.115 Bias=-35.13% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\SAMJ_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\SAMJ_metrics.csv\n",
            "SEMI: Dice=0.411 IoU=0.258 Bias=-28.41% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\SEMI_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\SEMI_metrics.csv\n",
            "UNET: Dice=0.657 IoU=0.490 Bias=1.62% -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\UNET_overlay.tif / c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\UNET_metrics.csv\n",
            "metrics_summary.csv -> c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\metrics_summary.csv\n",
            "saved: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\cryo_sem_analysis.py\n",
            "saved: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\cryo_sem_analysis.ipynb\n",
            "overlays and per-method metrics saved in: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import binary_erosion\n",
        "import os\n",
        "from pathlib import Path\n",
        "notebook_dir = Path.cwd()\n",
        "print('original',notebook_dir)\n",
        "proj_root = notebook_dir.parent\n",
        "BASE_DIR = str(proj_root / \"CRYO-SEM DATA\" / \"CRYO-SEM X30000\" / \"CRYO-SEM X30000 [1]\")\n",
        "\n",
        "# This script:\n",
        "# 1. Reads GOLD STANDARD.tif and each method .tif from BASE_DIR\n",
        "# 2. Converts them to binary pore masks (1=pore, 0=background)\n",
        "# 3. Calculates Dice, IoU, MCC, etc.\n",
        "# 4. Measures pore fraction and pore area in µm²\n",
        "# 5. Saves:\n",
        "#       - per-method overlay TIFFs\n",
        "#       - per-method CSVs\n",
        "#       - one summary CSV for all methods\n",
        "#       - a copy of this code (.py)\n",
        "#       - a minimal notebook (.ipynb)\n",
        "#\n",
        "# All outputs go into your GitHub repo folder.\n",
        "\n",
        "# BASE_DIR = r\"C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM DATA\\CRYO-SEM X30000\\CRYO-SEM X30000 [1]\"\n",
        "GT_FILENAME = \"GOLD STANDARD.tif\"\n",
        "\n",
        "GITHUB_DIR = proj_root\n",
        "GITHUB_DIR = str(GITHUB_DIR)\n",
        "os.makedirs(GITHUB_DIR, exist_ok=True)\n",
        "\n",
        "METRICS_CSV = os.path.join(GITHUB_DIR, \"metrics_summary.csv\")\n",
        "\n",
        "# pixel calibration: 640 x 480 image covers 5.98 µm x 4.49 µm\n",
        "PIX_SIZE_X_UM = 5.98 / 640.0\n",
        "PIX_SIZE_Y_UM = 4.49 / 480.0\n",
        "PIX_AREA_UM2  = PIX_SIZE_X_UM * PIX_SIZE_Y_UM\n",
        "\n",
        "\n",
        "def _read_tiff_any(path):\n",
        "    \"\"\"Read a TIFF from disk using Pillow. Return as numpy array.\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        return None\n",
        "    with Image.open(path) as im:\n",
        "        im.load()\n",
        "        # convert to grayscale 16-bit or 8-bit\n",
        "        if \"I;16\" in im.mode:\n",
        "            im = im.convert(\"I;16\")\n",
        "        else:\n",
        "            im = im.convert(\"L\")\n",
        "        arr = np.array(im)\n",
        "    return arr\n",
        "\n",
        "\n",
        "def _to_gray(arr):\n",
        "    \"\"\"Ensure we have a single 2D grayscale array.\"\"\"\n",
        "    if arr is None:\n",
        "        return None\n",
        "    if arr.ndim == 2:\n",
        "        return arr\n",
        "    if arr.ndim == 3:\n",
        "        # if RGB slipped in, average channels\n",
        "        if arr.shape[2] >= 3:\n",
        "            return np.mean(arr[:, :, :3], axis=2).astype(arr.dtype)\n",
        "        else:\n",
        "            return arr[:, :, 0]\n",
        "    return arr\n",
        "\n",
        "\n",
        "def _ensure_uint(arr):\n",
        "    \"\"\"Force array into uint8 or uint16, for consistent thresholding.\"\"\"\n",
        "    if arr.dtype == np.uint8 or arr.dtype == np.uint16:\n",
        "        return arr\n",
        "\n",
        "    if np.issubdtype(arr.dtype, np.floating):\n",
        "        a_min = float(arr.min())\n",
        "        a_max = float(arr.max())\n",
        "        rng = (a_max - a_min) + 1e-12\n",
        "        scaled = (arr - a_min) / rng\n",
        "        scaled = (scaled * 255.0 + 0.5).astype(np.uint8)\n",
        "        return scaled\n",
        "\n",
        "    maxv = float(arr.max())\n",
        "    if maxv > 255.0:\n",
        "        return arr.astype(np.uint16)\n",
        "    return arr.astype(np.uint8)\n",
        "\n",
        "\n",
        "def otsu_thresh_uint8(gray_u8):\n",
        "    \"\"\"Manual Otsu threshold. Returns mask of dark pixels as 1.\"\"\"\n",
        "    hist = np.bincount(gray_u8.flatten(), minlength=256).astype(float)\n",
        "    total = gray_u8.size\n",
        "    prob = hist / float(total)\n",
        "\n",
        "    cum_prob = np.cumsum(prob)\n",
        "    cum_mean = np.cumsum(prob * np.arange(256))\n",
        "    global_mean = cum_mean[-1]\n",
        "\n",
        "    best_t = 0\n",
        "    best_score = -1.0\n",
        "\n",
        "    for t in range(256):\n",
        "        w0 = cum_prob[t]\n",
        "        w1 = 1.0 - w0\n",
        "        if w0 == 0.0 or w1 == 0.0:\n",
        "            continue\n",
        "        mu0 = cum_mean[t] / w0\n",
        "        mu1 = (global_mean - cum_mean[t]) / w1\n",
        "        diff = mu0 - mu1\n",
        "        score = w0 * w1 * diff * diff\n",
        "        if score > best_score:\n",
        "            best_score = score\n",
        "            best_t = t\n",
        "\n",
        "    # pores are darker, so <= threshold is pore\n",
        "    mask_dark = (gray_u8 <= best_t).astype(np.uint8)\n",
        "    return mask_dark\n",
        "\n",
        "\n",
        "def binarize_pores_black(img_gray):\n",
        "    \"\"\"Make a binary mask where pores (dark) are 1 and background is 0.\"\"\"\n",
        "    g = _ensure_uint(img_gray)\n",
        "    uvals = np.unique(g)\n",
        "\n",
        "    # common case where the mask is already binary grayscale\n",
        "    if uvals.size == 2:\n",
        "        darker = int(uvals[0])\n",
        "        pores = (g == darker)\n",
        "        return pores.astype(np.uint8)\n",
        "\n",
        "    # not binary already: do Otsu on 8-bit version\n",
        "    if g.dtype == np.uint16:\n",
        "        g8 = (g / 257).astype(np.uint8)\n",
        "    else:\n",
        "        g8 = g.astype(np.uint8)\n",
        "\n",
        "    pores = otsu_thresh_uint8(g8)\n",
        "    return pores\n",
        "\n",
        "\n",
        "def read_mask_as_binary(path):\n",
        "    \"\"\"Load tiff, turn into a binary pore mask (0/1).\"\"\"\n",
        "    raw = _read_tiff_any(path)\n",
        "    if raw is None:\n",
        "        raise FileNotFoundError(\"Cannot read TIFF: \" + path)\n",
        "    gray = _to_gray(raw)\n",
        "    if gray is None or gray.ndim != 2:\n",
        "        raise ValueError(\"Not single-channel grayscale: \" + path)\n",
        "    return binarize_pores_black(gray)\n",
        "\n",
        "\n",
        "def _safe_div(n, d):\n",
        "    if d == 0:\n",
        "        return 0.0\n",
        "    return float(n) / float(d)\n",
        "\n",
        "\n",
        "def calc_confusion(gt, pr):\n",
        "    \"\"\"Return tp, fp, tn, fn for two binary masks.\"\"\"\n",
        "    gt = gt.astype(np.uint8)\n",
        "    pr = pr.astype(np.uint8)\n",
        "\n",
        "    tp = int(np.sum((gt == 1) & (pr == 1)))\n",
        "    tn = int(np.sum((gt == 0) & (pr == 0)))\n",
        "    fp = int(np.sum((gt == 0) & (pr == 1)))\n",
        "    fn = int(np.sum((gt == 1) & (pr == 0)))\n",
        "\n",
        "    return tp, fp, tn, fn\n",
        "\n",
        "\n",
        "def compute_metrics(gt, pr):\n",
        "    \"\"\"Return a dict of Dice, IoU, MCC, etc.\"\"\"\n",
        "    tp, fp, tn, fn = calc_confusion(gt, pr)\n",
        "\n",
        "    acc  = _safe_div(tp + tn, tp + tn + fp + fn)\n",
        "    prec = _safe_div(tp, tp + fp)\n",
        "    rec  = _safe_div(tp, tp + fn)\n",
        "    spec = _safe_div(tn, tn + fp)\n",
        "    ba   = 0.5 * (rec + spec)\n",
        "    dice = _safe_div(2 * tp, 2 * tp + fp + fn)\n",
        "    iou  = _safe_div(tp, tp + fp + fn)\n",
        "\n",
        "    # MCC denominator\n",
        "    prod_val = float((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
        "    if prod_val > 0.0:\n",
        "        den = prod_val ** 0.5\n",
        "    else:\n",
        "        den = 0.0\n",
        "    if den > 0.0:\n",
        "        mcc_val = (tp * tn - fp * fn) / den\n",
        "    else:\n",
        "        mcc_val = 0.0\n",
        "\n",
        "    out = {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"specificity\": spec,\n",
        "        \"balanced_accuracy\": ba,\n",
        "        \"f1_dice\": dice,\n",
        "        \"iou_jaccard\": iou,\n",
        "        \"mcc\": mcc_val,\n",
        "        \"TP\": tp,\n",
        "        \"FP\": fp,\n",
        "        \"TN\": tn,\n",
        "        \"FN\": fn\n",
        "    }\n",
        "    return out\n",
        "\n",
        "\n",
        "def pore_fraction(mask):\n",
        "    \"\"\"Fraction of pixels that are pore=1.\"\"\"\n",
        "    return float(np.mean(mask))\n",
        "\n",
        "\n",
        "def pore_area_um2(mask):\n",
        "    \"\"\"Total pore area in square microns.\"\"\"\n",
        "    pore_px = int(np.sum(mask == 1))\n",
        "    return pore_px * PIX_AREA_UM2\n",
        "\n",
        "\n",
        "def make_pil_overlay(gt_mask, pr_mask, save_path):\n",
        "    \"\"\"\n",
        "    Make an overlay using Pillow .paste(mask=...),\n",
        "    similar to the GeeksforGeeks example.\n",
        "\n",
        "    Colors:\n",
        "      red   = false positive (pred says pore, GT says no pore)\n",
        "      blue  = false negative (pred missed pore GT has)\n",
        "      green = outline of true positive\n",
        "    \"\"\"\n",
        "    base_gray = (1 - gt_mask) * 255.0\n",
        "    base_gray = base_gray.astype(np.uint8)\n",
        "    base_img = Image.fromarray(base_gray, mode=\"L\").convert(\"RGBA\")\n",
        "\n",
        "    h, w = gt_mask.shape\n",
        "\n",
        "    # false positives\n",
        "    fp_mask = ((gt_mask == 0) & (pr_mask == 1)).astype(np.uint8) * 255\n",
        "    red_img = Image.new(\"RGBA\", (w, h), (255, 0, 0, 180))\n",
        "    red_mask = Image.fromarray(fp_mask.astype(np.uint8), mode=\"L\")\n",
        "    base_img.paste(red_img, (0, 0), mask=red_mask)\n",
        "\n",
        "    # false negatives\n",
        "    fn_mask = ((gt_mask == 1) & (pr_mask == 0)).astype(np.uint8) * 255\n",
        "    blue_img = Image.new(\"RGBA\", (w, h), (0, 0, 255, 180))\n",
        "    blue_mask = Image.fromarray(fn_mask.astype(np.uint8), mode=\"L\")\n",
        "    base_img.paste(blue_img, (0, 0), mask=blue_mask)\n",
        "\n",
        "    # true positives, outline only\n",
        "    tp_region = ((gt_mask == 1) & (pr_mask == 1)).astype(np.uint8)\n",
        "    tp_eroded = binary_erosion(tp_region, border_value=0)\n",
        "    tp_edge = tp_region.astype(np.uint8) - tp_eroded.astype(np.uint8)\n",
        "    tp_edge_mask = (tp_edge > 0).astype(np.uint8) * 255\n",
        "\n",
        "    green_img = Image.new(\"RGBA\", (w, h), (0, 255, 0, 255))\n",
        "    green_mask = Image.fromarray(tp_edge_mask.astype(np.uint8), mode=\"L\")\n",
        "    base_img.paste(green_img, (0, 0), mask=green_mask)\n",
        "\n",
        "    # save RGB TIFF\n",
        "    final_rgb = base_img.convert(\"RGB\")\n",
        "    final_rgb.save(save_path, format=\"TIFF\")\n",
        "    return save_path\n",
        "\n",
        "\n",
        "def write_notebook_copy(code_text, ipynb_out_path):\n",
        "    \"\"\"Save a tiny 1-cell .ipynb that just contains this script.\"\"\"\n",
        "    nb_obj = {\n",
        "        \"cells\": [\n",
        "            {\n",
        "                \"cell_type\": \"code\",\n",
        "                \"execution_count\": None,\n",
        "                \"metadata\": {},\n",
        "                \"outputs\": [],\n",
        "                \"source\": code_text.splitlines(True)\n",
        "            }\n",
        "        ],\n",
        "        \"metadata\": {\n",
        "            \"language_info\": {\"name\": \"python\"},\n",
        "            \"kernelspec\": {\n",
        "                \"display_name\": \"Python\",\n",
        "                \"language\": \"python\",\n",
        "                \"name\": \"python\"\n",
        "            }\n",
        "        },\n",
        "        \"nbformat\": 4,\n",
        "        \"nbformat_minor\": 5\n",
        "    }\n",
        "\n",
        "    with open(ipynb_out_path, \"w\", encoding=\"utf-8\") as f_out:\n",
        "        json.dump(nb_obj, f_out, indent=2)\n",
        "\n",
        "\n",
        "def write_single_method_csv(row_dict, repo_dir):\n",
        "    \"\"\"\n",
        "    Save metrics for a single method as <method>_metrics.csv\n",
        "    so each method is traceable in Git.\n",
        "    \"\"\"\n",
        "    method_name = row_dict[\"method\"]\n",
        "    out_path = os.path.join(repo_dir, method_name + \"_metrics.csv\")\n",
        "\n",
        "    cols = [\n",
        "        \"method\",\n",
        "        \"f1_dice\",\n",
        "        \"iou_jaccard\",\n",
        "        \"mcc\",\n",
        "        \"precision\",\n",
        "        \"recall\",\n",
        "        \"specificity\",\n",
        "        \"balanced_accuracy\",\n",
        "        \"accuracy\",\n",
        "        \"TP\",\n",
        "        \"FP\",\n",
        "        \"TN\",\n",
        "        \"FN\",\n",
        "        \"gt_pore_fraction\",\n",
        "        \"pred_pore_fraction\",\n",
        "        \"pore_fraction_bias\",\n",
        "        \"gt_pore_area_um2\",\n",
        "        \"pred_pore_area_um2\",\n",
        "        \"pore_area_bias_um2\"\n",
        "    ]\n",
        "\n",
        "    with open(out_path, \"w\", newline=\"\", encoding=\"utf-8\") as f_one:\n",
        "        w = csv.DictWriter(f_one, fieldnames=cols)\n",
        "        w.writeheader()\n",
        "        w.writerow(row_dict)\n",
        "\n",
        "    return out_path\n",
        "\n",
        "\n",
        "def analyze_folder(folder, repo_dir, code_text):\n",
        "    \"\"\"\n",
        "    Do the full run:\n",
        "    - read GT\n",
        "    - loop over each method .tif\n",
        "    - compute metrics and pore stats\n",
        "    - save overlay.tif\n",
        "    - save <method>_metrics.csv\n",
        "    - save metrics_summary.csv\n",
        "    - save cryo_sem_analysis.py and cryo_sem_analysis.ipynb\n",
        "    \"\"\"\n",
        "\n",
        "    gt_path = os.path.join(folder, GT_FILENAME)\n",
        "    if not os.path.exists(gt_path):\n",
        "        raise FileNotFoundError(\"Ground truth not found: \" + gt_path)\n",
        "\n",
        "    gt_mask = read_mask_as_binary(gt_path)\n",
        "\n",
        "    all_rows = []\n",
        "\n",
        "    for fname in os.listdir(folder):\n",
        "        low = fname.lower()\n",
        "        if not (low.endswith(\".tif\") or low.endswith(\".tiff\")):\n",
        "            continue\n",
        "        if fname == GT_FILENAME:\n",
        "            continue\n",
        "\n",
        "        pr_path = os.path.join(folder, fname)\n",
        "        pr_mask = read_mask_as_binary(pr_path)\n",
        "\n",
        "        if gt_mask.shape != pr_mask.shape:\n",
        "            raise ValueError(\"Shape mismatch: GT \" + str(gt_mask.shape) +\n",
        "                             \" vs \" + fname + \" \" + str(pr_mask.shape))\n",
        "\n",
        "        m = compute_metrics(gt_mask, pr_mask)\n",
        "\n",
        "        gt_frac = pore_fraction(gt_mask)\n",
        "        pr_frac = pore_fraction(pr_mask)\n",
        "        frac_bias = pr_frac - gt_frac\n",
        "\n",
        "        gt_area = pore_area_um2(gt_mask)\n",
        "        pr_area = pore_area_um2(pr_mask)\n",
        "        area_bias = pr_area - gt_area\n",
        "\n",
        "        method_name = os.path.splitext(fname)[0]\n",
        "\n",
        "        overlay_file = os.path.join(repo_dir, method_name + \"_overlay.tif\")\n",
        "        make_pil_overlay(gt_mask, pr_mask, overlay_file)\n",
        "\n",
        "        row = {\n",
        "            \"method\": method_name,\n",
        "            \"f1_dice\": m[\"f1_dice\"],\n",
        "            \"iou_jaccard\": m[\"iou_jaccard\"],\n",
        "            \"mcc\": m[\"mcc\"],\n",
        "            \"precision\": m[\"precision\"],\n",
        "            \"recall\": m[\"recall\"],\n",
        "            \"specificity\": m[\"specificity\"],\n",
        "            \"balanced_accuracy\": m[\"balanced_accuracy\"],\n",
        "            \"accuracy\": m[\"accuracy\"],\n",
        "            \"TP\": m[\"TP\"],\n",
        "            \"FP\": m[\"FP\"],\n",
        "            \"TN\": m[\"TN\"],\n",
        "            \"FN\": m[\"FN\"],\n",
        "            \"gt_pore_fraction\": gt_frac,\n",
        "            \"pred_pore_fraction\": pr_frac,\n",
        "            \"pore_fraction_bias\": frac_bias,\n",
        "            \"gt_pore_area_um2\": gt_area,\n",
        "            \"pred_pore_area_um2\": pr_area,\n",
        "            \"pore_area_bias_um2\": area_bias\n",
        "        }\n",
        "\n",
        "        all_rows.append(row)\n",
        "\n",
        "        single_csv_path = write_single_method_csv(row, repo_dir)\n",
        "\n",
        "        print(method_name + \": Dice=%.3f IoU=%.3f Bias=%.2f%% -> %s / %s\"\n",
        "              % (m[\"f1_dice\"], m[\"iou_jaccard\"],\n",
        "                 frac_bias * 100.0, overlay_file, single_csv_path))\n",
        "\n",
        "    # now write combined CSV for all methods\n",
        "    if len(all_rows) > 0:\n",
        "        fieldnames = [\n",
        "            \"method\",\n",
        "            \"f1_dice\",\n",
        "            \"iou_jaccard\",\n",
        "            \"mcc\",\n",
        "            \"precision\",\n",
        "            \"recall\",\n",
        "            \"specificity\",\n",
        "            \"balanced_accuracy\",\n",
        "            \"accuracy\",\n",
        "            \"TP\",\n",
        "            \"FP\",\n",
        "            \"TN\",\n",
        "            \"FN\",\n",
        "            \"gt_pore_fraction\",\n",
        "            \"pred_pore_fraction\",\n",
        "            \"pore_fraction_bias\",\n",
        "            \"gt_pore_area_um2\",\n",
        "            \"pred_pore_area_um2\",\n",
        "            \"pore_area_bias_um2\"\n",
        "        ]\n",
        "    else:\n",
        "        fieldnames = []\n",
        "\n",
        "    with open(METRICS_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f_all:\n",
        "        w_all = csv.DictWriter(f_all, fieldnames=fieldnames)\n",
        "        w_all.writeheader()\n",
        "        for r in all_rows:\n",
        "            w_all.writerow(r)\n",
        "\n",
        "    print(\"metrics_summary.csv -> \" + METRICS_CSV)\n",
        "\n",
        "    # save a copy of the code and a notebook version into the repo\n",
        "    script_path_out = os.path.join(repo_dir, \"cryo_sem_analysis.py\")\n",
        "    nb_path_out     = os.path.join(repo_dir, \"cryo_sem_analysis.ipynb\")\n",
        "\n",
        "    with open(script_path_out, \"w\", encoding=\"utf-8\") as f_py:\n",
        "        f_py.write(code_text)\n",
        "\n",
        "    write_notebook_copy(code_text, nb_path_out)\n",
        "\n",
        "    print(\"saved: \" + script_path_out)\n",
        "    print(\"saved: \" + nb_path_out)\n",
        "    print(\"overlays and per-method metrics saved in: \" + repo_dir)\n",
        "\n",
        "\n",
        "# run it immediately when this script is executed\n",
        "analyze_folder(BASE_DIR, GITHUB_DIR, \"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cbce5309",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "original c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CODE\n",
            "60%: Dice=0.717 IoU=0.559 Bias=20.33%\n",
            "FREEHAND: Dice=0.61 IoU=0.439 Bias=-11.81%\n",
            "ILASTIK: Dice=0.723 IoU=0.567 Bias=-5.1%\n",
            "OTSU: Dice=0.624 IoU=0.453 Bias=-8.47%\n",
            "OVAL: Dice=0.653 IoU=0.484 Bias=-2.66%\n",
            "PLANKSTER: Dice=0.579 IoU=0.407 Bias=-16.9%\n",
            "PORED2: Dice=0.655 IoU=0.487 Bias=23.37%\n",
            "SAMJ: Dice=0.207 IoU=0.115 Bias=-35.13%\n",
            "SEMI: Dice=0.411 IoU=0.258 Bias=-28.41%\n",
            "UNET: Dice=0.657 IoU=0.49 Bias=1.62%\n",
            "Summary CSV saved: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVERLAYS\\metrics_summary.csv\n",
            "Code saved: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVERLAYS\\pore_analysis.py\n",
            "Notebook saved: c:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVERLAYS\\pore_analysis.ipynb\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.ndimage import binary_erosion\n",
        "import math\n",
        "import os\n",
        "from pathlib import Path\n",
        "notebook_dir = Path.cwd()\n",
        "print('original',notebook_dir)\n",
        "proj_root = notebook_dir.parent\n",
        "BASE_DIR = str(proj_root / \"CRYO-SEM DATA\" / \"CRYO-SEM X30000\" / \"CRYO-SEM X30000 [1]\")\n",
        "\n",
        "# script to compare different pore detection methods against gold standard\n",
        "# loads images, makes binary masks, calculates accuracy metrics\n",
        "# saves overlay images and CSV files with results\n",
        "\n",
        "#data_folder = r\"C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\CRYO-SEM DATA\\CRYO-SEM X30000\\CRYO-SEM X30000 [1]\"\n",
        "data_folder = BASE_DIR\n",
        "gold_standard_file = \"GOLD STANDARD.tif\"\n",
        "\n",
        "#output_folder = r\"C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\OVERLAYS\"\n",
        "output_folder = os.path.join(proj_root,'OVERLAYS')\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "summary_csv_file = os.path.join(output_folder, \"metrics_summary.csv\")\n",
        "\n",
        "# image size is 640x480 pixels covering 5.98 x 4.49 micrometers\n",
        "pixel_width_um = 5.98 / 640.0\n",
        "pixel_height_um = 4.49 / 480.0\n",
        "pixel_area_um2 = pixel_width_um * pixel_height_um\n",
        "\n",
        "def load_tiff_image(file_path):\n",
        "    \"\"\"load a tiff file and return as numpy array\"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        return None\n",
        "    \n",
        "    image = Image.open(file_path)\n",
        "    # convert to grayscale\n",
        "    if \"I;16\" in image.mode:\n",
        "        image = image.convert(\"I;16\")\n",
        "    else:\n",
        "        image = image.convert(\"L\")\n",
        "    \n",
        "    array_data = np.array(image)\n",
        "    image.close()\n",
        "    return array_data\n",
        "\n",
        "def make_grayscale(image_array):\n",
        "    \"\"\"make sure image is 2D grayscale\"\"\"\n",
        "    if image_array is None:\n",
        "        return None\n",
        "    if len(image_array.shape) == 2:\n",
        "        return image_array\n",
        "    if len(image_array.shape) == 3:\n",
        "        # if color image, average the channels\n",
        "        if image_array.shape[2] >= 3:\n",
        "            gray_image = np.mean(image_array[:, :, :3], axis=2)\n",
        "            return gray_image.astype(image_array.dtype)\n",
        "        else:\n",
        "            return image_array[:, :, 0]\n",
        "    return image_array\n",
        "\n",
        "def convert_to_uint8(image_array):\n",
        "    \"\"\"convert image to 8-bit format for processing\"\"\"\n",
        "    if image_array.dtype == np.uint8:\n",
        "        return image_array\n",
        "    \n",
        "    # if floating point values, scale to 0-255\n",
        "    if np.issubdtype(image_array.dtype, np.floating):\n",
        "        min_val = float(image_array.min())\n",
        "        max_val = float(image_array.max())\n",
        "        range_val = max_val - min_val\n",
        "        if range_val > 0:\n",
        "            scaled = (image_array - min_val) / range_val\n",
        "            scaled = (scaled * 255.0).astype(np.uint8)\n",
        "            return scaled\n",
        "        else:\n",
        "            return np.zeros_like(image_array, dtype=np.uint8)\n",
        "    \n",
        "    # if 16-bit, scale down to 8-bit\n",
        "    if image_array.dtype == np.uint16:\n",
        "        scaled = (image_array / 257).astype(np.uint8)\n",
        "        return scaled\n",
        "    \n",
        "    return image_array.astype(np.uint8)\n",
        "\n",
        "def find_threshold_otsu(gray_image):\n",
        "    \"\"\"find best threshold using otsu method\"\"\"\n",
        "    # count how many pixels at each brightness level\n",
        "    histogram = np.bincount(gray_image.flatten(), minlength=256)\n",
        "    total_pixels = gray_image.size\n",
        "    \n",
        "    # convert to probabilities\n",
        "    probabilities = histogram / float(total_pixels)\n",
        "    \n",
        "    best_threshold = 0\n",
        "    best_variance = 0.0\n",
        "    \n",
        "    # try each possible threshold\n",
        "    for threshold in range(256):\n",
        "        # calculate weights for background and foreground\n",
        "        weight_background = np.sum(probabilities[:threshold+1])\n",
        "        weight_foreground = 1.0 - weight_background\n",
        "        \n",
        "        if weight_background == 0 or weight_foreground == 0:\n",
        "            continue\n",
        "        \n",
        "        # calculate mean brightness for each group\n",
        "        mean_background = np.sum(probabilities[:threshold+1] * np.arange(threshold+1)) / weight_background\n",
        "        mean_foreground = np.sum(probabilities[threshold+1:] * np.arange(threshold+1, 256)) / weight_foreground\n",
        "        \n",
        "        # calculate between-class variance\n",
        "        variance = weight_background * weight_foreground * (mean_background - mean_foreground) ** 2\n",
        "        \n",
        "        if variance > best_variance:\n",
        "            best_variance = variance\n",
        "            best_threshold = threshold\n",
        "    \n",
        "    return best_threshold\n",
        "\n",
        "def make_binary_mask(gray_image):\n",
        "    \"\"\"convert grayscale image to binary pore mask\"\"\"\n",
        "    # convert to 8-bit if needed\n",
        "    processed_image = convert_to_uint8(gray_image)\n",
        "    \n",
        "    # check if already binary\n",
        "    unique_values = np.unique(processed_image)\n",
        "    if len(unique_values) == 2:\n",
        "        # already binary, assume darker pixels are pores\n",
        "        darker_value = unique_values[0]\n",
        "        pore_mask = (processed_image == darker_value).astype(np.uint8)\n",
        "        return pore_mask\n",
        "    \n",
        "    # find threshold automatically\n",
        "    threshold = find_threshold_otsu(processed_image)\n",
        "    \n",
        "    # pores are darker pixels\n",
        "    pore_mask = (processed_image <= threshold).astype(np.uint8)\n",
        "    return pore_mask\n",
        "\n",
        "def load_image_as_binary(file_path):\n",
        "    \"\"\"load tiff file and convert to binary pore mask\"\"\"\n",
        "    raw_image = load_tiff_image(file_path)\n",
        "    if raw_image is None:\n",
        "        raise FileNotFoundError(\"Could not read image: \" + file_path)\n",
        "    \n",
        "    gray_image = make_grayscale(raw_image)\n",
        "    if gray_image is None:\n",
        "        raise ValueError(\"Could not convert to grayscale: \" + file_path)\n",
        "    \n",
        "    binary_mask = make_binary_mask(gray_image)\n",
        "    return binary_mask\n",
        "\n",
        "def safe_divide(numerator, denominator):\n",
        "    \"\"\"divide two numbers safely, return 0 if denominator is 0\"\"\"\n",
        "    if denominator == 0:\n",
        "        return 0.0\n",
        "    return float(numerator) / float(denominator)\n",
        "\n",
        "def calculate_confusion_matrix(true_mask, predicted_mask):\n",
        "    \"\"\"calculate true positive, false positive, etc\"\"\"\n",
        "    true_binary = true_mask.astype(np.uint8)\n",
        "    pred_binary = predicted_mask.astype(np.uint8)\n",
        "    \n",
        "    # count pixels in each category\n",
        "    true_positive = int(np.sum((true_binary == 1) & (pred_binary == 1)))\n",
        "    true_negative = int(np.sum((true_binary == 0) & (pred_binary == 0)))\n",
        "    false_positive = int(np.sum((true_binary == 0) & (pred_binary == 1)))\n",
        "    false_negative = int(np.sum((true_binary == 1) & (pred_binary == 0)))\n",
        "    \n",
        "    return true_positive, false_positive, true_negative, false_negative\n",
        "\n",
        "def calculate_accuracy_metrics(true_mask, predicted_mask):\n",
        "    \"\"\"calculate dice, IoU, precision, recall etc\"\"\"\n",
        "    tp, fp, tn, fn = calculate_confusion_matrix(true_mask, predicted_mask)\n",
        "    \n",
        "    # basic metrics\n",
        "    accuracy = safe_divide(tp + tn, tp + tn + fp + fn)\n",
        "    precision = safe_divide(tp, tp + fp)\n",
        "    recall = safe_divide(tp, tp + fn)\n",
        "    specificity = safe_divide(tn, tn + fp)\n",
        "    \n",
        "    # combined metrics\n",
        "    dice_score = safe_divide(2 * tp, 2 * tp + fp + fn)\n",
        "    iou_score = safe_divide(tp, tp + fp + fn)\n",
        "    \n",
        "    # calculate MCC (correlation coefficient) - FIXED\n",
        "    mcc_denominator = (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n",
        "    if mcc_denominator > 0:\n",
        "        mcc_value = (tp * tn - fp * fn) / math.sqrt(float(mcc_denominator))\n",
        "    else:\n",
        "        mcc_value = 0.0\n",
        "    \n",
        "    results = {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"specificity\": specificity,\n",
        "        \"dice\": dice_score,\n",
        "        \"iou\": iou_score,\n",
        "        \"mcc\": mcc_value,\n",
        "        \"true_positive\": tp,\n",
        "        \"false_positive\": fp,\n",
        "        \"true_negative\": tn,\n",
        "        \"false_negative\": fn\n",
        "    }\n",
        "    \n",
        "    return results\n",
        "\n",
        "def calculate_pore_fraction(mask):\n",
        "    \"\"\"what fraction of pixels are pores\"\"\"\n",
        "    return float(np.mean(mask))\n",
        "\n",
        "def calculate_pore_area_micrometers(mask):\n",
        "    \"\"\"total pore area in square micrometers\"\"\"\n",
        "    pore_pixels = int(np.sum(mask == 1))\n",
        "    area_um2 = pore_pixels * pixel_area_um2\n",
        "    return area_um2\n",
        "\n",
        "def create_overlay_image(true_mask, predicted_mask, output_path):\n",
        "    \"\"\"create colored overlay showing differences between masks\"\"\"\n",
        "    # start with gray background\n",
        "    background = (1 - true_mask) * 255.0\n",
        "    background = background.astype(np.uint8)\n",
        "    base_image = Image.fromarray(background, mode=\"L\").convert(\"RGBA\")\n",
        "    \n",
        "    height, width = true_mask.shape\n",
        "    \n",
        "    # false positives in red (predicted pore but not true pore)\n",
        "    false_pos = ((true_mask == 0) & (predicted_mask == 1)).astype(np.uint8) * 255\n",
        "    red_layer = Image.new(\"RGBA\", (width, height), (255, 0, 0, 180))\n",
        "    red_mask = Image.fromarray(false_pos, mode=\"L\")\n",
        "    base_image.paste(red_layer, (0, 0), mask=red_mask)\n",
        "    \n",
        "    # false negatives in blue (missed true pores)\n",
        "    false_neg = ((true_mask == 1) & (predicted_mask == 0)).astype(np.uint8) * 255\n",
        "    blue_layer = Image.new(\"RGBA\", (width, height), (0, 0, 255, 180))\n",
        "    blue_mask = Image.fromarray(false_neg, mode=\"L\")\n",
        "    base_image.paste(blue_layer, (0, 0), mask=blue_mask)\n",
        "    \n",
        "    # true positives in green outline only\n",
        "    true_pos_region = ((true_mask == 1) & (predicted_mask == 1)).astype(np.uint8)\n",
        "    true_pos_eroded = binary_erosion(true_pos_region)\n",
        "    true_pos_outline = true_pos_region - true_pos_eroded.astype(np.uint8)\n",
        "    outline_mask = (true_pos_outline > 0).astype(np.uint8) * 255\n",
        "    \n",
        "    green_layer = Image.new(\"RGBA\", (width, height), (0, 255, 0, 255))\n",
        "    green_mask = Image.fromarray(outline_mask, mode=\"L\")\n",
        "    base_image.paste(green_layer, (0, 0), mask=green_mask)\n",
        "    \n",
        "    # save as RGB image\n",
        "    final_image = base_image.convert(\"RGB\")\n",
        "    final_image.save(output_path)\n",
        "    return output_path\n",
        "\n",
        "def save_method_csv(results_dict, output_dir):\n",
        "    \"\"\"save results for one method to its own CSV file\"\"\"\n",
        "    method_name = results_dict[\"method\"]\n",
        "    csv_filename = method_name + \"_metrics.csv\"\n",
        "    csv_path = os.path.join(output_dir, csv_filename)\n",
        "    \n",
        "    column_names = [\n",
        "        \"method\", \"dice\", \"iou\", \"mcc\", \"precision\", \"recall\", \n",
        "        \"specificity\", \"accuracy\", \"true_positive\", \"false_positive\", \n",
        "        \"true_negative\", \"false_negative\", \"true_pore_fraction\", \n",
        "        \"pred_pore_fraction\", \"pore_fraction_diff\", \"true_pore_area_um2\", \n",
        "        \"pred_pore_area_um2\", \"pore_area_diff_um2\"\n",
        "    ]\n",
        "    \n",
        "    with open(csv_path, \"w\", newline=\"\") as csv_file:\n",
        "        writer = csv.DictWriter(csv_file, fieldnames=column_names)\n",
        "        writer.writeheader()\n",
        "        writer.writerow(results_dict)\n",
        "    \n",
        "    return csv_path\n",
        "\n",
        "def create_notebook_file(python_code, notebook_path):\n",
        "    \"\"\"save python code as jupyter notebook\"\"\"\n",
        "    notebook_data = {\n",
        "        \"cells\": [{\n",
        "            \"cell_type\": \"code\",\n",
        "            \"execution_count\": None,\n",
        "            \"metadata\": {},\n",
        "            \"outputs\": [],\n",
        "            \"source\": python_code.splitlines(True)\n",
        "        }],\n",
        "        \"metadata\": {\n",
        "            \"language_info\": {\"name\": \"python\"},\n",
        "            \"kernelspec\": {\"display_name\": \"Python\", \"language\": \"python\", \"name\": \"python\"}\n",
        "        },\n",
        "        \"nbformat\": 4,\n",
        "        \"nbformat_minor\": 5\n",
        "    }\n",
        "    \n",
        "    with open(notebook_path, \"w\") as notebook_file:\n",
        "        json.dump(notebook_data, notebook_file, indent=2)\n",
        "\n",
        "def process_all_images(input_folder, output_folder):\n",
        "    \"\"\"main function to process all images and create results\"\"\"\n",
        "    \n",
        "    # load gold standard image\n",
        "    gold_standard_path = os.path.join(input_folder, gold_standard_file)\n",
        "    if not os.path.exists(gold_standard_path):\n",
        "        raise FileNotFoundError(\"Gold standard file not found: \" + gold_standard_path)\n",
        "    \n",
        "    true_mask = load_image_as_binary(gold_standard_path)\n",
        "    all_results = []\n",
        "    \n",
        "    # process each method image\n",
        "    for filename in os.listdir(input_folder):\n",
        "        filename_lower = filename.lower()\n",
        "        if not (filename_lower.endswith(\".tif\") or filename_lower.endswith(\".tiff\")):\n",
        "            continue\n",
        "        if filename == gold_standard_file:\n",
        "            continue\n",
        "        \n",
        "        # load and process this method's image\n",
        "        method_path = os.path.join(input_folder, filename)\n",
        "        predicted_mask = load_image_as_binary(method_path)\n",
        "        \n",
        "        # check image sizes match\n",
        "        if true_mask.shape != predicted_mask.shape:\n",
        "            error_msg = \"Image sizes don't match: \" + str(true_mask.shape) + \" vs \" + str(predicted_mask.shape)\n",
        "            raise ValueError(error_msg)\n",
        "        \n",
        "        # calculate accuracy metrics\n",
        "        metrics = calculate_accuracy_metrics(true_mask, predicted_mask)\n",
        "        \n",
        "        # calculate pore statistics\n",
        "        true_fraction = calculate_pore_fraction(true_mask)\n",
        "        pred_fraction = calculate_pore_fraction(predicted_mask)\n",
        "        fraction_difference = pred_fraction - true_fraction\n",
        "        \n",
        "        true_area = calculate_pore_area_micrometers(true_mask)\n",
        "        pred_area = calculate_pore_area_micrometers(predicted_mask)\n",
        "        area_difference = pred_area - true_area\n",
        "        \n",
        "        # get method name from filename\n",
        "        method_name = os.path.splitext(filename)[0]\n",
        "        \n",
        "        # create overlay image\n",
        "        overlay_filename = method_name + \"_overlay.tif\"\n",
        "        overlay_path = os.path.join(output_folder, overlay_filename)\n",
        "        create_overlay_image(true_mask, predicted_mask, overlay_path)\n",
        "        \n",
        "        # compile all results for this method\n",
        "        method_results = {\n",
        "            \"method\": method_name,\n",
        "            \"dice\": metrics[\"dice\"],\n",
        "            \"iou\": metrics[\"iou\"],\n",
        "            \"mcc\": metrics[\"mcc\"],\n",
        "            \"precision\": metrics[\"precision\"],\n",
        "            \"recall\": metrics[\"recall\"],\n",
        "            \"specificity\": metrics[\"specificity\"],\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"true_positive\": metrics[\"true_positive\"],\n",
        "            \"false_positive\": metrics[\"false_positive\"],\n",
        "            \"true_negative\": metrics[\"true_negative\"],\n",
        "            \"false_negative\": metrics[\"false_negative\"],\n",
        "            \"true_pore_fraction\": true_fraction,\n",
        "            \"pred_pore_fraction\": pred_fraction,\n",
        "            \"pore_fraction_diff\": fraction_difference,\n",
        "            \"true_pore_area_um2\": true_area,\n",
        "            \"pred_pore_area_um2\": pred_area,\n",
        "            \"pore_area_diff_um2\": area_difference\n",
        "        }\n",
        "        \n",
        "        all_results.append(method_results)\n",
        "        \n",
        "        # save individual method CSV\n",
        "        method_csv_path = save_method_csv(method_results, output_folder)\n",
        "        \n",
        "        # print progress\n",
        "        print(method_name + \": Dice=\" + str(round(metrics[\"dice\"], 3)) + \n",
        "              \" IoU=\" + str(round(metrics[\"iou\"], 3)) + \n",
        "              \" Bias=\" + str(round(fraction_difference * 100, 2)) + \"%\")\n",
        "    \n",
        "    # save combined results CSV\n",
        "    if len(all_results) > 0:\n",
        "        column_names = [\n",
        "            \"method\", \"dice\", \"iou\", \"mcc\", \"precision\", \"recall\", \n",
        "            \"specificity\", \"accuracy\", \"true_positive\", \"false_positive\", \n",
        "            \"true_negative\", \"false_negative\", \"true_pore_fraction\", \n",
        "            \"pred_pore_fraction\", \"pore_fraction_diff\", \"true_pore_area_um2\", \n",
        "            \"pred_pore_area_um2\", \"pore_area_diff_um2\"\n",
        "        ]\n",
        "        \n",
        "        with open(summary_csv_file, \"w\", newline=\"\") as summary_file:\n",
        "            writer = csv.DictWriter(summary_file, fieldnames=column_names)\n",
        "            writer.writeheader()\n",
        "            for result in all_results:\n",
        "                writer.writerow(result)\n",
        "    \n",
        "    print(\"Summary CSV saved: \" + summary_csv_file)\n",
        "    \n",
        "    # save copies of code\n",
        "    script_output_path = os.path.join(output_folder, \"pore_analysis.py\")\n",
        "    notebook_output_path = os.path.join(output_folder, \"pore_analysis.ipynb\")\n",
        "    \n",
        "    # get source code of this script\n",
        "    try:\n",
        "        script_source = \"\"\n",
        "        # read this file to get the source code\n",
        "        current_file_path = __file__\n",
        "        with open(current_file_path, \"r\") as source_file:\n",
        "            script_source = source_file.read()\n",
        "    except:\n",
        "        script_source = \"# source code not available in this environment\"\n",
        "    \n",
        "    with open(script_output_path, \"w\") as script_file:\n",
        "        script_file.write(script_source)\n",
        "    \n",
        "    create_notebook_file(script_source, notebook_output_path)\n",
        "    \n",
        "    print(\"Code saved: \" + script_output_path)\n",
        "    print(\"Notebook saved: \" + notebook_output_path)\n",
        "\n",
        "# run the analysis\n",
        "process_all_images(data_folder, output_folder)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pore-acc (NumPy 1.26)",
      "language": "python",
      "name": "pore-acc"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
