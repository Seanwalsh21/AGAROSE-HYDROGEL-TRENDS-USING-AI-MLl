{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63265d9f-0f53-40f1-be2d-840ceb251f41",
   "metadata": {},
   "source": [
    "## MULTIPLE GOLD STANDARD APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f8e8a7-c2d9-4a6d-82da-e6e0b8c335f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell imports all the basic Python libraries we need for image processing, data analysis, and file operations.\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import csv\n",
    "import itertools\n",
    "import sys\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939fdc7-c7cc-4304-bf9a-3d8bee03de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines where our data files are located and which segmentation methods\n",
    "we want to compare against the gold standard.\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd()\n",
    "proj_root = notebook_dir.parent\n",
    "BASE_DIR = str(proj_root / \"CRYO-SEM DATA\" / \"CRYO-SEM X30000\")\n",
    "\n",
    "\n",
    "# Setup paths to our data folders\n",
    "replicate_dirs = [\n",
    "    BASE_DIR / \"CRYO-SEM X30000 [1]\",\n",
    "    BASE_DIR / \"CRYO-SEM X30000 [2]\",\n",
    "    BASE_DIR / \"CRYO-SEM X30000 [3]\",\n",
    "    BASE_DIR / \"CRYO-SEM X30000 [4]\",\n",
    "]\n",
    "\n",
    "# These are all the different methods we want to test\n",
    "method_files = [\n",
    "    \"60%.tif\",\n",
    "    \"FREEHAND.tif\", \n",
    "    \"OVAL.tif\",\n",
    "    \"ILASTIK.tif\",\n",
    "    \"OTSU.tif\",\n",
    "    \"PLANKSTER.tif\",\n",
    "    \"PORED2.tif\",\n",
    "    \"SAMJ.tif\",\n",
    "    \"SEMI.tif\",\n",
    "    \"UNET.tif\",\n",
    "]\n",
    "\n",
    "FAMILY_TAG = \"CRYO-SEM X30000\"\n",
    "display_family_tag = \"[\" + FAMILY_TAG + \"]\"\n",
    "group_dir = BASE_DIR / \"MULTIPLE GS METHOD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae732b7-5a1c-46f3-b440-c0620eae8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell tries to import optional libraries for statistics and image processing,\n",
    "keeping track of which ones are available to use later.\"\"\"\n",
    "\n",
    "# Try to import scipy for better statistics\n",
    "try:\n",
    "    from scipy.stats import t as tdist\n",
    "    from scipy.stats import kruskal\n",
    "    from scipy.stats import wilcoxon \n",
    "    from scipy.stats import binomtest\n",
    "    from scipy.stats import t as analysis_t\n",
    "    got_scipy = True\n",
    "except Exception:\n",
    "    got_scipy = False\n",
    "\n",
    "# Try to import different image reading libraries as backup options\n",
    "try:\n",
    "    import tifffile as tiff\n",
    "    got_tifffile = True\n",
    "except Exception:\n",
    "    got_tifffile = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    got_pil = True\n",
    "except Exception:\n",
    "    got_pil = False\n",
    "\n",
    "# Try to import TIFF writing libraries\n",
    "try:\n",
    "    import tifffile as tiffw\n",
    "    got_tiff_write = True\n",
    "except Exception:\n",
    "    got_tiff_write = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image as PILImage\n",
    "    got_pil_write = True\n",
    "except Exception:\n",
    "    got_pil_write = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cc2c452-071d-4637-8865-a07263188159",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell creates functions to automatically find gold standard files and read TIFF\n",
    "images using multiple backup methods in case one fails.\"\"\"\n",
    "\n",
    "def find_gold_mask(rep_dir):\n",
    "    \"\"\"\n",
    "    Find the gold standard file in each replicate folder\n",
    "    The files might have different names so we search carefully\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(rep_dir):\n",
    "        return None\n",
    "    \n",
    "    # Look for files that match gold standard pattern\n",
    "    pattern = re.compile(r\"(?i)^gold standard\\s*(\\[\\s*\\d+\\s*\\])?\\.(tif|tiff)$\")\n",
    "    try:\n",
    "        candidates = [os.path.join(rep_dir, f) for f in os.listdir(rep_dir) if pattern.match(f)]\n",
    "    except Exception:\n",
    "        candidates = []\n",
    "    \n",
    "    # If no exact matches try broader search\n",
    "    if not candidates:\n",
    "        for ext in (\"tif\",\"tiff\"):\n",
    "            candidates += glob.glob(os.path.join(rep_dir, \"GOLD STANDARD*.\" + ext))\n",
    "            candidates += glob.glob(os.path.join(rep_dir, \"Gold Standard*.\" + ext))\n",
    "            candidates += glob.glob(os.path.join(rep_dir, \"gold standard*.\" + ext))\n",
    "    \n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Try to match the replicate number if possible\n",
    "    m = re.search(r\"\\[(\\d+)\\]\", os.path.basename(rep_dir))\n",
    "    if m:\n",
    "        idx = m.group(1)\n",
    "        for p in candidates:\n",
    "            if re.search(rf\"\\[\\s*{idx}\\s*\\]\", os.path.basename(p)):\n",
    "                return p\n",
    "    \n",
    "    return sorted(candidates)[0]\n",
    "\n",
    "def read_tiff_image(path):\n",
    "    \"\"\"\n",
    "    Try to read a TIFF image using different methods\n",
    "    OpenCV is first choice but we have backups\n",
    "    \"\"\"\n",
    "    # Try OpenCV first since its usually reliable\n",
    "    img = cv2.imread(path, cv2.IMREAD_ANYDEPTH | cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        return img\n",
    "    \n",
    "    # Try tifffile library if OpenCV fails\n",
    "    if got_tifffile:\n",
    "        try:\n",
    "            return tiff.imread(path)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Try PIL as last resort\n",
    "    if got_pil:\n",
    "        try:\n",
    "            with Image.open(path) as im:\n",
    "                if \"I;16\" in im.mode:\n",
    "                    im = im.convert(\"I;16\")\n",
    "                else:\n",
    "                    im = im.convert(\"L\")\n",
    "                return np.array(im)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea6d1d9f-253f-4dff-a386-9c3b276bd107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines functions to convert images to grayscale, prepare them for analysis,\n",
    "and calculate optimal thresholds for separating foreground from background.\"\"\"\n",
    "\n",
    "def convert_to_grayscale(arr):\n",
    "    \"\"\"\n",
    "    Convert image to grayscale if it has multiple channels\n",
    "    We need single channel images for our analysis\n",
    "    \"\"\"\n",
    "    if arr.ndim == 2:\n",
    "        return arr\n",
    "    \n",
    "    # Handle RGB or RGBA images\n",
    "    if arr.ndim == 3 and arr.shape[-1] in (3,4):\n",
    "        a = arr\n",
    "        # Convert to uint8 if needed for OpenCV functions\n",
    "        if a.dtype != np.uint8:\n",
    "            a_min = float(a.min())\n",
    "            a_max = float(a.max())\n",
    "            a = ((a - a_min) / (a_max - a_min + 1e-12) * 255.0).astype(np.uint8)\n",
    "        \n",
    "        # Remove alpha channel if present\n",
    "        if a.shape[-1] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2BGR)\n",
    "        return cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # If more than 3D just take first channel\n",
    "    if arr.ndim > 2:\n",
    "        return convert_to_grayscale(arr[..., 0])\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def make_image_uint(img):\n",
    "    \"\"\"\n",
    "    Convert image to unsigned integer format for processing\n",
    "    This helps with thresholding operations\n",
    "    \"\"\"\n",
    "    if img.dtype in (np.uint8, np.uint16):\n",
    "        return img\n",
    "    \n",
    "    # Handle floating point images by scaling to 0-255\n",
    "    if np.issubdtype(img.dtype, np.floating):\n",
    "        a_min = float(img.min())\n",
    "        a_max = float(img.max())\n",
    "        if a_max > a_min:\n",
    "            scaled = (img - a_min) / (a_max - a_min)\n",
    "        else:\n",
    "            scaled = np.zeros_like(img, float)\n",
    "        return (scaled * 255.0 + 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Convert other types appropriately\n",
    "    return img.astype(np.uint16 if img.max() > 255 else np.uint8)\n",
    "\n",
    "def otsu_threshold_manual(g8):\n",
    "    \"\"\"\n",
    "    Calculate Otsu threshold manually if OpenCV doesnt have it\n",
    "    This finds the best threshold to separate foreground from background\n",
    "    The method tries every possible threshold and picks the best one\n",
    "    \"\"\"\n",
    "    hist = np.bincount(g8.ravel(), minlength=256).astype(np.float64)\n",
    "    total = g8.size\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    \n",
    "    sum_total = np.dot(np.arange(256, dtype=np.float64), hist)\n",
    "    sumB = 0.0\n",
    "    wB = 0.0 \n",
    "    maximum = -1.0\n",
    "    threshold = 0\n",
    "    \n",
    "    # Try each possible threshold value to find the best separation\n",
    "    for t in range(256):\n",
    "        wB += hist[t]\n",
    "        if wB == 0: \n",
    "            continue\n",
    "        wF = total - wB\n",
    "        if wF == 0: \n",
    "            break\n",
    "        \n",
    "        sumB += t * hist[t]\n",
    "        mB = sumB / wB\n",
    "        mF = (sum_total - sumB) / wF\n",
    "        between = wB * wF * (mB - mF) ** 2\n",
    "        \n",
    "        if between > maximum:\n",
    "            maximum = between\n",
    "            threshold = t\n",
    "    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e1faa3-b049-4209-8a03-13d42b2d2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell converts grayscale images into binary masks where pores are marked as 1\n",
    "and background as 0, using automatic thresholding.\"\"\"\n",
    "\n",
    "def make_binary_mask(img_gray):\n",
    "    \"\"\"\n",
    "    Convert grayscale image to binary mask where pores are 1 and background is 0\n",
    "    We assume pores are the dark pixels (black equals pore)\n",
    "    \"\"\"\n",
    "    g = make_image_uint(img_gray)\n",
    "    unique_vals = np.unique(g)\n",
    "    \n",
    "    # If only two values use the darker one as pores\n",
    "    if unique_vals.size == 2:\n",
    "        pores = (g == int(unique_vals[0]))\n",
    "        return pores.astype(np.uint8)\n",
    "    \n",
    "    # Convert to 8-bit for thresholding\n",
    "    g8 = (g / 257).astype(np.uint8) if g.dtype == np.uint16 else g.astype(np.uint8)\n",
    "    \n",
    "    # Try to use OpenCV Otsu thresholding first\n",
    "    if hasattr(cv2, \"THRESH_OTSU\"):\n",
    "        _, th = cv2.threshold(g8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return (th == 0).astype(np.uint8)\n",
    "    else:\n",
    "        # Use manual Otsu calculation as fallback\n",
    "        thr = otsu_threshold_manual(g8)\n",
    "        th = (g8 > thr).astype(np.uint8) * 255\n",
    "        return (th == 0).astype(np.uint8)\n",
    "\n",
    "def read_mask(path):\n",
    "    \"\"\"\n",
    "    Read an image file and convert it to a binary mask\n",
    "    Returns numpy array where 1 equals pore and 0 equals background\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(\"file does not exist: \" + path)\n",
    "    \n",
    "    raw = read_tiff_image(path)\n",
    "    if raw is None:\n",
    "        raise FileNotFoundError(\"cannot read image: \" + path)\n",
    "    \n",
    "    gray = convert_to_grayscale(raw)\n",
    "    if gray.ndim != 2:\n",
    "        raise ValueError(\"not a single-channel image: \" + path)\n",
    "    \n",
    "    return make_binary_mask(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a5e3c1-441f-4e22-8c19-2fff765323b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell creates colorful overlay images that visually show where each method agrees\n",
    "or disagrees with the gold standard using green, red, and blue colors.\"\"\"\n",
    "\n",
    "def save_overlay_image(gt, pr, save_path_tif):\n",
    "    \"\"\"\n",
    "    Create and save an overlay image showing the comparison results\n",
    "    True Positives show as green outlines\n",
    "    False Positives show as red fill\n",
    "    False Negatives show as blue fill\n",
    "    Gold standard forms the grayscale background\n",
    "    \"\"\"\n",
    "    # Create grayscale background from gold standard\n",
    "    base_gray = (1 - gt) * 255\n",
    "    overlay = cv2.cvtColor(base_gray.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Calculate different types of pixels for comparison\n",
    "    tp = (gt == 1) & (pr == 1)  # True Positive: both methods found pore\n",
    "    fp = (gt == 0) & (pr == 1)  # False Positive: method found pore but gold standard didnt\n",
    "    fn = (gt == 1) & (pr == 0)  # False Negative: gold standard has pore but method missed it\n",
    "\n",
    "    # Add False Positives as red fill\n",
    "    fp_layer = overlay.copy()\n",
    "    fp_layer[fp] = (0, 0, 255)  # BGR format so this is red\n",
    "    overlay = cv2.addWeighted(fp_layer, 0.45, overlay, 0.55, 0)\n",
    "\n",
    "    # Add False Negatives as blue fill  \n",
    "    fn_layer = overlay.copy()\n",
    "    fn_layer[fn] = (255, 0, 0)  # BGR format so this is blue\n",
    "    overlay = cv2.addWeighted(fn_layer, 0.45, overlay, 0.55, 0)\n",
    "\n",
    "    # Add True Positives as green outline\n",
    "    edges = cv2.Canny((tp.astype(np.uint8) * 255), 50, 150)\n",
    "    overlay[edges > 0] = (0, 255, 0)  # BGR format so this is green\n",
    "\n",
    "    # Make sure output directory exists\n",
    "    os.makedirs(os.path.dirname(save_path_tif), exist_ok=True)\n",
    "    if not save_path_tif.lower().endswith((\".tif\", \".tiff\")):\n",
    "        save_path_tif += \".tif\"\n",
    "\n",
    "    # Try different methods to save the image\n",
    "    success = False\n",
    "    try:\n",
    "        success = cv2.imwrite(save_path_tif, overlay)\n",
    "    except Exception:\n",
    "        success = False\n",
    "    \n",
    "    if not success and got_tiff_write:\n",
    "        try:\n",
    "            tiffw.imwrite(save_path_tif, overlay)\n",
    "            success = True\n",
    "        except Exception:\n",
    "            success = False\n",
    "    \n",
    "    if not success and got_pil_write:\n",
    "        try:\n",
    "            # PIL uses RGB but OpenCV uses BGR so we need to flip\n",
    "            PILImage.fromarray(overlay[:, :, ::-1]).save(save_path_tif, format=\"TIFF\")\n",
    "            success = True\n",
    "        except Exception:\n",
    "            success = False\n",
    "    \n",
    "    if not success:\n",
    "        raise IOError(\"failed to write TIFF: \" + save_path_tif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad48eb3-bf51-424b-8a1f-837896c8f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell calculates accuracy metrics like Dice coefficient, precision, recall,\n",
    "and others that tell us how well each segmentation method performs.\"\"\"\n",
    "\n",
    "def safe_divide(numerator, denominator):\n",
    "    \"\"\"Helper function to avoid division by zero errors\"\"\"\n",
    "    return float(numerator) / float(denominator) if denominator else 0.0\n",
    "\n",
    "def count_pixels(gt, pred):\n",
    "    \"\"\"\n",
    "    Count True Positives False Positives True Negatives False Negatives\n",
    "    These counts tell us how the prediction compares to ground truth\n",
    "    \"\"\"\n",
    "    gt = gt.astype(np.uint8)\n",
    "    pred = pred.astype(np.uint8)\n",
    "    \n",
    "    tp = int(np.sum((gt == 1) & (pred == 1)))  # Both say pore\n",
    "    tn = int(np.sum((gt == 0) & (pred == 0)))  # Both say background  \n",
    "    fp = int(np.sum((gt == 0) & (pred == 1)))  # Pred says pore truth says background\n",
    "    fn = int(np.sum((gt == 1) & (pred == 0)))  # Pred says background truth says pore\n",
    "    \n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "def compute_metrics(gt, pred):\n",
    "    \"\"\"\n",
    "    Calculate all the performance metrics we need\n",
    "    These tell us how good a method is at finding pores correctly\n",
    "    \"\"\"\n",
    "    tp, fp, tn, fn = count_pixels(gt, pred)\n",
    "    \n",
    "    # Basic accuracy: how many pixels did we get right overall?\n",
    "    acc = safe_divide(tp + tn, tp + tn + fp + fn)\n",
    "    \n",
    "    # Precision: of the pixels we called pores how many really were pores?\n",
    "    prec = safe_divide(tp, tp + fp)\n",
    "    \n",
    "    # Recall (Sensitivity): of the real pores how many did we find?\n",
    "    rec = safe_divide(tp, tp + fn)\n",
    "    \n",
    "    # Specificity: of the real background pixels how many did we get right?\n",
    "    spec = safe_divide(tn, tn + fp)\n",
    "    \n",
    "    # Balanced accuracy: average of sensitivity and specificity\n",
    "    ba = 0.5 * (rec + spec)\n",
    "    \n",
    "    # Dice coefficient (also called F1 score): harmonic mean of precision and recall\n",
    "    dice = safe_divide(2 * tp, 2 * tp + fp + fn)\n",
    "    \n",
    "    # IoU (Intersection over Union): area of overlap divided by area of union\n",
    "    iou = safe_divide(tp, tp + fp + fn)\n",
    "    \n",
    "    # Matthews Correlation Coefficient: overall measure of quality\n",
    "    denominator_product = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n",
    "    mcc = safe_divide(tp*tn - fp*fn, sqrt(float(denominator_product))) if denominator_product > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"specificity\": spec,\n",
    "        \"balanced_accuracy\": ba,\n",
    "        \"f1_dice\": dice,\n",
    "        \"iou_jaccard\": iou,\n",
    "        \"mcc\": mcc,\n",
    "        \"TP\": tp, \n",
    "        \"FP\": fp, \n",
    "        \"TN\": tn, \n",
    "        \"FN\": fn,\n",
    "    }\n",
    "\n",
    "def calculate_confidence_interval(mean, sd, n):\n",
    "    \"\"\"\n",
    "    Calculate 95% confidence interval for the mean\n",
    "    This tells us the range where the true mean probably lies\n",
    "    \"\"\"\n",
    "    if n is None or n < 2 or sd is None or np.isnan(sd):\n",
    "        return (np.nan, np.nan)\n",
    "    \n",
    "    # Use t-distribution if we have scipy otherwise use normal approximation\n",
    "    if got_scipy:\n",
    "        t_critical = float(tdist.ppf(0.975, df=n-1))\n",
    "    else:\n",
    "        t_critical = 1.96  # Normal approximation\n",
    "    \n",
    "    margin_of_error = t_critical * sd / sqrt(n)\n",
    "    return (mean - margin_of_error, mean + margin_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453d8aac-9fe6-4761-8397-3022caccd6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of each replicate...\n",
      "Processing replicate: CRYO-SEM X30000 [1]\n",
      "SKIPPING - no gold standard found in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [1]\n",
      "Processing replicate: CRYO-SEM X30000 [2]\n",
      "SKIPPING - no gold standard found in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [2]\n",
      "Processing replicate: CRYO-SEM X30000 [3]\n",
      "SKIPPING - no gold standard found in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [3]\n",
      "Processing replicate: CRYO-SEM X30000 [4]\n",
      "SKIPPING - no gold standard found in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [4]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell processes each replicate folder individually, comparing every segmentation\n",
    "method against the gold standard and saving results as CSV files and overlay images.\"\"\"\n",
    "\n",
    "print(\"Starting analysis of each replicate...\")\n",
    "\n",
    "# Process each replicate folder one by one\n",
    "for root in replicate_dirs:\n",
    "    print(\"Processing replicate:\", os.path.basename(root))\n",
    "    \n",
    "    gold_path = find_gold_mask(root)\n",
    "    output_dir = os.path.join(root, \"Accuracy\")\n",
    "    overlay_dir = os.path.join(output_dir, \"Overlays_TIFF\")\n",
    "    \n",
    "    # Create output directories\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(overlay_dir, exist_ok=True)\n",
    "\n",
    "    # Skip if no gold standard found\n",
    "    if not gold_path or not os.path.exists(gold_path):\n",
    "        print(\"SKIPPING - no gold standard found in:\", root)\n",
    "        continue\n",
    "\n",
    "    # Load the gold standard mask\n",
    "    gt_mask = read_mask(gold_path)\n",
    "    replicate_tag = display_family_tag + \" \" + os.path.basename(root)\n",
    "\n",
    "    # Test each method against the gold standard\n",
    "    for method_file in method_files:\n",
    "        prediction_path = os.path.join(root, method_file)\n",
    "        \n",
    "        # Skip if method file doesnt exist\n",
    "        if not os.path.exists(prediction_path):\n",
    "            print(\"SKIPPING - file not found:\", prediction_path)\n",
    "            continue\n",
    "\n",
    "        method_name = os.path.splitext(os.path.basename(prediction_path))[0]\n",
    "        \n",
    "        # Load the prediction mask\n",
    "        prediction_mask = read_mask(prediction_path)\n",
    "\n",
    "        # Make sure images are the same size\n",
    "        if gt_mask.shape != prediction_mask.shape:\n",
    "            error_msg = root + \" -> shape mismatch for \" + method_name + \": \" + str(gt_mask.shape) + \" vs \" + str(prediction_mask.shape)\n",
    "            raise ValueError(error_msg)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        metrics = compute_metrics(gt_mask, prediction_mask)\n",
    "\n",
    "        # Save metrics to CSV file\n",
    "        csv_file_path = os.path.join(output_dir, \"Metric Results [\" + method_name + \"].csv\")\n",
    "        with open(csv_file_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"metric\",\"value\"])\n",
    "            \n",
    "            # Write main metrics in order of importance\n",
    "            for metric_name in [\"f1_dice\",\"iou_jaccard\",\"precision\",\"recall\",\"specificity\",\n",
    "                              \"balanced_accuracy\",\"accuracy\",\"mcc\"]:\n",
    "                writer.writerow([metric_name, metrics[metric_name]])\n",
    "            \n",
    "            # Add empty row for separation\n",
    "            writer.writerow([])\n",
    "            \n",
    "            # Write confusion matrix values\n",
    "            writer.writerow([\"TP\", metrics[\"TP\"]])\n",
    "            writer.writerow([\"FP\", metrics[\"FP\"]])\n",
    "            writer.writerow([\"TN\", metrics[\"TN\"]]) \n",
    "            writer.writerow([\"FN\", metrics[\"FN\"]])\n",
    "\n",
    "        # Create and save overlay image\n",
    "        overlay_file_path = os.path.join(overlay_dir, method_name + \" \" + replicate_tag + \" overlay.tif\")\n",
    "        save_overlay_image(gt_mask, prediction_mask, overlay_file_path)\n",
    "\n",
    "        print(method_name + \" \" + replicate_tag + \": Dice \" + str(round(metrics['f1_dice'], 3)) + \" -> saved to \" + csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e89224-38cd-45e0-8300-428c4682b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating group summary across all replicates...\n",
      "Saved per-replicate data: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Group_PerReplicate_Values [CRYO-SEM X30000].csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell collects data from all replicates and creates a master dataset showing\n",
    "how each method performed across all test images.\"\"\"\n",
    "\n",
    "print(\"\\nCreating group summary across all replicates...\")\n",
    "\n",
    "# List of metrics we want to summarize\n",
    "metrics_to_summarize = [\"f1_dice\",\"iou_jaccard\",\"precision\",\"recall\",\"specificity\",\n",
    "                       \"balanced_accuracy\",\"accuracy\",\"mcc\"]\n",
    "\n",
    "# Collect data from all replicates for group analysis\n",
    "all_replicate_data = []\n",
    "for method_file in method_files:\n",
    "    method_name = os.path.splitext(method_file)[0]\n",
    "    \n",
    "    for root in replicate_dirs:\n",
    "        gold_standard_path = find_gold_mask(root)\n",
    "        prediction_path = os.path.join(root, method_file)\n",
    "        \n",
    "        # Skip if either file is missing\n",
    "        if not (gold_standard_path and os.path.exists(gold_standard_path) and os.path.exists(prediction_path)):\n",
    "            continue\n",
    "        \n",
    "        # Load both masks\n",
    "        gt = read_mask(gold_standard_path)\n",
    "        pr = read_mask(prediction_path)\n",
    "        \n",
    "        # Check size compatibility\n",
    "        if gt.shape != pr.shape:\n",
    "            error_msg = root + \" -> shape mismatch for \" + method_name + \": \" + str(gt.shape) + \" vs \" + str(pr.shape)\n",
    "            raise ValueError(error_msg)\n",
    "        \n",
    "        # Calculate metrics for this replicate\n",
    "        m = compute_metrics(gt, pr)\n",
    "        \n",
    "        # Add to our collection\n",
    "        row_data = [method_name, os.path.basename(root)]\n",
    "        for metric in metrics_to_summarize:\n",
    "            row_data.append(m[metric])\n",
    "        all_replicate_data.append(row_data)\n",
    "\n",
    "# Save per-replicate data\n",
    "os.makedirs(group_dir, exist_ok=True)\n",
    "per_replicate_file = os.path.join(group_dir, \"Group_PerReplicate_Values [\" + FAMILY_TAG + \"].csv\")\n",
    "with open(per_replicate_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    header_row = [\"method\",\"replicate\"] + metrics_to_summarize\n",
    "    writer.writerow(header_row)\n",
    "    writer.writerows(all_replicate_data)\n",
    "\n",
    "print(\"Saved per-replicate data:\", per_replicate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a365282-720a-4ffb-b030-fcc177f9543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved group summary: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Group_Summary [CRYO-SEM X30000].csv\n",
      "\n",
      "Software versions used:\n",
      "Python: 3.10.18\n",
      "NumPy: 1.26.4\n",
      "OpenCV: 4.10.0\n",
      "SciPy: available (used for confidence intervals)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell calculates mean values, standard deviations, and confidence intervals\n",
    "for each method across all replicates to summarize overall performance.\"\"\"\n",
    "\n",
    "# Calculate summary statistics across replicates\n",
    "summary_file = os.path.join(group_dir, \"Group_Summary [\" + FAMILY_TAG + \"].csv\")\n",
    "summary_rows = []\n",
    "\n",
    "for method_file in method_files:\n",
    "    method_name = os.path.splitext(method_file)[0]\n",
    "    \n",
    "    # Find all rows for this method\n",
    "    method_data = [row for row in all_replicate_data if row[0] == method_name]\n",
    "    n_replicates = len(method_data)\n",
    "    \n",
    "    # Skip if no data for this method\n",
    "    if n_replicates == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate statistics for each metric\n",
    "    for metric_index, metric_name in enumerate(metrics_to_summarize):\n",
    "        # Metric values start at index 2 (after method name and replicate name)\n",
    "        column_index = metric_index + 2\n",
    "        \n",
    "        # Extract all values for this metric\n",
    "        metric_values = np.array([row[column_index] for row in method_data], dtype=float)\n",
    "        \n",
    "        # Calculate mean\n",
    "        mean_value = float(metric_values.mean())\n",
    "        \n",
    "        # Calculate standard deviation and confidence interval\n",
    "        if n_replicates > 1:\n",
    "            std_value = float(metric_values.std(ddof=1))  # Sample standard deviation\n",
    "            ci_low, ci_high = calculate_confidence_interval(mean_value, std_value, n_replicates)\n",
    "        else:\n",
    "            # Cannot calculate std dev with only 1 sample\n",
    "            std_value = float(\"nan\")\n",
    "            ci_low = float(\"nan\") \n",
    "            ci_high = float(\"nan\")\n",
    "        \n",
    "        # Save this summary row\n",
    "        summary_row = [method_name, metric_name, mean_value, std_value, n_replicates, ci_low, ci_high]\n",
    "        summary_rows.append(summary_row)\n",
    "\n",
    "# Write summary statistics file\n",
    "with open(summary_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    header_row = [\"method\", \"metric\", \"mean\", \"sd\", \"n_images\", \"ci95_low\", \"ci95_high\"]\n",
    "    writer.writerow(header_row)\n",
    "    writer.writerows(summary_rows)\n",
    "\n",
    "print(\"Saved group summary:\", summary_file)\n",
    "\n",
    "# Print version information for reproducibility\n",
    "print(\"\\nSoftware versions used:\")\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "if got_scipy:\n",
    "    print(\"SciPy: available (used for confidence intervals)\")\n",
    "else:\n",
    "    print(\"SciPy: not available (used normal approximation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "987c5c76-9a76-46a6-8249-b97ceb0d5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell imports plotting libraries and sets up all the directories and settings\n",
    "needed to create figures and statistical analysis.\"\"\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Setup for figures\n",
    "FAMILY_DIR = group_dir\n",
    "N_IN_TITLE = 4  # number of gold standard images for titles\n",
    "\n",
    "# Settings for Bland Altman plots\n",
    "ENABLE_BLAND_ALTMAN = True\n",
    "BA_PAIRS_VS_REF_ONLY = True\n",
    "BA_MIN_COMMON = 2\n",
    "\n",
    "SUMMARY_CSV = os.path.join(FAMILY_DIR, \"Group_Summary [\" + FAMILY_TAG + \"].csv\")\n",
    "PERREP_CSV  = os.path.join(FAMILY_DIR, \"Group_PerReplicate_Values [\" + FAMILY_TAG + \"].csv\")\n",
    "FIG_DIR   = os.path.join(FAMILY_DIR, \"Figures\")\n",
    "STATS_DIR = os.path.join(FAMILY_DIR, \"Stats\")\n",
    "BA_DIR    = os.path.join(FIG_DIR, \"Bland-Altman\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "os.makedirs(STATS_DIR, exist_ok=True)\n",
    "os.makedirs(BA_DIR, exist_ok=True)\n",
    "\n",
    "np.random.seed(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b3f6e0-7f16-4f85-abac-e0eea63fb40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines the visual style, colors, and categories for all plots,\n",
    "making traditional methods blue, semi-automated purple, and fully automated red.\"\"\"\n",
    "\n",
    "# Set up plot styling\n",
    "mpl.rcParams.update({\n",
    "    \"font.size\": 9,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"xtick.major.width\": 0.8,\n",
    "    \"ytick.major.width\": 0.8,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"savefig.dpi\": 600,\n",
    "})\n",
    "\n",
    "# Define method categories and colors\n",
    "TRADITIONAL = {\"FREEHAND\", \"OVAL\"}\n",
    "SEMI_AUTO   = {\"SEMI\", \"SAMJ\", \"ILASTIK\", \"60%\"}\n",
    "FULL_AUTO   = {\"PORED2\", \"UNET\", \"OTSU\", \"PLANKSTER\"}\n",
    "\n",
    "C_TRAD  = \"#9ecae1\"  # light blue\n",
    "C_SEMI  = \"#d0b7ff\"  # light purple\n",
    "C_AUTO  = \"#f7b6b6\"  # light red\n",
    "C_OTHER = \"#dddddd\"\n",
    "\n",
    "def method_color_and_group(name):\n",
    "    \"\"\"Assign colors based on method type\"\"\"\n",
    "    u = name.strip().upper()\n",
    "    if u in TRADITIONAL: \n",
    "        return C_TRAD, \"Traditional\"\n",
    "    if u in SEMI_AUTO:   \n",
    "        return C_SEMI, \"Semi-automated\"\n",
    "    if u in FULL_AUTO:   \n",
    "        return C_AUTO, \"Fully automated\"\n",
    "    return C_OTHER, \"Other\"\n",
    "\n",
    "# Create legend handles for the plots\n",
    "legend_handles = [\n",
    "    Patch(facecolor=C_TRAD, edgecolor='k', label='Traditional'),\n",
    "    Patch(facecolor=C_SEMI, edgecolor='k', label='Semi-automated'),\n",
    "    Patch(facecolor=C_AUTO, edgecolor='k', label='Fully automated'),\n",
    "]\n",
    "\n",
    "# Define metric names for nice display\n",
    "NICE = {\n",
    "    \"f1_dice\": \"Dice (F1)\",\n",
    "    \"iou_jaccard\": \"IoU (Jaccard)\",\n",
    "    \"mcc\": \"Matthews CC\",\n",
    "    \"precision\": \"Precision\",\n",
    "    \"recall\": \"Recall (Sensitivity)\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "    \"balanced_accuracy\": \"Balanced Accuracy\",\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "METRICS_ALL  = [\"f1_dice\",\"iou_jaccard\",\"mcc\",\"precision\",\"recall\",\"specificity\",\"balanced_accuracy\",\"accuracy\"]\n",
    "BOX_METRICS  = [\"f1_dice\",\"iou_jaccard\",\"mcc\"]\n",
    "HEAT_METRICS = [\"f1_dice\",\"iou_jaccard\",\"mcc\",\"precision\",\"recall\",\"specificity\",\"balanced_accuracy\",\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "525b0fa3-60b8-4e8e-bba2-f9d4f3c7cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell creates helper functions for reading data files, cleaning up text for\n",
    "filenames, and saving figures.\"\"\"\n",
    "\n",
    "def sanitize(s):\n",
    "    \"\"\"Clean up strings for filenames\"\"\"\n",
    "    s2 = re.sub(r'[<>:\"/\\\\|?*]+', \"_\", s)\n",
    "    return re.sub(r\"\\s+\", \" \", s2).strip()\n",
    "\n",
    "def safe_float(x):\n",
    "    \"\"\"Convert to float safely\"\"\"\n",
    "    if x is None: \n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() == \"nan\": \n",
    "        return np.nan\n",
    "    try: \n",
    "        return float(s)\n",
    "    except Exception: \n",
    "        return np.nan\n",
    "\n",
    "def read_group_summary(path):\n",
    "    \"\"\"Read the group summary CSV file\"\"\"\n",
    "    rows = []\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rows.append({\n",
    "                \"method\": row[\"method\"],\n",
    "                \"metric\": row[\"metric\"],\n",
    "                \"mean\":  safe_float(row.get(\"mean\")),\n",
    "                \"sd\":    safe_float(row.get(\"sd\")),\n",
    "                \"n\":     int(safe_float(row.get(\"n_images\")) or 0),\n",
    "                \"lo\":    safe_float(row.get(\"ci95_low\")),\n",
    "                \"hi\":    safe_float(row.get(\"ci95_high\")),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def read_perrep(path):\n",
    "    \"\"\"Read the per-replicate CSV file\"\"\"\n",
    "    rows = []\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        r = csv.DictReader(f)\n",
    "        for row in r:\n",
    "            rows.append({\n",
    "                \"method\": row[\"method\"],\n",
    "                \"replicate\": row[\"replicate\"],\n",
    "                \"f1_dice\": safe_float(row.get(\"f1_dice\")),\n",
    "                \"iou_jaccard\": safe_float(row.get(\"iou_jaccard\")),\n",
    "                \"precision\": safe_float(row.get(\"precision\")),\n",
    "                \"recall\": safe_float(row.get(\"recall\")),\n",
    "                \"specificity\": safe_float(row.get(\"specificity\")),\n",
    "                \"balanced_accuracy\": safe_float(row.get(\"balanced_accuracy\")),\n",
    "                \"accuracy\": safe_float(row.get(\"accuracy\")),\n",
    "                \"mcc\": safe_float(row.get(\"mcc\")),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def table_for_metric(summary_rows, metric):\n",
    "    \"\"\"Get rows for a specific metric\"\"\"\n",
    "    return [r for r in summary_rows if r[\"metric\"] == metric and not np.isnan(r[\"mean\"])]\n",
    "\n",
    "def ci_or_fallback_lo_hi(mean, lo, hi, sd, n):\n",
    "    \"\"\"Calculate confidence interval with fallback\"\"\"\n",
    "    if not np.isnan(lo) and not np.isnan(hi):\n",
    "        return lo, hi\n",
    "    if (sd is not None) and (not np.isnan(sd)) and n is not None and n >= 2:\n",
    "        half = 1.96 * sd / np.sqrt(n)\n",
    "        return mean - half, mean + half\n",
    "    return np.nan, np.nan\n",
    "\n",
    "def save_fig(fig, name_base, dirpath=FIG_DIR):\n",
    "    \"\"\"Save figure as both TIFF and PDF\"\"\"\n",
    "    tif = os.path.join(dirpath, sanitize(name_base) + \".tif\")\n",
    "    pdf = os.path.join(dirpath, sanitize(name_base) + \".pdf\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(tif, dpi=600)\n",
    "    fig.savefig(pdf)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", tif)\n",
    "    print(\"Saved:\", pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50dda69f-e599-4532-828a-6564a5568491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell loads the CSV files containing our calculated metrics \n",
    "so we can create plots and statistical comparisons from the data.\"\"\"\n",
    "\n",
    "# Load data for plotting\n",
    "if not os.path.exists(SUMMARY_CSV):\n",
    "    raise FileNotFoundError(\"Missing: \" + SUMMARY_CSV)\n",
    "if not os.path.exists(PERREP_CSV):\n",
    "    raise FileNotFoundError(\"Missing: \" + PERREP_CSV)\n",
    "\n",
    "summary_rows = read_group_summary(SUMMARY_CSV)\n",
    "perrep_rows  = read_perrep(PERREP_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "495ed772-5efb-4887-9d8f-83354b2eafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell defines functions for performing statistical tests like Wilcoxon tests\n",
    "and sign tests to determine if differences between methods are statistically significant.\"\"\"\n",
    "\n",
    "def build_series_by_replicate(metric):\n",
    "    \"\"\"Return dictionary of method to replicate to value\"\"\"\n",
    "    d = {}\n",
    "    for row in perrep_rows:\n",
    "        m = row[\"method\"]\n",
    "        r = row[\"replicate\"] \n",
    "        v = row[metric]\n",
    "        if np.isnan(v) or r is None or r == \"\": \n",
    "            continue\n",
    "        d.setdefault(m, {})[r] = float(v)\n",
    "    return d\n",
    "\n",
    "def holm_correction(pairs_pvals):\n",
    "    \"\"\"Apply Holm correction for multiple comparisons\"\"\"\n",
    "    ranked = sorted(pairs_pvals, key=lambda x: x[1])\n",
    "    m = len(ranked)\n",
    "    adj = {}\n",
    "    for i, (pair, p) in enumerate(ranked, start=1):\n",
    "        adj[pair] = min(1.0, p * (m - i + 1))\n",
    "    return adj\n",
    "\n",
    "def p_to_stars(p):\n",
    "    \"\"\"Convert p-value to significance stars\"\"\"\n",
    "    if p < 0.001: \n",
    "        return '***'\n",
    "    if p < 0.01:  \n",
    "        return '**'\n",
    "    if p < 0.05:  \n",
    "        return '*'\n",
    "    return ''\n",
    "\n",
    "def wilcoxon_exact_or_pratt(a, b):\n",
    "    \"\"\"Perform Wilcoxon test with exact or approximate method\"\"\"\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    d = a - b\n",
    "    nz = d != 0\n",
    "    n_eff = int(np.count_nonzero(nz))\n",
    "    if n_eff < 2:\n",
    "        return (np.nan, np.nan, n_eff, \"NA\")\n",
    "    if np.all(nz) and n_eff <= 25:\n",
    "        res = wilcoxon(a, b, alternative='two-sided', zero_method='wilcox',\n",
    "                       correction=False, method='exact')\n",
    "        return (float(res.statistic), float(res.pvalue), n_eff, \"exact\")\n",
    "    res = wilcoxon(a, b, alternative='two-sided', zero_method='pratt',\n",
    "                   correction=True, method='approx')\n",
    "    return (float(res.statistic), float(res.pvalue), n_eff, \"approx(pratt)\")\n",
    "\n",
    "def sign_test_two_sided(a, b):\n",
    "    \"\"\"Perform two-sided sign test\"\"\"\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    d = a - b\n",
    "    pos = int(np.sum(d > 0))\n",
    "    neg = int(np.sum(d < 0))\n",
    "    n   = pos + neg\n",
    "    if n == 0:\n",
    "        return (np.nan, 0, 0)\n",
    "    p = binomtest(k=pos, n=n, p=0.5, alternative='two-sided').pvalue\n",
    "    return (float(p), n, pos)\n",
    "\n",
    "def hodges_lehmann(a, b):\n",
    "    \"\"\"Calculate Hodges-Lehmann estimator\"\"\"\n",
    "    d = np.asarray(a, float) - np.asarray(b, float)\n",
    "    return float(np.median(d))\n",
    "\n",
    "def compute_ref_and_holm(metric):\n",
    "    \"\"\"Compute reference method and Holm-corrected p-values\"\"\"\n",
    "    tbl = table_for_metric(summary_rows, metric)\n",
    "    if not tbl: \n",
    "        return None, {}, {}, {}, {}\n",
    "    ref = max(tbl, key=lambda d: d[\"mean\"])[\"method\"]\n",
    "    series = build_series_by_replicate(metric)\n",
    "    methods = sorted(series.keys())\n",
    "    pairs = list(itertools.combinations(methods, 2))\n",
    "\n",
    "    wx_pairs = []\n",
    "    sign_pairs = []\n",
    "    wilcox_cache = {}\n",
    "    sign_cache   = {}\n",
    "\n",
    "    for a, b in pairs:\n",
    "        ra = series.get(a, {})\n",
    "        rb = series.get(b, {})\n",
    "        common = sorted(set(ra.keys()) & set(rb.keys()))\n",
    "        if len(common) < 2:\n",
    "            continue\n",
    "        a_vals = np.array([ra[r] for r in common], float)\n",
    "        b_vals = np.array([rb[r] for r in common], float)\n",
    "\n",
    "        W, p_wx, n_eff, mode = wilcoxon_exact_or_pratt(a_vals, b_vals)\n",
    "        p_sign, n_sign, pos = sign_test_two_sided(a_vals, b_vals)\n",
    "        HL = hodges_lehmann(a_vals, b_vals)\n",
    "        med = float(np.median(a_vals - b_vals))\n",
    "\n",
    "        if not np.isnan(p_wx):  \n",
    "            wx_pairs.append(((a,b), p_wx))\n",
    "        if not np.isnan(p_sign): \n",
    "            sign_pairs.append(((a,b), p_sign))\n",
    "\n",
    "        wilcox_cache[(a,b)] = (n_eff, W, p_wx, mode, HL, med)\n",
    "        sign_cache[(a,b)]   = (n_sign, pos, p_sign)\n",
    "\n",
    "    p_holm_wx   = holm_correction(wx_pairs) if wx_pairs else {}\n",
    "    p_holm_sign = holm_correction(sign_pairs) if sign_pairs else {}\n",
    "    return ref, p_holm_wx, p_holm_sign, wilcox_cache, sign_cache\n",
    "\n",
    "def lookup_pair(dct, a, b, default=np.nan):\n",
    "    \"\"\"Look up pair in dictionary with symmetric fallback\"\"\"\n",
    "    return dct.get((a,b), dct.get((b,a), default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f66e16c2-41f1-494b-a6b5-ca0e5f434eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating bar charts...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates bar charts showing the mean performance of each method with \n",
    "error bars, ranked from best to worst performance for each metric.\"\"\"\n",
    "\n",
    "# Create bar charts for each metric\n",
    "print(\"Creating bar charts...\")\n",
    "for metric in METRICS_ALL:\n",
    "    tbl = table_for_metric(summary_rows, metric)\n",
    "    if not tbl: \n",
    "        continue\n",
    "\n",
    "    tbl.sort(key=lambda d: d[\"mean\"], reverse=True)\n",
    "    methods = [t[\"method\"] for t in tbl]\n",
    "    means   = np.array([t[\"mean\"] for t in tbl], float)\n",
    "\n",
    "    los, his, ns = np.zeros_like(means), np.zeros_like(means), []\n",
    "    for i, t in enumerate(tbl):\n",
    "        lo, hi = ci_or_fallback_lo_hi(t[\"mean\"], t[\"lo\"], t[\"hi\"], t[\"sd\"], t[\"n\"])\n",
    "        los[i], his[i] = lo, hi\n",
    "        ns.append(t[\"n\"])\n",
    "    lower = np.where(np.isnan(los), 0.0, means - los)\n",
    "    upper = np.where(np.isnan(his), 0.0, his - means)\n",
    "    yerr  = np.vstack((lower, upper))\n",
    "\n",
    "    bar_colors = [method_color_and_group(m)[0] for m in methods]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 4.2))\n",
    "    x = np.arange(len(methods))\n",
    "    ax.bar(x, means, color=bar_colors, edgecolor=\"black\", linewidth=0.8)\n",
    "    ax.errorbar(x, means, yerr=yerr, fmt='none', ecolor='black', elinewidth=1.0, capsize=3)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(methods, rotation=45, ha='right')\n",
    "    ax.set_title(FAMILY_TAG + \" [\" + NICE.get(metric, metric) + \"] (n = \" + str(N_IN_TITLE) + \")\")\n",
    "    ax.set_ylabel(NICE.get(metric, metric) + \" (mean Â± 95% CI)\")\n",
    "\n",
    "    y_tops = means + np.where(np.isnan(upper), 0.0, upper)\n",
    "    ylim_top = float(np.nanmax(y_tops) + 0.05)\n",
    "    ax.set_ylim(0, min(1.15, max(1.0, ylim_top)))\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    ax.grid(axis='y', color=str(0.9), linestyle='-', linewidth=0.5)\n",
    "\n",
    "    leg = ax.legend(handles=legend_handles, loc='upper right', frameon=True)\n",
    "    leg.get_frame().set_edgecolor('black')\n",
    "    leg.get_frame().set_linewidth(0.8)\n",
    "    leg.get_frame().set_alpha(1.0)\n",
    "    leg.get_frame().set_facecolor('white')\n",
    "\n",
    "    save_fig(fig, FAMILY_TAG + \" - Bar \" + NICE.get(metric, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9caa774-242a-4cef-90c9-648b064f5d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating boxplots...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates boxplot charts showing the distribution and variability\n",
    "of performance for each method, with individual data points overlaid as dots.\"\"\"\n",
    "\n",
    "# Create boxplots for key metrics\n",
    "print(\"Creating boxplots...\")\n",
    "def build_series(metric):\n",
    "    \"\"\"Build series data for boxplots\"\"\"\n",
    "    methods = sorted(list({x[\"method\"] for x in perrep_rows}))\n",
    "    series = {}\n",
    "    for m in methods:\n",
    "        vals = [x[metric] for x in perrep_rows if x[\"method\"] == m and not np.isnan(x[metric])]\n",
    "        if len(vals) > 0:\n",
    "            series[m] = np.array(vals, float)\n",
    "    return series\n",
    "\n",
    "for metric in BOX_METRICS:\n",
    "    data = build_series(metric)\n",
    "    if not data: \n",
    "        continue\n",
    "\n",
    "    order = sorted(data.keys(), key=lambda m: np.median(data[m]), reverse=True)\n",
    "    vectors = [data[m] for m in order]\n",
    "    box_colors = [method_color_and_group(m)[0] for m in order]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 4.2))\n",
    "    bp = ax.boxplot(\n",
    "        vectors, vert=True, patch_artist=True, tick_labels=order,\n",
    "        whis=1.5, widths=0.65, showmeans=False, manage_ticks=True,\n",
    "    )\n",
    "    for patch, col in zip(bp['boxes'], box_colors):\n",
    "        patch.set(facecolor=col, edgecolor=\"black\", linewidth=0.8)\n",
    "    for whisker in bp['whiskers']: \n",
    "        whisker.set(color=\"black\", linewidth=0.8)\n",
    "    for cap in bp['caps']: \n",
    "        cap.set(color=\"black\", linewidth=0.8)\n",
    "    for median in bp['medians']: \n",
    "        median.set(color=\"black\", linewidth=1.2)\n",
    "    if 'fliers' in bp:\n",
    "        for fl in bp['fliers']:\n",
    "            fl.set(marker='o', markerfacecolor='none', markeredgecolor='black', markersize=3, alpha=0.7)\n",
    "\n",
    "    rng = np.random.default_rng(2025)\n",
    "    for i, vals in enumerate(vectors, start=1):\n",
    "        if len(vals) == 0: \n",
    "            continue\n",
    "        jitter = (rng.random(size=len(vals)) - 0.5) * 0.25\n",
    "        ax.plot(np.full(len(vals), i) + jitter, vals, 'o',\n",
    "                markerfacecolor='none', markeredgecolor='black', markersize=3, alpha=0.6, linewidth=0.8)\n",
    "\n",
    "    y_top = max([np.max(v) if len(v) else 0 for v in vectors] + [1.0])\n",
    "    ax.set_ylim(0, min(1.15, y_top + 0.05))\n",
    "    ax.set_ylabel(NICE.get(metric, metric))\n",
    "    ax.set_title(FAMILY_TAG + \" [\" + NICE.get(metric, metric) + \"] (n = \" + str(N_IN_TITLE) + \")\")\n",
    "    ax.set_xticklabels(order, rotation=45, ha='right')\n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(0.1))\n",
    "    ax.grid(axis='y', color=str(0.92), linestyle='-', linewidth=0.5)\n",
    "\n",
    "    leg = ax.legend(handles=legend_handles, loc='upper right', frameon=True)\n",
    "    leg.get_frame().set_edgecolor('black')\n",
    "    leg.get_frame().set_linewidth(0.8)\n",
    "    leg.get_frame().set_alpha(1.0)\n",
    "    leg.get_frame().set_facecolor('white')\n",
    "\n",
    "    save_fig(fig, FAMILY_TAG + \" - Boxplot \" + NICE.get(metric, metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9199c940-9d11-4fd9-a6e7-54e961112980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating heatmap...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m M \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(M, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     16\u001b[0m primary_idx \u001b[38;5;241m=\u001b[39m [HEAT_METRICS\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_dice\u001b[39m\u001b[38;5;124m\"\u001b[39m), HEAT_METRICS\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miou_jaccard\u001b[39m\u001b[38;5;124m\"\u001b[39m), HEAT_METRICS\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmcc\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m---> 17\u001b[0m order_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mnanmean(\u001b[43mM\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimary_idx\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     18\u001b[0m methods_sorted \u001b[38;5;241m=\u001b[39m [methods_all[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m order_idx]\n\u001b[0;32m     19\u001b[0m M_sorted \u001b[38;5;241m=\u001b[39m M[order_idx]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates a heatmap showing all performance metrics for all methods\n",
    "in a grid format, with darker colors indicating better performance.\"\"\"\n",
    "\n",
    "# Create heatmap of mean metrics\n",
    "print(\"Creating heatmap...\")\n",
    "methods_all = sorted(list({r[\"method\"] for r in summary_rows}))\n",
    "M = []\n",
    "for m in methods_all:\n",
    "    row_vals = []\n",
    "    for metric in HEAT_METRICS:\n",
    "        matches = [r for r in summary_rows if r[\"method\"] == m and r[\"metric\"] == metric]\n",
    "        row_vals.append(matches[0][\"mean\"] if matches and not np.isnan(matches[0][\"mean\"]) else np.nan)\n",
    "    M.append(row_vals)\n",
    "M = np.array(M, float)\n",
    "\n",
    "primary_idx = [HEAT_METRICS.index(\"f1_dice\"), HEAT_METRICS.index(\"iou_jaccard\"), HEAT_METRICS.index(\"mcc\")]\n",
    "order_idx = np.argsort(-np.nanmean(M[:, primary_idx], axis=1))\n",
    "methods_sorted = [methods_all[i] for i in order_idx]\n",
    "M_sorted = M[order_idx]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6.6, 0.45*len(methods_sorted) + 1.2))\n",
    "im = ax.imshow(M_sorted, aspect=\"auto\", cmap=\"Greys\", vmin=0, vmax=1.0)\n",
    "for i in range(M_sorted.shape[0]):\n",
    "    for j in range(M_sorted.shape[1]):\n",
    "        v = M_sorted[i, j]\n",
    "        if np.isnan(v): \n",
    "            continue\n",
    "        ax.text(j, i, str(round(v,2)), ha='center', va='center', color='black')\n",
    "ax.set_xticks(np.arange(len(HEAT_METRICS)))\n",
    "ax.set_xticklabels([NICE.get(m, m) for m in HEAT_METRICS], rotation=45, ha='right')\n",
    "ax.set_yticks(np.arange(len(methods_sorted)))\n",
    "ax.set_yticklabels(methods_sorted)\n",
    "ax.set_title(FAMILY_TAG + \" â Mean metrics (methods Ã metrics)\")\n",
    "cbar = fig.colorbar(im, ax=ax, fraction=0.03, pad=0.03)\n",
    "cbar.set_label(\"Mean (0â1)\")\n",
    "save_fig(fig, FAMILY_TAG + \" - Heatmap mean metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de434c4c-3598-444b-9528-00a4ebd6638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing statistical test results...\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Stats\\KruskalWallis [CRYO-SEM X30000].csv\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Stats\\Wilcoxon_Pairs [CRYO-SEM X30000].csv\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Stats\\Wilcoxon_vsRef [CRYO-SEM X30000].csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell performs comprehensive statistical testing including Kruskal-Wallis tests,\n",
    "pairwise Wilcoxon tests, and comparisons against the best reference method,\n",
    "saving all results to CSV files.\"\"\"\n",
    "\n",
    "# Generate statistical test CSVs\n",
    "print(\"Writing statistical test results...\")\n",
    "def write_stats_csvs():\n",
    "    \"\"\"Write statistical test results to CSV files\"\"\"\n",
    "    kw_path  = os.path.join(STATS_DIR, \"KruskalWallis [\" + FAMILY_TAG + \"].csv\")\n",
    "    wx_path  = os.path.join(STATS_DIR, \"Wilcoxon_Pairs [\" + FAMILY_TAG + \"].csv\")\n",
    "    vr_path  = os.path.join(STATS_DIR, \"Wilcoxon_vsRef [\" + FAMILY_TAG + \"].csv\")\n",
    "\n",
    "    with open(kw_path, \"w\", newline=\"\", encoding=\"utf-8\") as fkw, \\\n",
    "         open(wx_path, \"w\", newline=\"\", encoding=\"utf-8\") as fwx, \\\n",
    "         open(vr_path, \"w\", newline=\"\", encoding=\"utf-8\") as fvr:\n",
    "\n",
    "        kw_writer = csv.writer(fkw)\n",
    "        kw_writer.writerow([\"metric\",\"k_groups\",\"H\",\"p_value\"])\n",
    "        wx_writer = csv.writer(fwx)\n",
    "        wx_writer.writerow([\n",
    "            \"metric\",\"method_A\",\"method_B\",\"n_common\",\n",
    "            \"wilcoxon_n_eff\",\"wilcoxon_W\",\"wilcoxon_p_raw\",\"wilcoxon_mode\",\"wilcoxon_p_holm\",\n",
    "            \"sign_n\",\"sign_pos\",\"sign_p_raw\",\"sign_p_holm\",\n",
    "            \"HL_estimate(A-B)\",\"median_diff(A-B)\"\n",
    "        ])\n",
    "        vr_writer = csv.writer(fvr)\n",
    "        vr_writer.writerow([\n",
    "            \"metric\",\"reference\",\"method\",\"n_common\",\n",
    "            \"wilcoxon_n_eff\",\"wilcoxon_W\",\"wilcoxon_p_raw\",\"wilcoxon_mode\",\"wilcoxon_p_holm\",\"stars\",\n",
    "            \"sign_n\",\"sign_pos\",\"sign_p_raw\",\"sign_p_holm\",\n",
    "            \"HL_estimate(ref - method)\",\"median_diff(ref - method)\"\n",
    "        ])\n",
    "\n",
    "        for metric in METRICS_ALL:\n",
    "            ser = build_series_by_replicate(metric)\n",
    "            groups = [np.array(list(d.values()), float) for d in ser.values() if len(d) >= 2]\n",
    "            if len(groups) >= 2:\n",
    "                H, p = kruskal(*groups, nan_policy='omit')\n",
    "                kw_writer.writerow([metric, len(groups), float(H), float(p)])\n",
    "\n",
    "        for metric in METRICS_ALL:\n",
    "            ser = build_series_by_replicate(metric)\n",
    "            methods = sorted(ser.keys())\n",
    "            pairs = list(itertools.combinations(methods, 2))\n",
    "\n",
    "            wx_p_raw_pairs = []\n",
    "            temp_rows = []\n",
    "            for a, b in pairs:\n",
    "                ra, rb = ser[a], ser[b]\n",
    "                common = sorted(set(ra.keys()) & set(rb.keys()))\n",
    "                if len(common) < 2:\n",
    "                    continue\n",
    "                a_vals = np.array([ra[r] for r in common], float)\n",
    "                b_vals = np.array([rb[r] for r in common], float)\n",
    "\n",
    "                W, p_wx, n_eff, mode = wilcoxon_exact_or_pratt(a_vals, b_vals)\n",
    "                p_sign, n_sign, pos = sign_test_two_sided(a_vals, b_vals)\n",
    "                HL = hodges_lehmann(a_vals, b_vals)\n",
    "                med = float(np.median(a_vals - b_vals))\n",
    "                if not np.isnan(p_wx): \n",
    "                    wx_p_raw_pairs.append(((a,b), p_wx))\n",
    "                temp_rows.append((a,b,len(common), n_eff, W, p_wx, mode, n_sign, pos, p_sign, HL, med))\n",
    "\n",
    "            holm_wx = holm_correction(wx_p_raw_pairs) if wx_p_raw_pairs else {}\n",
    "            sign_p_raw_pairs = [((a,b), p_sign) for (a,b,_,_,_,_,_,_,_,p_sign,_,_) in temp_rows if not np.isnan(p_sign)]\n",
    "            holm_sign = holm_correction(sign_p_raw_pairs) if sign_p_raw_pairs else {}\n",
    "\n",
    "            for a,b,n_common, n_eff,W,p_wx,mode,n_sign,pos,p_sign,HL,med in temp_rows:\n",
    "                wx_writer.writerow([\n",
    "                    metric, a, b, n_common,\n",
    "                    n_eff, W, p_wx, mode, holm_wx.get((a,b), holm_wx.get((b,a), np.nan)),\n",
    "                    n_sign, pos, p_sign, holm_sign.get((a,b), holm_sign.get((b,a), np.nan)),\n",
    "                    HL, med\n",
    "                ])\n",
    "\n",
    "            ref, p_holm_wx_m, p_holm_sign_m, wilcox_cache_m, sign_cache_m = compute_ref_and_holm(metric)\n",
    "            if ref is not None:\n",
    "                for m in methods:\n",
    "                    if m == ref: \n",
    "                        continue\n",
    "                    n_eff, W, p_wx_raw, mode, HL, med = lookup_pair(wilcox_cache_m, ref, m, (np.nan,)*6)\n",
    "                    p_wx_holm = lookup_pair(p_holm_wx_m, ref, m, np.nan)\n",
    "                    n_sign, pos, p_sign_raw = lookup_pair(sign_cache_m, ref, m, (np.nan,)*3)\n",
    "                    p_sign_holm = lookup_pair(p_holm_sign_m, ref, m, np.nan)\n",
    "                    p_for_star = p_wx_holm if not np.isnan(p_wx_holm) else p_sign_holm\n",
    "                    stars = p_to_stars(p_for_star) if not np.isnan(p_for_star) and p_for_star < 0.05 else ''\n",
    "                    vr_writer.writerow([\n",
    "                        metric, ref, m, \n",
    "                        int(n_eff) if not np.isnan(n_eff) else np.nan,\n",
    "                        n_eff, W, p_wx_raw, mode, p_wx_holm, stars,\n",
    "                        n_sign, pos, p_sign_raw, p_sign_holm,\n",
    "                        HL, med\n",
    "                    ])\n",
    "\n",
    "    print(\"Saved:\", kw_path)\n",
    "    print(\"Saved:\", wx_path)\n",
    "    print(\"Saved:\", vr_path)\n",
    "\n",
    "write_stats_csvs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732493a-9216-4ed7-a77a-76e09ac0a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Bland-Altman plots...\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Dice (F1)] A=ILASTIK vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [IoU (Jaccard)] A=ILASTIK vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Matthews CC] A=ILASTIK vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=ILASTIK.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=ILASTIK.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Precision] A=SEMI vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=ILASTIK.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=ILASTIK.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Recall (Sensitivity)] A=60% vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=ILASTIK.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=ILASTIK.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Specificity] A=SEMI vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Balanced Accuracy] A=ILASTIK vs B=UNET.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=60%.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=60%.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=FREEHAND.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=FREEHAND.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=OTSU.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=OTSU.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=OVAL.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=OVAL.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=PLANKSTER.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=PLANKSTER.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=PORED2.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=PORED2.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=SAMJ.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=SAMJ.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=SEMI.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=SEMI.pdf\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=UNET.tif\n",
      "Saved: C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\\CRYO-SEM X30000 - Bland-Altman [Accuracy] A=ILASTIK vs B=UNET.pdf\n",
      "BlandâAltman: EXPORTED to C:\\Users\\walsh\\Documents\\GitHub\\AGAROSE-HYDROGEL-TRENDS-USING-AI-ML\\MULTIPLE GS METHOD\\Figures\\Bland-Altman\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This cell creates Bland-Altman plots that show agreement between different methods\n",
    "by plotting the difference versus the average, helping identify bias and limits of\n",
    "agreement.\"\"\"\n",
    "\n",
    "# Create Bland-Altman plots\n",
    "print(\"Creating Bland-Altman plots...\")\n",
    "def bland_altman_plot(a_vals, b_vals, title, outfile_base, dirpath=BA_DIR):\n",
    "    \"\"\"Create a Bland-Altman agreement plot\"\"\"\n",
    "    a_vals = np.asarray(a_vals, float)\n",
    "    b_vals = np.asarray(b_vals, float)\n",
    "    means = (a_vals + b_vals) / 2.0\n",
    "    diffs = a_vals - b_vals\n",
    "    n = len(diffs)\n",
    "\n",
    "    bias = float(np.mean(diffs))\n",
    "    sd = float(np.std(diffs, ddof=1)) if n > 1 else 0.0\n",
    "\n",
    "    # Use t-based quantile for 95% CI with fallback to 1.96\n",
    "    q = float(analysis_t.ppf(0.975, n-1)) if n > 1 else 1.96\n",
    "\n",
    "    loa_hi = bias + q * sd\n",
    "    loa_lo = bias - q * sd\n",
    "\n",
    "    # Calculate 95% CI for bias and limits of agreement\n",
    "    se_bias = sd / np.sqrt(n) if n > 0 else np.nan\n",
    "    se_loa  = sd * np.sqrt((1.0/n) + (q**2)/(2.0*(n-1))) if n > 1 else np.nan\n",
    "\n",
    "    bias_ci_lo = bias - q*se_bias if np.isfinite(se_bias) else np.nan\n",
    "    bias_ci_hi = bias + q*se_bias if np.isfinite(se_bias) else np.nan\n",
    "\n",
    "    loa_hi_ci_lo = loa_hi - q*se_loa if np.isfinite(se_loa) else np.nan\n",
    "    loa_hi_ci_hi = loa_hi + q*se_loa if np.isfinite(se_loa) else np.nan\n",
    "    loa_lo_ci_lo = loa_lo - q*se_loa if np.isfinite(se_loa) else np.nan\n",
    "    loa_lo_ci_hi = loa_lo + q*se_loa if np.isfinite(se_loa) else np.nan\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5.0, 3.6))\n",
    "\n",
    "    # Add confidence bands first so they appear behind points\n",
    "    if np.isfinite(bias_ci_lo) and np.isfinite(bias_ci_hi):\n",
    "        ax.axhspan(bias_ci_lo, bias_ci_hi, alpha=0.12, color='blue', linewidth=0, zorder=1)\n",
    "    if np.isfinite(loa_hi_ci_lo) and np.isfinite(loa_hi_ci_hi):\n",
    "        ax.axhspan(loa_hi_ci_lo, loa_hi_ci_hi, alpha=0.15, color='red', linewidth=0, zorder=1)\n",
    "    if np.isfinite(loa_lo_ci_lo) and np.isfinite(loa_lo_ci_hi):\n",
    "        ax.axhspan(loa_lo_ci_lo, loa_lo_ci_hi, alpha=0.15, color='red', linewidth=0, zorder=1)\n",
    "\n",
    "    # Plot the data points\n",
    "    ax.plot(means, diffs, 'o', markerfacecolor='none', markeredgecolor='black',\n",
    "            markersize=4, alpha=0.85, zorder=2)\n",
    "\n",
    "    # Add the main lines\n",
    "    ax.axhline(bias,  linestyle='-',  color='blue', linewidth=1.1, label='Bias', zorder=3)\n",
    "    ax.axhline(loa_hi, linestyle='--', color='red',  linewidth=1.0, label='LoA',  zorder=3)\n",
    "    ax.axhline(loa_lo, linestyle='--', color='red',  linewidth=1.0,               zorder=3)\n",
    "\n",
    "    ax.set_xlabel(\"Mean of pair\")\n",
    "    ax.set_ylabel(\"Difference (A â B)\")\n",
    "    ax.set_title(title)\n",
    "    ax.grid(axis='both', color=str(0.92), linestyle='-', linewidth=0.5)\n",
    "\n",
    "    handles = [\n",
    "        Line2D([0], [0], color='blue', lw=1.2, label='Bias (Â±95% CI)'),\n",
    "        Line2D([0], [0], color='red',  lw=1.0, linestyle='--', label='LoA (Â±95% CI)'),\n",
    "    ]\n",
    "    ax.legend(handles=handles, loc='lower right', frameon=True)\n",
    "\n",
    "    # Add text annotation with statistics\n",
    "    ann = [\n",
    "        \"Bias=\" + str(round(bias,3)) + (\" (95% CI \" + str(round(bias_ci_lo,3)) + \" to \" + str(round(bias_ci_hi,3)) + \")\" if np.isfinite(bias_ci_lo) else \"\"),\n",
    "        \"LoA+=\" + str(round(loa_hi,3)) + (\" (95% CI \" + str(round(loa_hi_ci_lo,3)) + \" to \" + str(round(loa_hi_ci_hi,3)) + \")\" if np.isfinite(loa_hi_ci_lo) else \"\"),\n",
    "        \"LoAâ=\" + str(round(loa_lo,3)) + (\" (95% CI \" + str(round(loa_lo_ci_lo,3)) + \" to \" + str(round(loa_lo_ci_hi,3)) + \")\" if np.isfinite(loa_lo_ci_lo) else \"\"),\n",
    "    ]\n",
    "    ax.text(0.02, 0.98, \"\\n\".join(ann), transform=ax.transAxes,\n",
    "            ha='left', va='top', fontsize=8,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", facecolor=\"white\", edgecolor=\"black\", linewidth=0.6))\n",
    "\n",
    "    save_fig(fig, outfile_base, dirpath=dirpath)\n",
    "\n",
    "if ENABLE_BLAND_ALTMAN:\n",
    "    for metric in METRICS_ALL:\n",
    "        # Build series data for Bland-Altman analysis\n",
    "        series = {}\n",
    "        for row in perrep_rows:\n",
    "            v = row[metric]\n",
    "            if np.isnan(v): \n",
    "                continue\n",
    "            series.setdefault(row[\"method\"], {})[row[\"replicate\"]] = float(v)\n",
    "        methods = sorted(series.keys())\n",
    "        if len(methods) < 2:\n",
    "            continue\n",
    "\n",
    "        # Choose pairs for comparison\n",
    "        pairs = []\n",
    "        if BA_PAIRS_VS_REF_ONLY:\n",
    "            tbl = table_for_metric(summary_rows, metric)\n",
    "            if not tbl: \n",
    "                continue\n",
    "            ref = max(tbl, key=lambda d: d[\"mean\"])[\"method\"]\n",
    "            for m in methods:\n",
    "                if m == ref: \n",
    "                    continue\n",
    "                pairs.append((ref, m))\n",
    "        else:\n",
    "            pairs = list(itertools.combinations(methods, 2))\n",
    "\n",
    "        for A, B in pairs:\n",
    "            ra, rb = series.get(A, {}), series.get(B, {})\n",
    "            common = sorted(set(ra.keys()) & set(rb.keys()))\n",
    "            if len(common) < BA_MIN_COMMON:\n",
    "                continue\n",
    "            a_vals = [ra[r] for r in common]\n",
    "            b_vals = [rb[r] for r in common]\n",
    "            title = FAMILY_TAG + \" â BlandâAltman [\" + NICE.get(metric, metric) + \"]\\nA=\" + A + \" vs B=\" + B + \" (n=\" + str(len(common)) + \")\"\n",
    "            base = FAMILY_TAG + \" - Bland-Altman [\" + NICE.get(metric, metric) + \"] A=\" + A + \" vs B=\" + B\n",
    "            bland_altman_plot(a_vals, b_vals, title, base)\n",
    "\n",
    "    print(\"BlandâAltman: EXPORTED to\", BA_DIR)\n",
    "else:\n",
    "    print(\"BlandâAltman: SKIPPED (set ENABLE_BLAND_ALTMAN=True to export)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8f4e4-c59c-4362-89f4-0e5b0adb452a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pore-acc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
