{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0401b0bd-5344-4b14-a825-3907d73309ec",
   "metadata": {},
   "source": [
    "## **SPLIT CELLS SINGLE GOLD STANDARD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e1156-8900-415b-905e-7ed02bb96467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STED analysis script\n",
    "# This script reads pore masks and measures how good each method is\n",
    "\n",
    "import math\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.stats import kruskal, wilcoxon\n",
    "\n",
    "\"\"\"\n",
    "Set up file paths and basic settings\n",
    "We need to tell the script where to find the image files\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd()\n",
    "proj_root = notebook_dir.parent\n",
    "org_dir = str(proj_root)\n",
    "\n",
    "# Where the original TIFF images are stored\n",
    "#base_dir = r\"C:\\Users\\walsh\\Downloads\\STED Accuracy INTERNAL\\Internal 0.375%\"\n",
    "base_dir = os.path.join(org_dir , \"[STED] Internal 0.375%\")\n",
    "\n",
    "# Where to save all the results\n",
    "results_folder = os.path.join(org_dir , \"SINGLE GS METHOD\")\n",
    "\n",
    "# The gold standard image (what we compare everything to)\n",
    "gold_image_path = os.path.join(base_dir , \"GOLD STANDARD.tif\")\n",
    "\n",
    "# List of all the method images we want to test\n",
    "method_image_paths = [\n",
    "    os.path.join(base_dir , \"60%.tif\"),\n",
    "    os.path.join(base_dir , \"FREEHAND.tif\"), \n",
    "    os.path.join(base_dir , \"ILASTIK.tif\"),\n",
    "    os.path.join(base_dir , \"OVAL.tif\"),\n",
    "    os.path.join(base_dir , \"OTSU.tif\"),\n",
    "    os.path.join(base_dir , \"PLANKSTER.tif\"),\n",
    "    os.path.join(base_dir , \"PORED2.tif\"),\n",
    "    os.path.join(base_dir , \"SAMJ.tif\"),\n",
    "    os.path.join(base_dir , \"SEMI.tif\"),\n",
    "    os.path.join(base_dir , \"UNET.tif\")\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Basic settings for the analysis\n",
    "\"\"\"\n",
    "\n",
    "# What to call this experiment in the results\n",
    "experiment_name = \"[STED 0.375%]\"\n",
    "\n",
    "# Make folders to save results\n",
    "accuracy_folder = os.path.join(results_folder, \"Accuracy\")\n",
    "figures_folder = results_folder\n",
    "stats_folder = os.path.join(results_folder, \"Stats\")\n",
    "\n",
    "# Size of image patches to analyze (64x64 pixels)\n",
    "patch_size = 64\n",
    "\n",
    "# Make sure the folders exist\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "os.makedirs(accuracy_folder, exist_ok=True)\n",
    "os.makedirs(stats_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deca650f-dd47-4ab5-8116-68f00240546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read images and convert them to binary masks\n",
    "# Pores are black pixels, we convert them to white (value 1)\n",
    "\n",
    "\"\"\"\n",
    "Try to import image reading libraries\n",
    "We use different libraries as backup in case one doesn't work\n",
    "\"\"\"\n",
    "try:\n",
    "    import tifffile as tiff\n",
    "    has_tifffile = True\n",
    "except:\n",
    "    has_tifffile = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "    has_pil = True\n",
    "except:\n",
    "    has_pil = False\n",
    "\n",
    "def read_image_file(file_path):\n",
    "    \"\"\"\n",
    "    Read an image file using different methods\n",
    "    Try OpenCV first, then other libraries if that fails\n",
    "    \"\"\"\n",
    "    # Try OpenCV first\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        return img\n",
    "    \n",
    "    # Try tifffile library if available\n",
    "    if has_tifffile:\n",
    "        try:\n",
    "            return tiff.imread(file_path)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Try PIL as last option\n",
    "    if has_pil:\n",
    "        try:\n",
    "            with Image.open(file_path) as pil_img:\n",
    "                return np.array(pil_img.convert(\"L\"))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "def make_grayscale(image_array):\n",
    "    \"\"\"\n",
    "    Convert image to grayscale if it has multiple channels\n",
    "    \"\"\"\n",
    "    if image_array is None:\n",
    "        return None\n",
    "    \n",
    "    # Already grayscale\n",
    "    if len(image_array.shape) == 2:\n",
    "        return image_array\n",
    "    \n",
    "    # Color image - convert to grayscale\n",
    "    if len(image_array.shape) == 3:\n",
    "        return cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    return image_array\n",
    "\n",
    "def convert_to_binary(gray_image):\n",
    "    \"\"\"\n",
    "    Convert grayscale image to binary\n",
    "    Black pixels (pores) become 1, white pixels become 0\n",
    "    \"\"\"\n",
    "    # Check if image is already binary (only 2 values)\n",
    "    unique_values = np.unique(gray_image)\n",
    "    if len(unique_values) == 2:\n",
    "        # Make black pixels = 1, white pixels = 0\n",
    "        black_value = unique_values[0]\n",
    "        binary_image = (gray_image == black_value).astype(np.uint8)\n",
    "        return binary_image\n",
    "    \n",
    "    # Use automatic thresholding to make binary\n",
    "    _, threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Convert so black pixels = 1\n",
    "    binary_image = (threshold_image == 0).astype(np.uint8)\n",
    "    return binary_image\n",
    "\n",
    "def load_mask_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image file and convert it to a binary mask\n",
    "    \"\"\"\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Error: file not found -\", image_path)\n",
    "        return None\n",
    "    \n",
    "    # Read the image\n",
    "    raw_image = read_image_file(image_path)\n",
    "    if raw_image is None:\n",
    "        print(\"Error: could not read image -\", image_path)\n",
    "        return None\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = make_grayscale(raw_image)\n",
    "    \n",
    "    # Convert to binary mask\n",
    "    binary_mask = convert_to_binary(gray_image)\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "\"\"\"\n",
    "Load the gold standard image (the correct answer we compare to)\n",
    "\"\"\"\n",
    "gold_standard_mask = load_mask_image(gold_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef878f62-3257-41c0-bb8b-0d7d73102600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis of all methods...\n",
      "Testing method: 60%\n",
      "  Patches: 81 Mean Dice: 0.65\n",
      "Testing method: FREEHAND\n",
      "  Patches: 81 Mean Dice: 0.167\n",
      "Testing method: OVAL\n",
      "  Patches: 81 Mean Dice: 0.138\n",
      "Testing method: ILASTIK\n",
      "  Patches: 81 Mean Dice: 0.541\n",
      "Testing method: OTSU\n",
      "  Patches: 81 Mean Dice: 0.031\n",
      "Testing method: PLANKSTER\n",
      "  Patches: 81 Mean Dice: 0.635\n",
      "Testing method: PORED2\n",
      "  Patches: 81 Mean Dice: 0.511\n",
      "Testing method: SAMJ\n",
      "  Patches: 81 Mean Dice: 0.126\n",
      "Testing method: SEMI\n",
      "  Patches: 81 Mean Dice: 0.663\n",
      "Testing method: UNET\n",
      "  Patches: 81 Mean Dice: 0.628\n",
      "Methods tested: 10\n"
     ]
    }
   ],
   "source": [
    "# Calculate how good each method is at finding pores\n",
    "# We skip making overlay images to save time\n",
    "\n",
    "import math\n",
    "\n",
    "\"\"\"\n",
    "Helper functions to calculate basic metrics\n",
    "\"\"\"\n",
    "\n",
    "def count_pixels(true_mask, predicted_mask):\n",
    "    \"\"\"\n",
    "    Count true positives, false positives, etc.\n",
    "    \"\"\"\n",
    "    # Make sure both masks are 0s and 1s\n",
    "    true_binary = (true_mask > 0).astype(int)\n",
    "    pred_binary = (predicted_mask > 0).astype(int)\n",
    "    \n",
    "    # Count each type of pixel (convert to regular Python numbers)\n",
    "    true_positive = int(np.sum((true_binary == 1) & (pred_binary == 1)))\n",
    "    true_negative = int(np.sum((true_binary == 0) & (pred_binary == 0)))\n",
    "    false_positive = int(np.sum((true_binary == 0) & (pred_binary == 1)))\n",
    "    false_negative = int(np.sum((true_binary == 1) & (pred_binary == 0)))\n",
    "    \n",
    "    return true_positive, false_positive, true_negative, false_negative\n",
    "\n",
    "def safe_divide(top_number, bottom_number):\n",
    "    \"\"\"\n",
    "    Divide two numbers safely (avoid dividing by zero)\n",
    "    \"\"\"\n",
    "    if bottom_number == 0:\n",
    "        return 0.0\n",
    "    return float(top_number) / float(bottom_number)\n",
    "\n",
    "def calculate_metrics(true_mask, predicted_mask):\n",
    "    \"\"\"\n",
    "    Calculate all the important metrics for comparing masks\n",
    "    \"\"\"\n",
    "    tp, fp, tn, fn = count_pixels(true_mask, predicted_mask)\n",
    "\n",
    "    # Basic metrics\n",
    "    accuracy = safe_divide(tp + tn, tp + tn + fp + fn)\n",
    "    precision = safe_divide(tp, tp + fp)\n",
    "    recall = safe_divide(tp, tp + fn)\n",
    "    specificity = safe_divide(tn, tn + fp)\n",
    "\n",
    "    # Combined metrics\n",
    "    balanced_accuracy = 0.5 * (recall + specificity)\n",
    "    dice_score = safe_divide(2 * tp, 2 * tp + fp + fn)\n",
    "    iou_score = safe_divide(tp, tp + fp + fn)\n",
    "\n",
    "    # MCC calculation (avoid overflow by using floats)\n",
    "    mcc = 0.0\n",
    "    try:\n",
    "        # Convert everything to float first to avoid overflow\n",
    "        tp_f = float(tp)\n",
    "        tn_f = float(tn)\n",
    "        fp_f = float(fp)\n",
    "        fn_f = float(fn)\n",
    "        \n",
    "        # Calculate denominator parts separately\n",
    "        denom1 = (tp_f + fp_f) * (tp_f + fn_f)\n",
    "        denom2 = (tn_f + fp_f) * (tn_f + fn_f)\n",
    "        \n",
    "        if denom1 > 0 and denom2 > 0:\n",
    "            denominator = math.sqrt(denom1 * denom2)\n",
    "            if denominator > 0:\n",
    "                numerator = (tp_f * tn_f) - (fp_f * fn_f)\n",
    "                mcc = numerator / denominator\n",
    "                # Keep MCC between -1 and 1\n",
    "                mcc = max(-1.0, min(1.0, mcc))\n",
    "    except:\n",
    "        mcc = 0.0\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"specificity\": specificity,\n",
    "        \"balanced_accuracy\": balanced_accuracy,\n",
    "        \"f1_dice\": dice_score,\n",
    "        \"iou_jaccard\": iou_score,\n",
    "        \"mcc\": mcc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "\n",
    "def analyze_image_patches(true_mask, predicted_mask, patch_size=64):\n",
    "    \"\"\"\n",
    "    Break image into small squares and calculate metrics for each\n",
    "    \"\"\"\n",
    "    height, width = true_mask.shape\n",
    "    patch_results = []\n",
    "    \n",
    "    # Go through image in patch_size x patch_size squares\n",
    "    for y in range(0, height, patch_size):\n",
    "        for x in range(0, width, patch_size):\n",
    "            # Get the boundaries of this patch\n",
    "            y_end = min(y + patch_size, height)\n",
    "            x_end = min(x + patch_size, width)\n",
    "            \n",
    "            # Extract the patch from both images\n",
    "            true_patch = true_mask[y:y_end, x:x_end]\n",
    "            pred_patch = predicted_mask[y:y_end, x:x_end]\n",
    "            \n",
    "            # Skip tiny patches\n",
    "            if true_patch.size < 10:\n",
    "                continue\n",
    "            \n",
    "            # Calculate metrics for this patch\n",
    "            patch_metrics = calculate_metrics(true_patch, pred_patch)\n",
    "            patch_results.append(patch_metrics)\n",
    "    \n",
    "    return patch_results\n",
    "\n",
    "\"\"\"\n",
    "Test each segmentation method\n",
    "\"\"\"\n",
    "method_names = []\n",
    "method_results = {}\n",
    "\n",
    "print(\"Starting analysis of all methods...\")\n",
    "\n",
    "for method_path in method_image_paths:\n",
    "    # Get the method name from the file path\n",
    "    method_name = os.path.basename(method_path).replace('.tif', '')\n",
    "    method_names.append(method_name)\n",
    "    \n",
    "    print(\"Testing method:\", method_name)\n",
    "    \n",
    "    try:\n",
    "        # Load the predicted mask\n",
    "        predicted_mask = load_mask_image(method_path)\n",
    "        \n",
    "        # Check if images are the same size\n",
    "        if gold_standard_mask.shape != predicted_mask.shape:\n",
    "            print(\"  Error: size mismatch for\", method_name)\n",
    "            continue\n",
    "        \n",
    "        # Analyze this method using patches\n",
    "        patch_results = analyze_image_patches(gold_standard_mask, predicted_mask, patch_size)\n",
    "        \n",
    "        # If no patches, analyze the whole image\n",
    "        if len(patch_results) == 0:\n",
    "            whole_image_result = calculate_metrics(gold_standard_mask, predicted_mask)\n",
    "            patch_results = [whole_image_result]\n",
    "        \n",
    "        # Store results\n",
    "        method_results[method_name] = patch_results\n",
    "        \n",
    "        # Print quick summary\n",
    "        dice_scores = [result[\"f1_dice\"] for result in patch_results]\n",
    "        mean_dice = np.mean(dice_scores)\n",
    "        \n",
    "        print(\"  Patches:\", len(patch_results), \"Mean Dice:\", round(mean_dice, 3))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"  Error processing\", method_name, \":\", str(e))\n",
    "        continue\n",
    "\n",
    "print(\"Methods tested:\", len(method_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a8e9c8-7fb6-475e-862f-6f943bfc1aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best method (highest Dice score): SEMI\n"
     ]
    }
   ],
   "source": [
    "# Compare methods to find the best one and see how they differ\n",
    "# We use statistical tests to see which differences are real\n",
    "\n",
    "\"\"\"\n",
    "Find the best method (highest average Dice score)\n",
    "\"\"\"\n",
    "method_dice_averages = {}\n",
    "for method_name, results_list in method_results.items():\n",
    "    dice_scores = [result[\"f1_dice\"] for result in results_list]\n",
    "    average_dice = np.mean(dice_scores)\n",
    "    method_dice_averages[method_name] = average_dice\n",
    "\n",
    "# Find which method has the highest average\n",
    "best_method = max(method_dice_averages, key=method_dice_averages.get)\n",
    "print(\"Best method (highest Dice score):\", best_method)\n",
    "\n",
    "\"\"\"\n",
    "Compare all other methods to the best one\n",
    "Simple statistical comparison without complex bootstrap\n",
    "\"\"\"\n",
    "best_method_scores = [result[\"f1_dice\"] for result in method_results[best_method]]\n",
    "\n",
    "comparison_results = []\n",
    "for method_name, results_list in method_results.items():\n",
    "    if method_name == best_method:\n",
    "        continue  # Skip comparing best method to itself\n",
    "    \n",
    "    method_scores = [result[\"f1_dice\"] for result in results_list]\n",
    "    \n",
    "    # Calculate basic difference\n",
    "    best_avg = np.mean(best_method_scores)\n",
    "    method_avg = np.mean(method_scores)\n",
    "    difference = best_avg - method_avg\n",
    "    \n",
    "    # Simple statistical test\n",
    "    if len(method_scores) > 1 and len(best_method_scores) > 1:\n",
    "        try:\n",
    "            from scipy.stats import ttest_rel\n",
    "            stat, p_value = ttest_rel(best_method_scores[:len(method_scores)], method_scores)\n",
    "        except:\n",
    "            p_value = 1.0  # If test fails, assume no difference\n",
    "    else:\n",
    "        p_value = 1.0\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'method': method_name,\n",
    "        'difference': difference,\n",
    "        'p_value': p_value\n",
    "    })\n",
    "\n",
    "# Sort by p-value (most significant first)\n",
    "comparison_results.sort(key=lambda x: x['p_value'])\n",
    "\n",
    "\"\"\"\n",
    "Calculate pore fraction bias (does method find too many or too few pores?)\n",
    "\"\"\"\n",
    "def calculate_pore_fraction(mask):\n",
    "    \"\"\"Calculate what fraction of pixels are pores\"\"\"\n",
    "    return np.mean(mask)\n",
    "\n",
    "def get_patch_pore_fractions(true_mask, pred_mask, patch_size=64):\n",
    "    \"\"\"Get pore fractions for each patch\"\"\"\n",
    "    height, width = true_mask.shape\n",
    "    true_fractions = []\n",
    "    pred_fractions = []\n",
    "    \n",
    "    for y in range(0, height, patch_size):\n",
    "        for x in range(0, width, patch_size):\n",
    "            y_end = min(y + patch_size, height)\n",
    "            x_end = min(x + patch_size, width)\n",
    "            \n",
    "            true_patch = true_mask[y:y_end, x:x_end]\n",
    "            pred_patch = pred_mask[y:y_end, x:x_end]\n",
    "            \n",
    "            if true_patch.size < 10:  # Skip tiny patches\n",
    "                continue\n",
    "            \n",
    "            true_fractions.append(calculate_pore_fraction(true_patch))\n",
    "            pred_fractions.append(calculate_pore_fraction(pred_patch))\n",
    "    \n",
    "    return np.array(true_fractions), np.array(pred_fractions)\n",
    "\n",
    "bias_results = {}\n",
    "for method_path in method_image_paths:\n",
    "    method_name = os.path.basename(method_path).replace('.tif', '')\n",
    "    \n",
    "    # Load the predicted mask\n",
    "    predicted_mask = load_mask_image(method_path)\n",
    "    \n",
    "    # Get pore fractions for each patch\n",
    "    true_fractions, pred_fractions = get_patch_pore_fractions(gold_standard_mask, predicted_mask)\n",
    "    \n",
    "    # Calculate bias (positive = over-estimates pores, negative = under-estimates)\n",
    "    bias_values = pred_fractions - true_fractions\n",
    "    mean_bias = np.mean(bias_values)\n",
    "    \n",
    "    bias_results[method_name] = {\n",
    "        'mean_bias': mean_bias,\n",
    "        'std_bias': np.std(bias_values) if len(bias_values) > 1 else 0.0,\n",
    "        'num_patches': len(bias_values)\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "Set up colors and styles for plotting\n",
    "\"\"\"\n",
    "# Define method categories\n",
    "traditional_methods = [\"FREEHAND\", \"OVAL\"]\n",
    "semi_auto_methods = [\"SEMI\", \"SAMJ\", \"ILASTIK\", \"60%\"]\n",
    "fully_auto_methods = [\"PORED2\", \"UNET\", \"OTSU\", \"PLANKSTER\"]\n",
    "\n",
    "# Colors for each category\n",
    "traditional_color = \"#9ecae1\"  # Light blue\n",
    "semi_auto_color = \"#d0b7ff\"   # Light purple\n",
    "fully_auto_color = \"#f7b6b6\"  # Light red\n",
    "other_color = \"#dddddd\"       # Gray\n",
    "\n",
    "def get_method_color(method_name):\n",
    "    \"\"\"Get color based on method type\"\"\"\n",
    "    name_upper = method_name.upper()\n",
    "    \n",
    "    if any(trad in name_upper for trad in traditional_methods):\n",
    "        return traditional_color\n",
    "    elif any(semi in name_upper for semi in semi_auto_methods):\n",
    "        return semi_auto_color\n",
    "    elif any(auto in name_upper for auto in fully_auto_methods):\n",
    "        return fully_auto_color\n",
    "    else:\n",
    "        return other_color\n",
    "\n",
    "# Create legend\n",
    "legend_patches = [\n",
    "    Patch(facecolor=traditional_color, edgecolor='black', label='Traditional'),\n",
    "    Patch(facecolor=semi_auto_color, edgecolor='black', label='Semi-automated'),\n",
    "    Patch(facecolor=fully_auto_color, edgecolor='black', label='Fully automated')\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Prepare data for making plots\n",
    "\"\"\"\n",
    "# Metric names for display\n",
    "metric_display_names = {\n",
    "    \"f1_dice\": \"Dice (F1)\",\n",
    "    \"iou_jaccard\": \"IoU (Jaccard)\",\n",
    "    \"mcc\": \"Matthews CC\",\n",
    "    \"precision\": \"Precision\",\n",
    "    \"recall\": \"Recall\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "    \"balanced_accuracy\": \"Balanced Accuracy\",\n",
    "    \"accuracy\": \"Accuracy\"\n",
    "}\n",
    "\n",
    "# List of metrics to analyze\n",
    "metrics_to_plot = [\"f1_dice\", \"iou_jaccard\", \"mcc\", \"precision\", \"recall\", \"specificity\", \"balanced_accuracy\", \"accuracy\"]\n",
    "\n",
    "def save_figure(fig, filename):\n",
    "    \"\"\"Save figure in multiple formats\"\"\"\n",
    "    clean_name = filename.replace('[', '').replace(']', '').replace(':', '')\n",
    "    \n",
    "    tif_path = os.path.join(figures_folder, clean_name + '.tif')\n",
    "    pdf_path = os.path.join(figures_folder, clean_name + '.pdf')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(tif_path, dpi=300, bbox_inches='tight')\n",
    "    fig.savefig(pdf_path, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(\"Saved:\", clean_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9eae716-6e18-4614-875b-4de5dd1360e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for plots...\n",
      "Creating bar charts...\n",
      "Saved: STED 0.375% Bar Chart Accuracy\n",
      "Saved: STED 0.375% Bar Chart Precision\n",
      "Saved: STED 0.375% Bar Chart Recall\n",
      "Saved: STED 0.375% Bar Chart Specificity\n",
      "Saved: STED 0.375% Bar Chart Balanced Accuracy\n",
      "Saved: STED 0.375% Bar Chart Dice Score\n",
      "Saved: STED 0.375% Bar Chart IoU Score\n",
      "Saved: STED 0.375% Bar Chart MCC\n",
      "Creating box plots...\n",
      "Saved: STED 0.375% Box Plot Dice Score\n",
      "Saved: STED 0.375% Box Plot IoU Score\n",
      "Saved: STED 0.375% Box Plot MCC\n",
      "Creating heatmap...\n",
      "Saved: STED 0.375% Performance Heatmap\n",
      "Creating Bland-Altman plots...\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs 60% Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs FREEHAND Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OVAL Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs ILASTIK Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OTSU Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PLANKSTER Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PORED2 Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs SAMJ Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs UNET Dice Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs 60% IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs FREEHAND IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OVAL IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs ILASTIK IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OTSU IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PLANKSTER IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PORED2 IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs SAMJ IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs UNET IoU Score\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs 60% MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs FREEHAND MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OVAL MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs ILASTIK MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs OTSU MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PLANKSTER MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs PORED2 MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs SAMJ MCC\n",
      "Saved: STED 0.375% Bland-Altman SEMI vs UNET MCC\n",
      "All plots created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Make charts and plots to show the results\n",
    "# Create bar charts, box plots, heatmap, and Bland-Altman plots\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"\n",
    "Set up what we want to plot\n",
    "\"\"\"\n",
    "# All the metrics we calculated\n",
    "metrics_to_plot = [\"accuracy\", \"precision\", \"recall\", \"specificity\", \n",
    "                  \"balanced_accuracy\", \"f1_dice\", \"iou_jaccard\", \"mcc\"]\n",
    "\n",
    "# Key metrics for box plots\n",
    "key_metrics = [\"f1_dice\", \"iou_jaccard\", \"mcc\"]\n",
    "\n",
    "# Nice names for the plots\n",
    "metric_names = {\n",
    "    \"accuracy\": \"Accuracy\",\n",
    "    \"precision\": \"Precision\", \n",
    "    \"recall\": \"Recall\",\n",
    "    \"specificity\": \"Specificity\",\n",
    "    \"balanced_accuracy\": \"Balanced Accuracy\",\n",
    "    \"f1_dice\": \"Dice Score\",\n",
    "    \"iou_jaccard\": \"IoU Score\",\n",
    "    \"mcc\": \"MCC\"\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Create legend for method groups\n",
    "\"\"\"\n",
    "def create_method_legend():\n",
    "    \"\"\"Make legend patches for different method types\"\"\"\n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    legend_patches = [\n",
    "        Patch(color='blue', label='Traditional'),\n",
    "        Patch(color='purple', label='Semi-Automated'), \n",
    "        Patch(color='red', label='Fully-Automated')\n",
    "    ]\n",
    "    return legend_patches\n",
    "\n",
    "\"\"\"\n",
    "Simple statistical tests\n",
    "\"\"\"\n",
    "def simple_t_test(values1, values2):\n",
    "    \"\"\"Compare two groups of values\"\"\"\n",
    "    try:\n",
    "        from scipy.stats import ttest_ind\n",
    "        if len(values1) >= 2 and len(values2) >= 2:\n",
    "            stat, p_value = ttest_ind(values1, values2)\n",
    "            return p_value\n",
    "        else:\n",
    "            return 1.0\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "\"\"\"\n",
    "Prepare the data for plotting\n",
    "\"\"\"\n",
    "print(\"Preparing data for plots...\")\n",
    "\n",
    "# Make summary data for each method\n",
    "summary_data = {}\n",
    "for method_name, results_list in method_results.items():\n",
    "    summary_data[method_name] = {}\n",
    "    \n",
    "    for metric in metrics_to_plot:\n",
    "        values = [result[metric] for result in results_list if metric in result]\n",
    "        if values:\n",
    "            mean_val = np.mean(values)\n",
    "            std_val = np.std(values) if len(values) > 1 else 0\n",
    "            \n",
    "            summary_data[method_name][metric] = {\n",
    "                'mean': mean_val,\n",
    "                'std': std_val,\n",
    "                'values': values,\n",
    "                'count': len(values)\n",
    "            }\n",
    "\n",
    "# Create legend patches\n",
    "legend_patches = create_method_legend()\n",
    "\n",
    "\"\"\"\n",
    "Create bar charts for each metric\n",
    "\"\"\"\n",
    "print(\"Creating bar charts...\")\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    # Get data for this metric\n",
    "    methods_for_plot = []\n",
    "    means_for_plot = []\n",
    "    stds_for_plot = []\n",
    "    colors_for_plot = []\n",
    "    \n",
    "    for method_name, method_summary in summary_data.items():\n",
    "        if metric in method_summary:\n",
    "            methods_for_plot.append(method_name)\n",
    "            means_for_plot.append(method_summary[metric]['mean'])\n",
    "            stds_for_plot.append(method_summary[metric]['std'])\n",
    "            colors_for_plot.append(get_method_color(method_name))\n",
    "    \n",
    "    if not methods_for_plot:\n",
    "        continue\n",
    "    \n",
    "    # Sort by performance (best first)\n",
    "    combined = list(zip(methods_for_plot, means_for_plot, stds_for_plot, colors_for_plot))\n",
    "    combined.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    methods_sorted = [x[0] for x in combined]\n",
    "    means_sorted = [x[1] for x in combined]\n",
    "    stds_sorted = [x[2] for x in combined]\n",
    "    colors_sorted = [x[3] for x in combined]\n",
    "    \n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    x_positions = range(len(methods_sorted))\n",
    "    bars = ax.bar(x_positions, means_sorted, yerr=stds_sorted,\n",
    "                  color=colors_sorted, edgecolor='black', linewidth=0.8,\n",
    "                  capsize=3)\n",
    "    \n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(methods_sorted, rotation=45, ha='right')\n",
    "    ax.set_ylabel(metric_names.get(metric, metric))\n",
    "    ax.set_title(experiment_name + ' - ' + metric_names.get(metric, metric))\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add legend in top right corner\n",
    "    ax.legend(handles=legend_patches, loc='upper right', frameon=True,\n",
    "              fancybox=True, shadow=True, framealpha=0.9)\n",
    "    \n",
    "    # Save the figure\n",
    "    save_figure(fig, experiment_name + ' Bar Chart ' + metric_names.get(metric, metric))\n",
    "\n",
    "\"\"\"\n",
    "Create box plots for key metrics\n",
    "\"\"\"\n",
    "print(\"Creating box plots...\")\n",
    "\n",
    "for metric in key_metrics:\n",
    "    if metric not in metrics_to_plot:\n",
    "        continue\n",
    "    \n",
    "    # Get all values for each method\n",
    "    box_data = []\n",
    "    box_labels = []\n",
    "    box_colors = []\n",
    "    \n",
    "    method_values = {}\n",
    "    for method_name, method_summary in summary_data.items():\n",
    "        if metric in method_summary:\n",
    "            method_values[method_name] = method_summary[metric]['values']\n",
    "    \n",
    "    # Sort methods by median performance\n",
    "    sorted_methods = sorted(method_values.keys(), \n",
    "                          key=lambda m: np.median(method_values[m]), \n",
    "                          reverse=True)\n",
    "    \n",
    "    for method_name in sorted_methods:\n",
    "        box_data.append(method_values[method_name])\n",
    "        box_labels.append(method_name)\n",
    "        box_colors.append(get_method_color(method_name))\n",
    "    \n",
    "    if not box_data:\n",
    "        continue\n",
    "    \n",
    "    # Create box plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    bp = ax.boxplot(box_data, labels=box_labels, patch_artist=True)\n",
    "    \n",
    "    # Color the boxes\n",
    "    for patch, color in zip(bp['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_edgecolor('black')\n",
    "    \n",
    "    # Style the other box plot elements\n",
    "    for element in ['whiskers', 'caps', 'medians']:\n",
    "        for item in bp[element]:\n",
    "            item.set_color('black')\n",
    "    \n",
    "    ax.set_ylabel(metric_names.get(metric, metric))\n",
    "    ax.set_title(experiment_name + ' - ' + metric_names.get(metric, metric))\n",
    "    ax.set_xticklabels(box_labels, rotation=45, ha='right')\n",
    "    ax.set_ylim(0, 1.1)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add legend in top right corner\n",
    "    ax.legend(handles=legend_patches, loc='upper right', frameon=True,\n",
    "              fancybox=True, shadow=True, framealpha=0.9)\n",
    "    \n",
    "    # Save the figure\n",
    "    save_figure(fig, experiment_name + ' Box Plot ' + metric_names.get(metric, metric))\n",
    "\n",
    "\"\"\"\n",
    "Create heatmap showing all metrics for all methods\n",
    "\"\"\"\n",
    "print(\"Creating heatmap...\")\n",
    "\n",
    "# Prepare data matrix\n",
    "methods_list = list(summary_data.keys())\n",
    "heatmap_data = []\n",
    "\n",
    "for method_name in methods_list:\n",
    "    method_row = []\n",
    "    for metric in metrics_to_plot:\n",
    "        if metric in summary_data[method_name]:\n",
    "            method_row.append(summary_data[method_name][metric]['mean'])\n",
    "        else:\n",
    "            method_row.append(np.nan)\n",
    "    heatmap_data.append(method_row)\n",
    "\n",
    "heatmap_array = np.array(heatmap_data)\n",
    "\n",
    "# Sort methods by average performance\n",
    "avg_performance = np.nanmean(heatmap_array, axis=1)\n",
    "sort_order = np.argsort(-avg_performance)  # Descending order\n",
    "\n",
    "methods_sorted = [methods_list[i] for i in sort_order]\n",
    "heatmap_sorted = heatmap_array[sort_order]\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, len(methods_sorted) * 0.4 + 2))\n",
    "\n",
    "im = ax.imshow(heatmap_sorted, cmap='Greys', vmin=0, vmax=1, aspect='auto')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(methods_sorted)):\n",
    "    for j in range(len(metrics_to_plot)):\n",
    "        value = heatmap_sorted[i, j]\n",
    "        if not np.isnan(value):\n",
    "            ax.text(j, i, '{:.2f}'.format(value), \n",
    "                   ha='center', va='center', color='black')\n",
    "\n",
    "ax.set_xticks(range(len(metrics_to_plot)))\n",
    "ax.set_xticklabels([metric_names.get(m, m) for m in metrics_to_plot], \n",
    "                  rotation=45, ha='right')\n",
    "ax.set_yticks(range(len(methods_sorted)))\n",
    "ax.set_yticklabels(methods_sorted)\n",
    "ax.set_title(experiment_name + ' - Performance Heatmap')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(im, ax=ax)\n",
    "cbar.set_label('Performance (0-1)')\n",
    "\n",
    "# Save the figure\n",
    "save_figure(fig, experiment_name + ' Performance Heatmap')\n",
    "\n",
    "\"\"\"\n",
    "Create simple Bland-Altman plots\n",
    "\"\"\"\n",
    "print(\"Creating Bland-Altman plots...\")\n",
    "\n",
    "def make_bland_altman_plot(values_a, values_b, method_a_name, method_b_name, metric_name):\n",
    "    \"\"\"\n",
    "    Make a simple Bland-Altman plot comparing two methods\n",
    "    \"\"\"\n",
    "    # Convert to arrays\n",
    "    a_array = np.array(values_a)\n",
    "    b_array = np.array(values_b)\n",
    "    \n",
    "    # Calculate means and differences\n",
    "    means = (a_array + b_array) / 2.0\n",
    "    differences = a_array - b_array\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    mean_diff = np.mean(differences)\n",
    "    std_diff = np.std(differences) if len(differences) > 1 else 0\n",
    "    \n",
    "    # Simple limits of agreement\n",
    "    upper_limit = mean_diff + 2 * std_diff\n",
    "    lower_limit = mean_diff - 2 * std_diff\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Plot the data points\n",
    "    ax.scatter(means, differences, alpha=0.7, color='black', s=40)\n",
    "    \n",
    "    # Plot the mean difference line\n",
    "    ax.axhline(mean_diff, color='blue', linestyle='-', linewidth=2, \n",
    "               label='Mean difference: {:.3f}'.format(mean_diff))\n",
    "    \n",
    "    # Plot the limits\n",
    "    ax.axhline(upper_limit, color='red', linestyle='--', linewidth=1, \n",
    "               label='Upper limit: {:.3f}'.format(upper_limit))\n",
    "    ax.axhline(lower_limit, color='red', linestyle='--', linewidth=1, \n",
    "               label='Lower limit: {:.3f}'.format(lower_limit))\n",
    "    \n",
    "    # Add zero line\n",
    "    ax.axhline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('Mean of ' + method_a_name + ' and ' + method_b_name)\n",
    "    ax.set_ylabel(method_a_name + ' - ' + method_b_name)\n",
    "    ax.set_title('Bland-Altman: ' + method_a_name + ' vs ' + method_b_name + \n",
    "                ' (' + metric_names.get(metric_name, metric_name) + ')')\n",
    "    \n",
    "    # Add grid and legend\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_name = (experiment_name + ' Bland-Altman ' + method_a_name + ' vs ' + \n",
    "                method_b_name + ' ' + metric_names.get(metric_name, metric_name))\n",
    "    save_figure(fig, plot_name)\n",
    "\n",
    "# Find the best method for each key metric\n",
    "best_methods = {}\n",
    "for metric in key_metrics:\n",
    "    best_score = 0\n",
    "    best_method = None\n",
    "    \n",
    "    for method_name in summary_data.keys():\n",
    "        if metric in summary_data[method_name]:\n",
    "            score = summary_data[method_name][metric]['mean']\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_method = method_name\n",
    "    \n",
    "    if best_method:\n",
    "        best_methods[metric] = best_method\n",
    "\n",
    "# Create Bland-Altman plots comparing methods to the best one\n",
    "for metric in key_metrics:\n",
    "    if metric not in best_methods:\n",
    "        continue\n",
    "    \n",
    "    best_method_name = best_methods[metric]\n",
    "    best_method_values = summary_data[best_method_name][metric]['values']\n",
    "    \n",
    "    # Compare other methods to the best one\n",
    "    for method_name in summary_data.keys():\n",
    "        if method_name == best_method_name:\n",
    "            continue\n",
    "        \n",
    "        if metric not in summary_data[method_name]:\n",
    "            continue\n",
    "            \n",
    "        method_values = summary_data[method_name][metric]['values']\n",
    "        \n",
    "        # Make sure we have enough data points\n",
    "        min_length = min(len(best_method_values), len(method_values))\n",
    "        if min_length >= 3:  # Need at least 3 points\n",
    "            # Use first min_length values from each method\n",
    "            values_a = best_method_values[:min_length]\n",
    "            values_b = method_values[:min_length]\n",
    "            \n",
    "            make_bland_altman_plot(values_a, values_b, best_method_name, \n",
    "                                 method_name, metric)\n",
    "\n",
    "print(\"All plots created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1ad9e-c563-4480-a289-69f6e46b1a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pore-acc-126 (NumPy 1.26)",
   "language": "python",
   "name": "pore-acc-126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
