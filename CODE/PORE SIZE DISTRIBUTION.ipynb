{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c913430c-cca3-4a90-876f-f3bd5d5d66b2",
   "metadata": {},
   "source": [
    "## **PORE SIZE DISTRIBUTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "635a6adb-e89c-4274-a3ef-dd745b43092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for data analysis\n",
    "\n",
    "import os\n",
    "import re  \n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac95cb-e426-4424-8cf8-f59883371fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up folder paths for the analysis\n",
    "import os\n",
    "from pathlib import Path\n",
    "notebook_dir = Path.cwd()\n",
    "proj_root = notebook_dir.parent\n",
    "BASE_DIR = str(proj_root / \"CRYO-SEM DATA\" / \"CRYO-SEM X30000\")\n",
    "# where the data files are stored\n",
    "pore_size_folder = BASE_DIR / \"CRYO-SEM X30000 [1]\" / \"CRYO-SEM X30000 [1]\" / \"STATS\" / \"PORE SIZE RESULTS\"\n",
    "bubble_analysis_folder = BASE_DIR / \"CRYO-SEM X30000 [1]\" / \"CRYO-SEM X30000 [1] BA INDIVIDUAL STATS\" / \"Diameters\"\n",
    "\n",
    "# list of all input folders\n",
    "data_folders = [pore_size_folder, bubble_analysis_folder]\n",
    "org_dir = str(proj_root)\n",
    "\n",
    "# where to save the output files\n",
    "output_pore_folder = org_dir / \"PORE SIZE DISTRIBUTIONS\" / \"ANALYSED PRIOR\"\n",
    "output_bubble_folder = org_dir / \"PORE SIZE DISTRIBUTIONS\" / \"BUBBLE ANALYSIS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6322bed9-cbe4-4ba9-933e-50e132b6e0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up colors for different analysis methods\n",
    "\n",
    "# lighter colors for some chart types\n",
    "light_colors = {\"blue\": \"#8ecae6\", \"purple\": \"#cdb4db\", \"red\": \"#f08080\"}\n",
    "\n",
    "# darker colors for other chart types  \n",
    "dark_colors = {\"blue\": \"#1f77b4\", \"purple\": \"#6b21a8\", \"red\": \"#b91c1c\"}\n",
    "\n",
    "# grouping different analysis methods by color\n",
    "method_groups = {\n",
    "    \"blue\": [\"FREEHAND\", \"OVAL\"],\n",
    "    \"purple\": [\"ILASTIK\", \"SEMI\", \"SAMJ\", \"60%\", \"60P\"], \n",
    "    \"red\": [\"PLANKSTER\", \"OTSU\", \"UNET\", \"PORED2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0131c07-badb-4385-b18b-7eff00e42807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to help organize and identify different data types\n",
    "\n",
    "def check_if_bubble_analysis(folder_path):\n",
    "    \"\"\"Check if this folder contains bubble analysis data\"\"\"\n",
    "    return \"BA INDIVIDUAL STATS\" in folder_path.upper()\n",
    "\n",
    "def check_if_pore_size_data(folder_path):\n",
    "    \"\"\"Check if this folder has pore size analysis results\"\"\"\n",
    "    folder_upper = folder_path.upper()\n",
    "    if \"STATS\\\\MATLAB STATS\" in folder_upper:\n",
    "        return True\n",
    "    if \"STATS/MATLAB STATS\" in folder_upper:\n",
    "        return True\n",
    "    if \"PORE SIZE RESULTS\" in folder_upper:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def figure_out_analysis_method(file_path):\n",
    "    \"\"\"Try to determine what analysis method was used from the filename\"\"\"\n",
    "    # get just the filename without the full path\n",
    "    just_filename = os.path.basename(file_path).upper()\n",
    "    \n",
    "    # check each group of methods to see if any match\n",
    "    for color_group in method_groups.values():\n",
    "        for method_name in color_group:\n",
    "            if method_name in just_filename:\n",
    "                # fix the percentage naming issue\n",
    "                if method_name == \"60P\":\n",
    "                    return \"60%\"\n",
    "                else:\n",
    "                    return method_name\n",
    "    \n",
    "    # if no match found, just use the first part of the filename\n",
    "    filename_without_extension = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    filename_parts = re.split('[_\\\\-\\\\s]+', filename_without_extension)\n",
    "    return filename_parts[0]\n",
    "\n",
    "def get_color_for_method(method_name, use_dark_color=False):\n",
    "    \"\"\"Get the right color for this analysis method\"\"\"\n",
    "    method_upper = method_name.upper()\n",
    "    \n",
    "    # look through each color group to find where this method belongs\n",
    "    for color_name, method_list in method_groups.items():\n",
    "        for method in method_list:\n",
    "            if method in method_upper:\n",
    "                if use_dark_color:\n",
    "                    return dark_colors[color_name]\n",
    "                else:\n",
    "                    return light_colors[color_name]\n",
    "    \n",
    "    # default to purple if method not found\n",
    "    if use_dark_color:\n",
    "        return dark_colors[\"purple\"]\n",
    "    else:\n",
    "        return light_colors[\"purple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "963043f4-4235-4c9f-9f1c-ca19b27d2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to read CSV files and handle histogram data\n",
    "\n",
    "def convert_histogram_to_individual_values(data_frame):\n",
    "    \"\"\"Take histogram data and expand it into individual sample points\"\"\"\n",
    "    # get the diameter values from first column\n",
    "    diameter_values = pd.to_numeric(data_frame.iloc[:,0], errors=\"coerce\").to_numpy()\n",
    "    \n",
    "    # get the probability or count values from second column\n",
    "    probability_values = pd.to_numeric(data_frame.iloc[:,1], errors=\"coerce\").fillna(0).to_numpy()\n",
    "    \n",
    "    # check if these look like probabilities (sum close to 1)\n",
    "    total_probability = probability_values.sum()\n",
    "    if total_probability > 0.5 and total_probability < 2.0:\n",
    "        # normalize to make sure they sum to 1\n",
    "        probability_values = probability_values / total_probability\n",
    "    \n",
    "    # convert to counts for sampling (use 10000 total samples)\n",
    "    total_samples = 10000\n",
    "    sample_counts = np.round(probability_values * total_samples).astype(int)\n",
    "    \n",
    "    # create individual samples by repeating each diameter value\n",
    "    individual_samples = np.repeat(diameter_values, sample_counts)\n",
    "    \n",
    "    return individual_samples\n",
    "\n",
    "def read_csv_file_safely(file_path):\n",
    "    \"\"\"Try different ways to read a CSV file until one works\"\"\"\n",
    "    # try the normal way first\n",
    "    try:\n",
    "        return pd.read_csv(file_path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # try with automatic separator detection\n",
    "    try:\n",
    "        return pd.read_csv(file_path, sep=None, engine=\"python\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # try with different encoding\n",
    "    try:\n",
    "        return pd.read_csv(file_path, encoding=\"latin-1\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # try both different separator and encoding\n",
    "    try:\n",
    "        return pd.read_csv(file_path, sep=None, engine=\"python\", encoding=\"latin-1\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # if nothing worked, give up\n",
    "    raise RuntimeError(\"Could not read CSV file: \" + file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "09cf505e-448b-42aa-b2b3-e03a6d23efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pore_sizes_from_file(file_path):\n",
    "    \"\"\"Read a CSV file and extract pore size values, figure out if units are um or nm\"\"\"\n",
    "    \n",
    "    # try to read the CSV file\n",
    "    data_frame = read_csv_file_safely(file_path)\n",
    "    pore_values = None\n",
    "    \n",
    "    # first check if this looks like histogram data (2 columns with probabilities)\n",
    "    if data_frame.shape[1] == 2:\n",
    "        try:\n",
    "            # check if second column sums to around 1 (probabilities)\n",
    "            second_column_sum = pd.to_numeric(data_frame.iloc[:,1], errors=\"coerce\").fillna(0).sum()\n",
    "            if second_column_sum >= 0.5 and second_column_sum <= 1.5:\n",
    "                # treat as histogram and expand to individual values\n",
    "                pore_values = convert_histogram_to_individual_values(data_frame)\n",
    "        except Exception:\n",
    "            # if histogram conversion fails, try other methods\n",
    "            pass\n",
    "    \n",
    "    # if histogram approach didn't work, look for diameter columns\n",
    "    if pore_values is None:\n",
    "        for column_name in data_frame.columns:\n",
    "            column_lower = str(column_name).lower()\n",
    "            \n",
    "            # check if this column name suggests it contains diameter data\n",
    "            diameter_keywords = [\"diam\", \"d_um\", \"d (um)\", \"d (Âµm)\", \"d_nm\", \"d (nm)\", \"aecd\"]\n",
    "            contains_diameter_keyword = False\n",
    "            for keyword in diameter_keywords:\n",
    "                if keyword in column_lower:\n",
    "                    contains_diameter_keyword = True\n",
    "                    break\n",
    "            \n",
    "            if contains_diameter_keyword:\n",
    "                # try to extract numeric values from this column\n",
    "                numeric_values = pd.to_numeric(data_frame[column_name], errors=\"coerce\").dropna().to_numpy()\n",
    "                if len(numeric_values) > 0:\n",
    "                    pore_values = numeric_values\n",
    "                    break\n",
    "    \n",
    "    # if still no values found, just use the first column\n",
    "    if pore_values is None:\n",
    "        pore_values = pd.to_numeric(data_frame.iloc[:,0], errors=\"coerce\").dropna().to_numpy()\n",
    "    \n",
    "    # if no valid data found, return empty array\n",
    "    if len(pore_values) == 0:\n",
    "        return pore_values, \"um\"\n",
    "    \n",
    "    # figure out units by looking at the 95th percentile value\n",
    "    percentile_95 = np.nanpercentile(pore_values, 95)\n",
    "    \n",
    "    if percentile_95 < 10:\n",
    "        units = \"um\"\n",
    "    else:\n",
    "        units = \"nm\"\n",
    "    \n",
    "    # special case for very small values\n",
    "    if percentile_95 < 0.02:\n",
    "        units = \"um\"\n",
    "    \n",
    "    return pore_values, units\n",
    "\n",
    "def convert_to_nanometers(values, current_units):\n",
    "    \"\"\"Convert pore size values to nanometers\"\"\"\n",
    "    if current_units.lower() == \"um\":\n",
    "        # multiply by 1000 to convert micrometers to nanometers\n",
    "        return values * 1000.0\n",
    "    else:\n",
    "        # already in nanometers, just make sure it's float\n",
    "        return values.astype(float, copy=False)\n",
    "\n",
    "def make_axis_numbers_plain(plot_axis):\n",
    "    \"\"\"Make the axis show regular numbers instead of scientific notation\"\"\"\n",
    "    plot_axis.ticklabel_format(style='plain', axis='x', useOffset=False)\n",
    "    \n",
    "    number_formatter = ScalarFormatter(useOffset=False, useMathText=False)\n",
    "    number_formatter.set_scientific(False)\n",
    "    plot_axis.xaxis.set_major_formatter(number_formatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8efe5561-6bdc-4e29-824d-8a105253674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to create histogram bins for different analysis types\n",
    "\n",
    "def create_bins_for_pore_analysis(data_values, padding_fraction=0.20, \n",
    "                                 target_min_bins=20, target_max_bins=45,\n",
    "                                 minimum_bin_width=3.0, maximum_total_bins=60):\n",
    "    \"\"\"Create bins for pore size analysis - not too many bins, around 20-45 total\"\"\"\n",
    "    \n",
    "    # clean up the data and remove any invalid values\n",
    "    clean_data = np.asarray(data_values)\n",
    "    clean_data = clean_data[np.isfinite(clean_data)]\n",
    "    \n",
    "    # find the range of the data\n",
    "    data_min = float(clean_data.min())\n",
    "    data_max = float(clean_data.max())\n",
    "    data_range = max(1e-9, data_max - data_min)  # avoid division by zero\n",
    "    \n",
    "    # add some padding around the data range\n",
    "    padding_amount = data_range * padding_fraction\n",
    "    bin_start = max(0.0, data_min - padding_amount)  # don't go below zero\n",
    "    bin_end = data_max + padding_amount\n",
    "    total_span = bin_end - bin_start\n",
    "    \n",
    "    # calculate how many bins we want based on data size\n",
    "    target_bins = int(round(np.sqrt(len(clean_data)) * 3.0))\n",
    "    # make sure it's within our desired range\n",
    "    if target_bins < target_min_bins:\n",
    "        target_bins = target_min_bins\n",
    "    if target_bins > target_max_bins:\n",
    "        target_bins = target_max_bins\n",
    "    \n",
    "    # figure out bin width, respecting minimum width\n",
    "    suggested_width = total_span / target_bins\n",
    "    max_width_allowed = total_span / maximum_total_bins\n",
    "    actual_bin_width = max(minimum_bin_width, max_width_allowed, suggested_width)\n",
    "    \n",
    "    # calculate final number of bins\n",
    "    final_bin_count = int(np.ceil(total_span / actual_bin_width))\n",
    "    if final_bin_count < target_min_bins:\n",
    "        final_bin_count = target_min_bins\n",
    "    if final_bin_count > maximum_total_bins:\n",
    "        final_bin_count = maximum_total_bins\n",
    "    \n",
    "    # create the actual bin edges\n",
    "    bin_edges = np.linspace(bin_start, bin_end, final_bin_count + 1)\n",
    "    \n",
    "    return bin_edges, (bin_start, bin_end)\n",
    "\n",
    "def create_bins_for_bubble_analysis(data_values, padding_fraction=0.20,\n",
    "                                   target_bins=100, min_allowed_bins=70, \n",
    "                                   max_allowed_bins=120, minimum_bin_width=1.5):\n",
    "    \"\"\"Create bins for bubble analysis - more detailed, around 70-120 bins\"\"\"\n",
    "    \n",
    "    # clean up the data and remove any invalid values\n",
    "    clean_data = np.asarray(data_values)\n",
    "    clean_data = clean_data[np.isfinite(clean_data)]\n",
    "    \n",
    "    # find the range of the data\n",
    "    data_min = float(clean_data.min())\n",
    "    data_max = float(clean_data.max())\n",
    "    data_range = max(1e-9, data_max - data_min)  # avoid division by zero\n",
    "    \n",
    "    # add some padding around the data range\n",
    "    padding_amount = data_range * padding_fraction\n",
    "    bin_start = max(0.0, data_min - padding_amount)  # don't go below zero\n",
    "    bin_end = data_max + padding_amount\n",
    "    total_span = bin_end - bin_start\n",
    "    \n",
    "    # calculate bin width based on target number of bins\n",
    "    suggested_bin_width = total_span / target_bins\n",
    "    actual_bin_width = max(minimum_bin_width, suggested_bin_width)\n",
    "    \n",
    "    # calculate final number of bins\n",
    "    final_bin_count = int(np.ceil(total_span / actual_bin_width))\n",
    "    if final_bin_count < min_allowed_bins:\n",
    "        final_bin_count = min_allowed_bins\n",
    "    if final_bin_count > max_allowed_bins:\n",
    "        final_bin_count = max_allowed_bins\n",
    "    \n",
    "    # create the actual bin edges\n",
    "    bin_edges = np.linspace(bin_start, bin_end, final_bin_count + 1)\n",
    "    \n",
    "    return bin_edges, (bin_start, bin_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4171639-e717-4471-a943-a6b79ea0a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_plot(diameter_values_nm, plot_title, bar_color, save_path, analysis_type):\n",
    "    \"\"\"Create and save a histogram plot of pore size data\"\"\"\n",
    "    \n",
    "    # clean up the data and remove any invalid values\n",
    "    clean_values = np.asarray(diameter_values_nm)\n",
    "    clean_values = clean_values[np.isfinite(clean_values)]\n",
    "    \n",
    "    # if no valid data, don't make a plot\n",
    "    if len(clean_values) == 0:\n",
    "        return\n",
    "    \n",
    "    # choose the right binning method based on analysis type\n",
    "    if analysis_type == \"BA\":\n",
    "        bin_edges, (x_min, x_max) = create_bins_for_bubble_analysis(clean_values)\n",
    "    else:\n",
    "        # default to pore analysis binning\n",
    "        bin_edges, (x_min, x_max) = create_bins_for_pore_analysis(clean_values)\n",
    "    \n",
    "    # calculate histogram to find the maximum count for y-axis scaling\n",
    "    bin_counts, temp_edges = np.histogram(clean_values, bins=bin_edges)\n",
    "    max_count = max(1, bin_counts.max())\n",
    "    \n",
    "    # add some extra space at the top (30% headroom)\n",
    "    y_padding = max(1, int(np.ceil(max_count * 0.30)))\n",
    "    \n",
    "    # create the plot\n",
    "    figure, axis = plt.subplots(figsize=(6.8, 4.8))\n",
    "    \n",
    "    # make the histogram\n",
    "    axis.hist(clean_values, bins=bin_edges, color=bar_color, \n",
    "              edgecolor=\"black\", linewidth=0.6, alpha=0.85)\n",
    "    \n",
    "    # add labels and title\n",
    "    axis.set_xlabel(\"Pore Size (nm)\")\n",
    "    axis.set_ylabel(\"Frequency\")\n",
    "    \n",
    "    # create title with sample count\n",
    "    full_title = plot_title + \" (n = \" + str(len(clean_values)) + \")\"\n",
    "    axis.set_title(full_title)\n",
    "    \n",
    "    # make the numbers on x-axis look normal (not scientific notation)\n",
    "    make_axis_numbers_plain(axis)\n",
    "    \n",
    "    # set the axis limits\n",
    "    axis.set_xlim(x_min, x_max)\n",
    "    axis.set_ylim(0, max_count + y_padding)\n",
    "    \n",
    "    # make it look nice and save\n",
    "    figure.tight_layout()\n",
    "    figure.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bdea397-e61b-4c36-8d9c-55d6423eeac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to clean up filenames and find CSV files\n",
    "\n",
    "def remove_hidden_characters(text_string):\n",
    "    \"\"\"Clean up text by removing hidden unicode characters\"\"\"\n",
    "    # normalize the unicode characters\n",
    "    normalized_text = unicodedata.normalize('NFKC', text_string)\n",
    "    \n",
    "    # keep only visible characters (remove control and separator characters)\n",
    "    clean_characters = []\n",
    "    for character in normalized_text:\n",
    "        char_category = unicodedata.category(character)\n",
    "        # skip control characters and line/paragraph separators\n",
    "        if not char_category.startswith('C') and not char_category.startswith('Zl') and not char_category.startswith('Zp'):\n",
    "            clean_characters.append(character)\n",
    "    \n",
    "    # join back together and remove extra whitespace\n",
    "    clean_text = ''.join(clean_characters)\n",
    "    return clean_text.strip()\n",
    "\n",
    "def find_csv_files_in_folder(folder_path):\n",
    "    \"\"\"Look through a folder and find all CSV files, handling weird filenames\"\"\"\n",
    "    csv_files_found = []\n",
    "    \n",
    "    # try to get the list of files in the folder\n",
    "    try:\n",
    "        file_names = os.listdir(folder_path)\n",
    "    except Exception as error:\n",
    "        print(\"Warning: Could not list files in \" + folder_path + \": \" + str(error))\n",
    "        return csv_files_found\n",
    "    \n",
    "    # check each file to see if it's a CSV\n",
    "    for file_name in file_names:\n",
    "        # skip system files\n",
    "        if file_name.lower() == \"desktop.ini\":\n",
    "            continue\n",
    "        \n",
    "        # clean up any weird characters in the filename\n",
    "        clean_filename = remove_hidden_characters(file_name)\n",
    "        \n",
    "        # check if this looks like a CSV file\n",
    "        if clean_filename.lower().endswith(\".csv\"):\n",
    "            full_file_path = os.path.join(folder_path, file_name)\n",
    "            csv_files_found.append(full_file_path)\n",
    "            continue\n",
    "        \n",
    "        # also check for files that start with .csv (in case of weird extensions)\n",
    "        filename_without_extension, file_extension = os.path.splitext(file_name)\n",
    "        if file_extension.lower().startswith(\".csv\"):\n",
    "            full_file_path = os.path.join(folder_path, file_name)\n",
    "            csv_files_found.append(full_file_path)\n",
    "    \n",
    "    return csv_files_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c86972c-d3b0-4d6e-b06a-47cc194d57cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[AP] Looking for files in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [1]\\CRYO-SEM X30000 [1] STATS\\PORE SIZE RESULTS\n",
      "   - '60% AECD Results.csv'\n",
      "   - 'FREEHAND AECD Results.csv'\n",
      "   - 'GOLD STANDARD [X30000] Results AECD Results.csv'\n",
      "   - 'ILASTIK [X30000] Results AECD Results.csv'\n",
      "   - 'OTSU AECD Results.csv'\n",
      "   - 'OVAL [X30000] Results AECD Results.csv'\n",
      "   - 'PLANKSTER [X30000] Results AECD Results.csv'\n",
      "   - 'PORE SIZE DISTRIBUTION'\n",
      "   - 'PORED2 [X30000] Results AECD Results.csv'\n",
      "   - 'SAMJ [X30000] Results AECD Results.csv'\n",
      "   - 'SEMI [X30000] Results AECD Results.csv'\n",
      "   - 'UNET [X30000] Results AECD Results.csv'\n",
      "\n",
      "Processing 11 file(s) -> Output folder: C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\n",
      "  Success: 60% AECD Results.csv -> AP_60%_hist_nm.png (n=55)\n",
      "  Success: FREEHAND AECD Results.csv -> AP_FREEHAND_hist_nm.png (n=59)\n",
      "  Success: GOLD STANDARD [X30000] Results AECD Results.csv -> AP_GOLD_hist_nm.png (n=119)\n",
      "  Success: ILASTIK [X30000] Results AECD Results.csv -> AP_ILASTIK_hist_nm.png (n=171)\n",
      "  Success: OTSU AECD Results.csv -> AP_OTSU_hist_nm.png (n=724)\n",
      "  Success: OVAL [X30000] Results AECD Results.csv -> AP_OVAL_hist_nm.png (n=62)\n",
      "  Success: PLANKSTER [X30000] Results AECD Results.csv -> AP_PLANKSTER_hist_nm.png (n=795)\n",
      "  Success: PORED2 [X30000] Results AECD Results.csv -> AP_PORED2_hist_nm.png (n=4)\n",
      "  Success: SAMJ [X30000] Results AECD Results.csv -> AP_SAMJ_hist_nm.png (n=11)\n",
      "  Success: SEMI [X30000] Results AECD Results.csv -> AP_SEMI_hist_nm.png (n=33)\n",
      "  Success: UNET [X30000] Results AECD Results.csv -> AP_UNET_hist_nm.png (n=235)\n",
      "\n",
      "[BA] Looking for files in: C:\\Users\\walsh\\Downloads\\CRYO-SEM Accuracy INTERNAL\\CRYO-SEM X30000\\CRYO-SEM X30000 [1]\\CRYO-SEM X30000 [1] BA INDIVIDUAL STATS\\Diameters\n",
      "   - '60%_diameters_um.csv'\n",
      "   - 'desktop.ini'\n",
      "   - 'FREEHAND_diameters_um.csv'\n",
      "   - 'GOLD STANDARD_diameters_um.csv'\n",
      "   - 'ILASTIK_diameters_um.csv'\n",
      "   - 'OTSU_diameters_um.csv'\n",
      "   - 'OVAL_diameters_um.csv'\n",
      "   - 'PLANKSTER_diameters_um.csv'\n",
      "   - 'PORE SIZE DISTRIBUTION'\n",
      "   - 'PORED2_diameters_um.csv'\n",
      "   - 'SAMJ_diameters_um.csv'\n",
      "   - 'SEMI_diameters_um.csv'\n",
      "   - 'UNET_diameters_um.csv'\n",
      "\n",
      "Processing 11 file(s) -> Output folder: C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\n",
      "  Success: 60%_diameters_um.csv -> BA_60%_hist_nm.png (n=225)\n",
      "  Success: FREEHAND_diameters_um.csv -> BA_FREEHAND_hist_nm.png (n=63)\n",
      "  Success: GOLD STANDARD_diameters_um.csv -> BA_GOLD_hist_nm.png (n=108)\n",
      "  Success: ILASTIK_diameters_um.csv -> BA_ILASTIK_hist_nm.png (n=201)\n",
      "  Success: OTSU_diameters_um.csv -> BA_OTSU_hist_nm.png (n=565)\n",
      "  Success: OVAL_diameters_um.csv -> BA_OVAL_hist_nm.png (n=58)\n",
      "  Success: PLANKSTER_diameters_um.csv -> BA_PLANKSTER_hist_nm.png (n=559)\n",
      "  Success: PORED2_diameters_um.csv -> BA_PORED2_hist_nm.png (n=92)\n",
      "  Success: SAMJ_diameters_um.csv -> BA_SAMJ_hist_nm.png (n=11)\n",
      "  Success: SEMI_diameters_um.csv -> BA_SEMI_hist_nm.png (n=45)\n",
      "  Success: UNET_diameters_um.csv -> BA_UNET_hist_nm.png (n=449)\n",
      "\n",
      "Finished processing. Saved plot files:\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_60%_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_FREEHAND_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_GOLD_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_ILASTIK_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_OTSU_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_OVAL_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_PLANKSTER_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_PORED2_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_SAMJ_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_SEMI_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/ANALYSED PRIOR\\AP_UNET_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_60%_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_FREEHAND_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_GOLD_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_ILASTIK_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_OTSU_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_OVAL_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_PLANKSTER_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_PORED2_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_SAMJ_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_SEMI_hist_nm.png\n",
      " - C:/Users/walsh/Documents/GitHub/AGAROSE-HYDROGEL-TRENDS-USING-AI-ML/PORE SIZE DISTRIBUTIONS/BUBBLE ANALYSIS\\BA_UNET_hist_nm.png\n"
     ]
    }
   ],
   "source": [
    "# process all the data folders and create histogram plots\n",
    "\n",
    "saved_plot_files = []\n",
    "\n",
    "for data_folder in data_folders:\n",
    "    # clean up the folder path\n",
    "    clean_folder_path = os.path.normpath(data_folder.strip().rstrip(\".\"))\n",
    "    \n",
    "    # check if this folder actually exists\n",
    "    if not os.path.isdir(clean_folder_path):\n",
    "        print(\"Skipping - not a valid folder: \" + clean_folder_path)\n",
    "        continue\n",
    "    \n",
    "    # figure out what type of analysis this is\n",
    "    if check_if_bubble_analysis(clean_folder_path):\n",
    "        analysis_mode = \"BA\"\n",
    "    elif check_if_pore_size_data(clean_folder_path):\n",
    "        analysis_mode = \"AP\"\n",
    "    else:\n",
    "        analysis_mode = \"AP\"  # default to pore analysis\n",
    "    \n",
    "    print(\"\\n[\" + analysis_mode + \"] Looking for files in: \" + clean_folder_path)\n",
    "    \n",
    "    # show what files are in this folder\n",
    "    try:\n",
    "        folder_contents = os.listdir(clean_folder_path)\n",
    "        for file_name in folder_contents:\n",
    "            print(\"   - \" + repr(file_name))\n",
    "    except Exception as error:\n",
    "        print(\"   Warning: Could not list folder contents: \" + str(error))\n",
    "    \n",
    "    # find all the CSV files in this folder\n",
    "    csv_file_list = find_csv_files_in_folder(clean_folder_path)\n",
    "    if len(csv_file_list) == 0:\n",
    "        print(\"Info: No CSV files found in this folder\")\n",
    "        continue\n",
    "    \n",
    "    # figure out where to save the output plots\n",
    "    if analysis_mode == \"BA\":\n",
    "        output_folder = output_bubble_folder\n",
    "    else:\n",
    "        output_folder = output_pore_folder\n",
    "    \n",
    "    # make sure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # create a label for the plots based on the folder name\n",
    "    folder_basename = os.path.basename(clean_folder_path)\n",
    "    parent_folder_name = os.path.basename(os.path.dirname(clean_folder_path))\n",
    "    \n",
    "    # use parent folder name if current folder is a generic stats folder\n",
    "    generic_folder_names = [\"STATS\", \"DIAMETERS\", \"MATLAB STATS\", \"PORE SIZE RESULTS\"]\n",
    "    if folder_basename.upper() in generic_folder_names:\n",
    "        base_label = parent_folder_name\n",
    "    else:\n",
    "        base_label = folder_basename\n",
    "    \n",
    "    plot_label_prefix = base_label + \" [\" + analysis_mode + \"]\"\n",
    "    \n",
    "    print(\"\\nProcessing \" + str(len(csv_file_list)) + \" file(s) -> Output folder: \" + output_folder)\n",
    "    \n",
    "    # process each CSV file\n",
    "    for csv_file_path in csv_file_list:\n",
    "        try:\n",
    "            # load the pore size data from this file\n",
    "            pore_values, original_units = load_pore_sizes_from_file(csv_file_path)\n",
    "            \n",
    "            # convert everything to nanometers\n",
    "            diameter_nm = convert_to_nanometers(pore_values, original_units)\n",
    "            \n",
    "            # figure out what analysis method was used\n",
    "            analysis_method = figure_out_analysis_method(csv_file_path)\n",
    "            \n",
    "            # pick the right color for this method\n",
    "            use_dark_colors = (analysis_mode == \"BA\")\n",
    "            plot_color = get_color_for_method(analysis_method, use_dark_colors)\n",
    "            \n",
    "            # create the plot title\n",
    "            full_plot_title = plot_label_prefix + \" \" + analysis_method\n",
    "            \n",
    "            # create the output filename\n",
    "            output_filename = analysis_mode + \"_\" + analysis_method + \"_hist_nm.png\"\n",
    "            output_file_path = os.path.join(output_folder, output_filename)\n",
    "            \n",
    "            # create and save the histogram plot\n",
    "            create_histogram_plot(diameter_nm, full_plot_title, plot_color, output_file_path, analysis_mode)\n",
    "            \n",
    "            # keep track of what we saved\n",
    "            saved_plot_files.append(output_file_path)\n",
    "            \n",
    "            print(\"  Success: \" + os.path.basename(csv_file_path) + \" -> \" + os.path.basename(output_file_path) + \" (n=\" + str(len(diameter_nm)) + \")\")\n",
    "            \n",
    "        except Exception as error:\n",
    "            print(\"  Failed: \" + os.path.basename(csv_file_path) + \": \" + str(error))\n",
    "\n",
    "print(\"\\nFinished processing. Saved plot files:\")\n",
    "for saved_file in saved_plot_files:\n",
    "    print(\" - \" + saved_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3b499-c695-4551-b79a-38ab242ec55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pore-acc-126 (NumPy 1.26)",
   "language": "python",
   "name": "pore-acc-126"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
